I0829 16:18:14.662863 16790 caffe.cpp:204] Using GPUs 1
I0829 16:18:14.692919 16790 caffe.cpp:209] GPU 1: GeForce GTX 1080 Ti
I0829 16:18:15.007133 16790 solver.cpp:45] Initializing solver from parameters: 
test_iter: 498
test_interval: 20
base_lr: 0.001
display: 10
max_iter: 1000
lr_policy: "inv"
gamma: 0.001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 0
snapshot_prefix: "snapshots/aw2d-bn_with_dann-alexnet"
solver_mode: GPU
device_id: 1
net: "/home/alfa/Documents/msda/mywork/models/aw2d/bn_with_dann/alexnet.prototxt"
train_state {
  level: 0
  stage: ""
}
weights: "/home/alfa/Documents/msda/mywork/pretrain/bvlc_reference_caffenet.caffemodel"
I0829 16:18:15.007177 16790 solver.cpp:102] Creating training net from net file: /home/alfa/Documents/msda/mywork/models/aw2d/bn_with_dann/alexnet.prototxt
I0829 16:18:15.007639 16790 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: /home/alfa/Documents/msda/mywork/models/aw2d/bn_with_dann/alexnet.prototxt
I0829 16:18:15.007650 16790 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0829 16:18:15.007769 16790 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0829 16:18:15.007788 16790 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer fc6_target/bn
I0829 16:18:15.007798 16790 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer fc7_target/bn
I0829 16:18:15.007812 16790 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer fc8_target/bn
I0829 16:18:15.007818 16790 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0829 16:18:15.008147 16790 net.cpp:51] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "s1_data"
  type: "ImageData"
  top: "s1_data"
  top: "s1_label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "/home/alfa/Documents/msda/mywork/data/office/office_a.txt"
    batch_size: 128
    shuffle: true
    new_height: 256
    new_width: 256
    is_color: true
  }
}
layer {
  name: "s2_data"
  type: "ImageData"
  top: "s2_data"
  top: "s2_label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "/home/alfa/Documents/msda/mywork/data/office/office_w.txt"
    batch_size: 128
    shuffle: true
    new_height: 256
    new_width: 256
    is_color: true
  }
}
layer {
  name: "target_data"
  type: "ImageData"
  top: "t_data"
  top: "t_label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "/home/alfa/Documents/msda/mywork/data/office/office_d.txt"
    batch_size: 128
    shuffle: true
    new_height: 256
    new_width: 256
    is_color: true
  }
}
layer {
  name: "source_domain_labels"
  type: "DummyData"
  top: "source_domain_labels"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "constant"
      value: 0
    }
    num: 128
    channels: 1
    height: 1
    width: 1
  }
}
layer {
  name: "target_domain_labels"
  type: "DummyData"
  top: "target_domain_labels"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "constant"
      value: 1
    }
    num: 128
    channels: 1
    height: 1
    width: 1
  }
}
layer {
  name: "data"
  type: "Concat"
  bottom: "s1_data"
  bottom: "s2_data"
  bottom: "t_data"
  top: "data"
  include {
    phase: TRAIN
  }
  concat_param {
    concat_dim: 0
  }
}
layer {
  name: "label"
  type: "Concat"
  bottom: "s1_label"
  bottom: "s2_label"
  top: "label"
  include {
    phase: TRAIN
  }
  concat_param {
    concat_dim: 0
  }
}
layer {
  name: "concat_domain_labels"
  type: "Concat"
  bottom: "source_domain_labels"
  bottom: "target_domain_labels"
  top: "domain_labels"
  include {
    phase: TRAIN
  }
  concat_param {
    concat_dim: 0
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "slicer_fc6"
  type: "Slice"
  bottom: "fc6"
  top: "fc6_source"
  top: "fc6_target"
  include {
    phase: TRAIN
  }
  slice_param {
    slice_point: 256
    axis: 0
  }
}
layer {
  name: "fc6_source/bn"
  type: "BatchNorm"
  bottom: "fc6_source"
  top: "fc6_source/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    moving_average_fraction: 0.95
  }
}
layer {
  name: "fc6_target/bn"
  type: "BatchNorm"
  bottom: "fc6_target"
  top: "fc6_target/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    moving_average_fraction: 0.95
  }
}
layer {
  name: "concat_wbn_6"
  type: "Concat"
  bottom: "fc6_source/bn"
  bottom: "fc6_target/bn"
  top: "fc6/bn"
  include {
    phase: TRAIN
  }
  concat_param {
    axis: 0
  }
}
layer {
  name: "fc6_scale"
  type: "Scale"
  bottom: "fc6/bn"
  top: "fc6/scale"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    axis: 1
    num_axes: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6/scale"
  top: "fc6/relu"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6/relu"
  top: "fc6/out"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6/out"
  top: "fc7"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "slicer_fc7"
  type: "Slice"
  bottom: "fc7"
  top: "fc7_source"
  top: "fc7_target"
  include {
    phase: TRAIN
  }
  slice_param {
    slice_point: 256
    axis: 0
  }
}
layer {
  name: "fc7_source/bn"
  type: "BatchNorm"
  bottom: "fc7_source"
  top: "fc7_source/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    moving_average_fraction: 0.95
  }
}
layer {
  name: "fc7_target/bn"
  type: "BatchNorm"
  bottom: "fc7_target"
  top: "fc7_target/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    moving_average_fraction: 0.95
  }
}
layer {
  name: "concat_wbn_7"
  type: "Concat"
  bottom: "fc7_source/bn"
  bottom: "fc7_target/bn"
  top: "fc7/bn"
  include {
    phase: TRAIN
  }
  concat_param {
    axis: 0
  }
}
layer {
  name: "fc7_scale"
  type: "Scale"
  bottom: "fc7/bn"
  top: "fc7/scale"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    axis: 1
    num_axes: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7/scale"
  top: "fc7/relu"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7/relu"
  top: "fc7/out"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "bottleneck"
  type: "InnerProduct"
  bottom: "fc7/out"
  top: "bottleneck"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "slicer_bottle"
  type: "Slice"
  bottom: "bottleneck"
  top: "bottleneck_source"
  top: "bottleneck_target"
  include {
    phase: TRAIN
  }
  slice_param {
    slice_point: 256
    axis: 0
  }
}
layer {
  name: "silence_target_feature"
  type: "Silence"
  bottom: "bottleneck_target"
  include {
    phase: TRAIN
  }
}
layer {
  name: "grl"
  type: "GradientScaler"
  bottom: "bottleneck_source"
  top: "grl"
  include {
    phase: TRAIN
  }
  gradient_scaler_param {
    lower_bound: 0.7
    upper_bound: 1
    alpha: 10
    max_iter: 1000
  }
}
layer {
  name: "dc_ip1"
  type: "InnerProduct"
  bottom: "grl"
  top: "dc_ip1"
  param {
    lr_mult: 10
  }
  param {
    lr_mult: 20
  }
  include {
    phase: TRAIN
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "dc_relu1"
  type: "ReLU"
  bottom: "dc_ip1"
  top: "dc_ip1"
  include {
    phase: TRAIN
  }
}
layer {
  name: "dc_drop1"
  type: "Dropout"
  bottom: "dc_ip1"
  top: "dc_ip1"
  include {
    phase: TRAIN
  }
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "dc_ip2"
  type: "InnerProduct"
  bottom: "dc_ip1"
  top: "dc_ip2"
  param {
    lr_mult: 10
  }
  param {
    lr_mult: 20
  }
  include {
    phase: TRAIN
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "dc_relu2"
  type: "ReLU"
  bottom: "dc_ip2"
  top: "dc_ip2"
  include {
    phase: TRAIN
  }
}
layer {
  name: "dc_drop2"
  type: "Dropout"
  bottom: "dc_ip2"
  top: "dc_ip2"
  include {
    phase: TRAIN
  }
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "dc_ip3"
  type: "InnerProduct"
  bottom: "dc_ip2"
  top: "dc_ip3"
  param {
    lr_mult: 10
  }
  param {
    lr_mult: 20
  }
  include {
    phase: TRAIN
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.3
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "dc_loss"
  type: "SigmoidCrossEntropyLoss"
  bottom: "dc_ip3"
  bottom: "domain_labels"
  top: "dc_loss"
  loss_weight: 0.3
  include {
    phase: TRAIN
  }
}
layer {
  name: "dc_accuracy"
  type: "Accuracy"
  bottom: "dc_ip3"
  bottom: "domain_labels"
  top: "domain_accuracy"
  include {
    phase: TRAIN
  }
}
layer {
  name: "office-fc8"
  type: "InnerProduct"
  bottom: "bottleneck"
  top: "fc8"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 31
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "slicer_fc8"
  type: "Slice"
  bottom: "fc8"
  top: "fc8_source"
  top: "fc8_target"
  include {
    phase: TRAIN
  }
  slice_param {
    slice_point: 256
    axis: 0
  }
}
layer {
  name: "fc8_source/bn"
  type: "BatchNorm"
  bottom: "fc8_source"
  top: "fc8_source/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    moving_average_fraction: 0.95
  }
}
layer {
  name: "fc8_target/bn"
  type: "BatchNorm"
  bottom: "fc8_target"
  top: "fc8_target/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    moving_average_fraction: 0.95
  }
}
layer {
  name: "concat_wbn_8"
  type: "Concat"
  bottom: "fc8_source/bn"
  bottom: "fc8_target/bn"
  top: "fc8/bn"
  include {
    phase: TRAIN
  }
  concat_param {
    axis: 0
  }
}
layer {
  name: "fc8_scale"
  type: "Scale"
  bottom: "fc8/bn"
  top: "fc8/scale"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    axis: 1
    num_axes: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "slicer_scorer"
  type: "Slice"
  bottom: "fc8/scale"
  top: "score_source"
  top: "score_target"
  include {
    phase: TRAIN
  }
  slice_param {
    slice_point: 256
    axis: 0
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score_source"
  bottom: "label"
  top: "loss"
  loss_weight: 1
  include {
    phase: TRAIN
  }
}
layer {
  name: "entropy"
  type: "EntropyLoss"
  bottom: "score_target"
  top: "entropy"
  loss_weight: 0.8
  include {
    phase: TRAIN
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score_source"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TRAIN
  }
}
layer {
  name: "silence_target"
  type: "Silence"
  bottom: "t_label"
  include {
    phase: TRAIN
  }
}
I0829 16:18:15.008397 16790 layer_factory.hpp:77] Creating layer s1_data
I0829 16:18:15.008421 16790 net.cpp:84] Creating Layer s1_data
I0829 16:18:15.008430 16790 net.cpp:380] s1_data -> s1_data
I0829 16:18:15.008447 16790 net.cpp:380] s1_data -> s1_label
I0829 16:18:15.008733 16790 image_data_layer.cpp:38] Opening file /home/alfa/Documents/msda/mywork/data/office/office_a.txt
I0829 16:18:15.010069 16790 image_data_layer.cpp:53] Shuffling data
I0829 16:18:15.010526 16790 image_data_layer.cpp:63] A total of 2817 images.
I0829 16:18:15.016443 16790 image_data_layer.cpp:90] output data size: 128,3,227,227
I0829 16:18:15.130096 16790 net.cpp:122] Setting up s1_data
I0829 16:18:15.130122 16790 net.cpp:129] Top shape: 128 3 227 227 (19787136)
I0829 16:18:15.130127 16790 net.cpp:129] Top shape: 128 (128)
I0829 16:18:15.130131 16790 net.cpp:137] Memory required for data: 79149056
I0829 16:18:15.130138 16790 layer_factory.hpp:77] Creating layer s2_data
I0829 16:18:15.130157 16790 net.cpp:84] Creating Layer s2_data
I0829 16:18:15.130165 16790 net.cpp:380] s2_data -> s2_data
I0829 16:18:15.130175 16790 net.cpp:380] s2_data -> s2_label
I0829 16:18:15.130187 16790 image_data_layer.cpp:38] Opening file /home/alfa/Documents/msda/mywork/data/office/office_w.txt
I0829 16:18:15.130578 16790 image_data_layer.cpp:53] Shuffling data
I0829 16:18:15.130707 16790 image_data_layer.cpp:63] A total of 795 images.
I0829 16:18:15.138214 16790 image_data_layer.cpp:90] output data size: 128,3,227,227
I0829 16:18:15.254525 16790 net.cpp:122] Setting up s2_data
I0829 16:18:15.254549 16790 net.cpp:129] Top shape: 128 3 227 227 (19787136)
I0829 16:18:15.254552 16790 net.cpp:129] Top shape: 128 (128)
I0829 16:18:15.254555 16790 net.cpp:137] Memory required for data: 158298112
I0829 16:18:15.254561 16790 layer_factory.hpp:77] Creating layer target_data
I0829 16:18:15.254581 16790 net.cpp:84] Creating Layer target_data
I0829 16:18:15.254590 16790 net.cpp:380] target_data -> t_data
I0829 16:18:15.254600 16790 net.cpp:380] target_data -> t_label
I0829 16:18:15.254611 16790 image_data_layer.cpp:38] Opening file /home/alfa/Documents/msda/mywork/data/office/office_d.txt
I0829 16:18:15.254827 16790 image_data_layer.cpp:53] Shuffling data
I0829 16:18:15.254909 16790 image_data_layer.cpp:63] A total of 498 images.
I0829 16:18:15.264140 16790 image_data_layer.cpp:90] output data size: 128,3,227,227
I0829 16:18:15.380978 16790 net.cpp:122] Setting up target_data
I0829 16:18:15.381005 16790 net.cpp:129] Top shape: 128 3 227 227 (19787136)
I0829 16:18:15.381011 16790 net.cpp:129] Top shape: 128 (128)
I0829 16:18:15.381014 16790 net.cpp:137] Memory required for data: 237447168
I0829 16:18:15.381022 16790 layer_factory.hpp:77] Creating layer source_domain_labels
I0829 16:18:15.381040 16790 net.cpp:84] Creating Layer source_domain_labels
I0829 16:18:15.381049 16790 net.cpp:380] source_domain_labels -> source_domain_labels
I0829 16:18:15.381137 16790 net.cpp:122] Setting up source_domain_labels
I0829 16:18:15.381146 16790 net.cpp:129] Top shape: 128 1 1 1 (128)
I0829 16:18:15.381151 16790 net.cpp:137] Memory required for data: 237447680
I0829 16:18:15.381156 16790 layer_factory.hpp:77] Creating layer target_domain_labels
I0829 16:18:15.381170 16790 net.cpp:84] Creating Layer target_domain_labels
I0829 16:18:15.381178 16790 net.cpp:380] target_domain_labels -> target_domain_labels
I0829 16:18:15.381224 16790 net.cpp:122] Setting up target_domain_labels
I0829 16:18:15.381254 16790 net.cpp:129] Top shape: 128 1 1 1 (128)
I0829 16:18:15.381270 16790 net.cpp:137] Memory required for data: 237448192
I0829 16:18:15.381286 16790 layer_factory.hpp:77] Creating layer data
I0829 16:18:15.381310 16790 net.cpp:84] Creating Layer data
I0829 16:18:15.381320 16790 net.cpp:406] data <- s1_data
I0829 16:18:15.381335 16790 net.cpp:406] data <- s2_data
I0829 16:18:15.381342 16790 net.cpp:406] data <- t_data
I0829 16:18:15.381381 16790 net.cpp:380] data -> data
I0829 16:18:15.381433 16790 net.cpp:122] Setting up data
I0829 16:18:15.381458 16790 net.cpp:129] Top shape: 384 3 227 227 (59361408)
I0829 16:18:15.381475 16790 net.cpp:137] Memory required for data: 474893824
I0829 16:18:15.381491 16790 layer_factory.hpp:77] Creating layer label
I0829 16:18:15.381511 16790 net.cpp:84] Creating Layer label
I0829 16:18:15.381518 16790 net.cpp:406] label <- s1_label
I0829 16:18:15.381525 16790 net.cpp:406] label <- s2_label
I0829 16:18:15.381534 16790 net.cpp:380] label -> label
I0829 16:18:15.381569 16790 net.cpp:122] Setting up label
I0829 16:18:15.381582 16790 net.cpp:129] Top shape: 256 (256)
I0829 16:18:15.381587 16790 net.cpp:137] Memory required for data: 474894848
I0829 16:18:15.381593 16790 layer_factory.hpp:77] Creating layer label_label_0_split
I0829 16:18:15.381609 16790 net.cpp:84] Creating Layer label_label_0_split
I0829 16:18:15.381633 16790 net.cpp:406] label_label_0_split <- label
I0829 16:18:15.381659 16790 net.cpp:380] label_label_0_split -> label_label_0_split_0
I0829 16:18:15.381683 16790 net.cpp:380] label_label_0_split -> label_label_0_split_1
I0829 16:18:15.381736 16790 net.cpp:122] Setting up label_label_0_split
I0829 16:18:15.381749 16790 net.cpp:129] Top shape: 256 (256)
I0829 16:18:15.381755 16790 net.cpp:129] Top shape: 256 (256)
I0829 16:18:15.381760 16790 net.cpp:137] Memory required for data: 474896896
I0829 16:18:15.381765 16790 layer_factory.hpp:77] Creating layer concat_domain_labels
I0829 16:18:15.381778 16790 net.cpp:84] Creating Layer concat_domain_labels
I0829 16:18:15.381783 16790 net.cpp:406] concat_domain_labels <- source_domain_labels
I0829 16:18:15.381793 16790 net.cpp:406] concat_domain_labels <- target_domain_labels
I0829 16:18:15.381821 16790 net.cpp:380] concat_domain_labels -> domain_labels
I0829 16:18:15.381866 16790 net.cpp:122] Setting up concat_domain_labels
I0829 16:18:15.381876 16790 net.cpp:129] Top shape: 256 1 1 1 (256)
I0829 16:18:15.381880 16790 net.cpp:137] Memory required for data: 474897920
I0829 16:18:15.381886 16790 layer_factory.hpp:77] Creating layer domain_labels_concat_domain_labels_0_split
I0829 16:18:15.381894 16790 net.cpp:84] Creating Layer domain_labels_concat_domain_labels_0_split
I0829 16:18:15.381899 16790 net.cpp:406] domain_labels_concat_domain_labels_0_split <- domain_labels
I0829 16:18:15.381909 16790 net.cpp:380] domain_labels_concat_domain_labels_0_split -> domain_labels_concat_domain_labels_0_split_0
I0829 16:18:15.381920 16790 net.cpp:380] domain_labels_concat_domain_labels_0_split -> domain_labels_concat_domain_labels_0_split_1
I0829 16:18:15.381979 16790 net.cpp:122] Setting up domain_labels_concat_domain_labels_0_split
I0829 16:18:15.381990 16790 net.cpp:129] Top shape: 256 1 1 1 (256)
I0829 16:18:15.381996 16790 net.cpp:129] Top shape: 256 1 1 1 (256)
I0829 16:18:15.382001 16790 net.cpp:137] Memory required for data: 474899968
I0829 16:18:15.382006 16790 layer_factory.hpp:77] Creating layer conv1
I0829 16:18:15.382023 16790 net.cpp:84] Creating Layer conv1
I0829 16:18:15.382048 16790 net.cpp:406] conv1 <- data
I0829 16:18:15.382073 16790 net.cpp:380] conv1 -> conv1
I0829 16:18:15.870782 16790 net.cpp:122] Setting up conv1
I0829 16:18:15.870807 16790 net.cpp:129] Top shape: 384 96 55 55 (111513600)
I0829 16:18:15.870812 16790 net.cpp:137] Memory required for data: 920954368
I0829 16:18:15.870831 16790 layer_factory.hpp:77] Creating layer relu1
I0829 16:18:15.870839 16790 net.cpp:84] Creating Layer relu1
I0829 16:18:15.870844 16790 net.cpp:406] relu1 <- conv1
I0829 16:18:15.870851 16790 net.cpp:367] relu1 -> conv1 (in-place)
I0829 16:18:15.871019 16790 net.cpp:122] Setting up relu1
I0829 16:18:15.871028 16790 net.cpp:129] Top shape: 384 96 55 55 (111513600)
I0829 16:18:15.871031 16790 net.cpp:137] Memory required for data: 1367008768
I0829 16:18:15.871035 16790 layer_factory.hpp:77] Creating layer pool1
I0829 16:18:15.871042 16790 net.cpp:84] Creating Layer pool1
I0829 16:18:15.871045 16790 net.cpp:406] pool1 <- conv1
I0829 16:18:15.871050 16790 net.cpp:380] pool1 -> pool1
I0829 16:18:15.871107 16790 net.cpp:122] Setting up pool1
I0829 16:18:15.871129 16790 net.cpp:129] Top shape: 384 96 27 27 (26873856)
I0829 16:18:15.871132 16790 net.cpp:137] Memory required for data: 1474504192
I0829 16:18:15.871135 16790 layer_factory.hpp:77] Creating layer norm1
I0829 16:18:15.871145 16790 net.cpp:84] Creating Layer norm1
I0829 16:18:15.871150 16790 net.cpp:406] norm1 <- pool1
I0829 16:18:15.871155 16790 net.cpp:380] norm1 -> norm1
I0829 16:18:15.871330 16790 net.cpp:122] Setting up norm1
I0829 16:18:15.871340 16790 net.cpp:129] Top shape: 384 96 27 27 (26873856)
I0829 16:18:15.871343 16790 net.cpp:137] Memory required for data: 1581999616
I0829 16:18:15.871346 16790 layer_factory.hpp:77] Creating layer conv2
I0829 16:18:15.871356 16790 net.cpp:84] Creating Layer conv2
I0829 16:18:15.871362 16790 net.cpp:406] conv2 <- norm1
I0829 16:18:15.871368 16790 net.cpp:380] conv2 -> conv2
I0829 16:18:15.880234 16790 net.cpp:122] Setting up conv2
I0829 16:18:15.880254 16790 net.cpp:129] Top shape: 384 256 27 27 (71663616)
I0829 16:18:15.880259 16790 net.cpp:137] Memory required for data: 1868654080
I0829 16:18:15.880271 16790 layer_factory.hpp:77] Creating layer relu2
I0829 16:18:15.880282 16790 net.cpp:84] Creating Layer relu2
I0829 16:18:15.880290 16790 net.cpp:406] relu2 <- conv2
I0829 16:18:15.880296 16790 net.cpp:367] relu2 -> conv2 (in-place)
I0829 16:18:15.880797 16790 net.cpp:122] Setting up relu2
I0829 16:18:15.880808 16790 net.cpp:129] Top shape: 384 256 27 27 (71663616)
I0829 16:18:15.880811 16790 net.cpp:137] Memory required for data: 2155308544
I0829 16:18:15.880816 16790 layer_factory.hpp:77] Creating layer pool2
I0829 16:18:15.880827 16790 net.cpp:84] Creating Layer pool2
I0829 16:18:15.880832 16790 net.cpp:406] pool2 <- conv2
I0829 16:18:15.880839 16790 net.cpp:380] pool2 -> pool2
I0829 16:18:15.880885 16790 net.cpp:122] Setting up pool2
I0829 16:18:15.880892 16790 net.cpp:129] Top shape: 384 256 13 13 (16613376)
I0829 16:18:15.880895 16790 net.cpp:137] Memory required for data: 2221762048
I0829 16:18:15.880899 16790 layer_factory.hpp:77] Creating layer norm2
I0829 16:18:15.880906 16790 net.cpp:84] Creating Layer norm2
I0829 16:18:15.880909 16790 net.cpp:406] norm2 <- pool2
I0829 16:18:15.880914 16790 net.cpp:380] norm2 -> norm2
I0829 16:18:15.881079 16790 net.cpp:122] Setting up norm2
I0829 16:18:15.881088 16790 net.cpp:129] Top shape: 384 256 13 13 (16613376)
I0829 16:18:15.881091 16790 net.cpp:137] Memory required for data: 2288215552
I0829 16:18:15.881095 16790 layer_factory.hpp:77] Creating layer conv3
I0829 16:18:15.881105 16790 net.cpp:84] Creating Layer conv3
I0829 16:18:15.881111 16790 net.cpp:406] conv3 <- norm2
I0829 16:18:15.881117 16790 net.cpp:380] conv3 -> conv3
I0829 16:18:15.889767 16790 net.cpp:122] Setting up conv3
I0829 16:18:15.889788 16790 net.cpp:129] Top shape: 384 384 13 13 (24920064)
I0829 16:18:15.889793 16790 net.cpp:137] Memory required for data: 2387895808
I0829 16:18:15.889806 16790 layer_factory.hpp:77] Creating layer relu3
I0829 16:18:15.889817 16790 net.cpp:84] Creating Layer relu3
I0829 16:18:15.889823 16790 net.cpp:406] relu3 <- conv3
I0829 16:18:15.889832 16790 net.cpp:367] relu3 -> conv3 (in-place)
I0829 16:18:15.889982 16790 net.cpp:122] Setting up relu3
I0829 16:18:15.889991 16790 net.cpp:129] Top shape: 384 384 13 13 (24920064)
I0829 16:18:15.889994 16790 net.cpp:137] Memory required for data: 2487576064
I0829 16:18:15.889998 16790 layer_factory.hpp:77] Creating layer conv4
I0829 16:18:15.890009 16790 net.cpp:84] Creating Layer conv4
I0829 16:18:15.890014 16790 net.cpp:406] conv4 <- conv3
I0829 16:18:15.890020 16790 net.cpp:380] conv4 -> conv4
I0829 16:18:15.899458 16790 net.cpp:122] Setting up conv4
I0829 16:18:15.899479 16790 net.cpp:129] Top shape: 384 384 13 13 (24920064)
I0829 16:18:15.899482 16790 net.cpp:137] Memory required for data: 2587256320
I0829 16:18:15.899492 16790 layer_factory.hpp:77] Creating layer relu4
I0829 16:18:15.899500 16790 net.cpp:84] Creating Layer relu4
I0829 16:18:15.899505 16790 net.cpp:406] relu4 <- conv4
I0829 16:18:15.899511 16790 net.cpp:367] relu4 -> conv4 (in-place)
I0829 16:18:15.906146 16790 net.cpp:122] Setting up relu4
I0829 16:18:15.906165 16790 net.cpp:129] Top shape: 384 384 13 13 (24920064)
I0829 16:18:15.906169 16790 net.cpp:137] Memory required for data: 2686936576
I0829 16:18:15.906174 16790 layer_factory.hpp:77] Creating layer conv5
I0829 16:18:15.906189 16790 net.cpp:84] Creating Layer conv5
I0829 16:18:15.906196 16790 net.cpp:406] conv5 <- conv4
I0829 16:18:15.906205 16790 net.cpp:380] conv5 -> conv5
I0829 16:18:15.912242 16790 net.cpp:122] Setting up conv5
I0829 16:18:15.912263 16790 net.cpp:129] Top shape: 384 256 13 13 (16613376)
I0829 16:18:15.912267 16790 net.cpp:137] Memory required for data: 2753390080
I0829 16:18:15.912281 16790 layer_factory.hpp:77] Creating layer relu5
I0829 16:18:15.912290 16790 net.cpp:84] Creating Layer relu5
I0829 16:18:15.912297 16790 net.cpp:406] relu5 <- conv5
I0829 16:18:15.912303 16790 net.cpp:367] relu5 -> conv5 (in-place)
I0829 16:18:15.912456 16790 net.cpp:122] Setting up relu5
I0829 16:18:15.912464 16790 net.cpp:129] Top shape: 384 256 13 13 (16613376)
I0829 16:18:15.912467 16790 net.cpp:137] Memory required for data: 2819843584
I0829 16:18:15.912472 16790 layer_factory.hpp:77] Creating layer pool5
I0829 16:18:15.912478 16790 net.cpp:84] Creating Layer pool5
I0829 16:18:15.912483 16790 net.cpp:406] pool5 <- conv5
I0829 16:18:15.912489 16790 net.cpp:380] pool5 -> pool5
I0829 16:18:15.912529 16790 net.cpp:122] Setting up pool5
I0829 16:18:15.912536 16790 net.cpp:129] Top shape: 384 256 6 6 (3538944)
I0829 16:18:15.912539 16790 net.cpp:137] Memory required for data: 2833999360
I0829 16:18:15.912542 16790 layer_factory.hpp:77] Creating layer fc6
I0829 16:18:15.912551 16790 net.cpp:84] Creating Layer fc6
I0829 16:18:15.912557 16790 net.cpp:406] fc6 <- pool5
I0829 16:18:15.912564 16790 net.cpp:380] fc6 -> fc6
I0829 16:18:16.200742 16790 net.cpp:122] Setting up fc6
I0829 16:18:16.200764 16790 net.cpp:129] Top shape: 384 4096 (1572864)
I0829 16:18:16.200767 16790 net.cpp:137] Memory required for data: 2840290816
I0829 16:18:16.200775 16790 layer_factory.hpp:77] Creating layer slicer_fc6
I0829 16:18:16.200788 16790 net.cpp:84] Creating Layer slicer_fc6
I0829 16:18:16.200793 16790 net.cpp:406] slicer_fc6 <- fc6
I0829 16:18:16.200800 16790 net.cpp:380] slicer_fc6 -> fc6_source
I0829 16:18:16.200810 16790 net.cpp:380] slicer_fc6 -> fc6_target
I0829 16:18:16.200844 16790 net.cpp:122] Setting up slicer_fc6
I0829 16:18:16.200851 16790 net.cpp:129] Top shape: 256 4096 (1048576)
I0829 16:18:16.200855 16790 net.cpp:129] Top shape: 128 4096 (524288)
I0829 16:18:16.200858 16790 net.cpp:137] Memory required for data: 2846582272
I0829 16:18:16.200861 16790 layer_factory.hpp:77] Creating layer fc6_source/bn
I0829 16:18:16.200870 16790 net.cpp:84] Creating Layer fc6_source/bn
I0829 16:18:16.200873 16790 net.cpp:406] fc6_source/bn <- fc6_source
I0829 16:18:16.200879 16790 net.cpp:380] fc6_source/bn -> fc6_source/bn
I0829 16:18:16.201033 16790 net.cpp:122] Setting up fc6_source/bn
I0829 16:18:16.201041 16790 net.cpp:129] Top shape: 256 4096 (1048576)
I0829 16:18:16.201045 16790 net.cpp:137] Memory required for data: 2850776576
I0829 16:18:16.201051 16790 layer_factory.hpp:77] Creating layer fc6_target/bn
I0829 16:18:16.201057 16790 net.cpp:84] Creating Layer fc6_target/bn
I0829 16:18:16.201061 16790 net.cpp:406] fc6_target/bn <- fc6_target
I0829 16:18:16.201066 16790 net.cpp:380] fc6_target/bn -> fc6_target/bn
I0829 16:18:16.201211 16790 net.cpp:122] Setting up fc6_target/bn
I0829 16:18:16.201218 16790 net.cpp:129] Top shape: 128 4096 (524288)
I0829 16:18:16.201223 16790 net.cpp:137] Memory required for data: 2852873728
I0829 16:18:16.201233 16790 layer_factory.hpp:77] Creating layer concat_wbn_6
I0829 16:18:16.201241 16790 net.cpp:84] Creating Layer concat_wbn_6
I0829 16:18:16.201244 16790 net.cpp:406] concat_wbn_6 <- fc6_source/bn
I0829 16:18:16.201248 16790 net.cpp:406] concat_wbn_6 <- fc6_target/bn
I0829 16:18:16.201253 16790 net.cpp:380] concat_wbn_6 -> fc6/bn
I0829 16:18:16.201270 16790 net.cpp:122] Setting up concat_wbn_6
I0829 16:18:16.201293 16790 net.cpp:129] Top shape: 384 4096 (1572864)
I0829 16:18:16.201297 16790 net.cpp:137] Memory required for data: 2859165184
I0829 16:18:16.201300 16790 layer_factory.hpp:77] Creating layer fc6_scale
I0829 16:18:16.201308 16790 net.cpp:84] Creating Layer fc6_scale
I0829 16:18:16.201311 16790 net.cpp:406] fc6_scale <- fc6/bn
I0829 16:18:16.201318 16790 net.cpp:380] fc6_scale -> fc6/scale
I0829 16:18:16.201352 16790 layer_factory.hpp:77] Creating layer fc6_scale
I0829 16:18:16.201447 16790 net.cpp:122] Setting up fc6_scale
I0829 16:18:16.201454 16790 net.cpp:129] Top shape: 384 4096 (1572864)
I0829 16:18:16.201457 16790 net.cpp:137] Memory required for data: 2865456640
I0829 16:18:16.201462 16790 layer_factory.hpp:77] Creating layer relu6
I0829 16:18:16.201468 16790 net.cpp:84] Creating Layer relu6
I0829 16:18:16.201472 16790 net.cpp:406] relu6 <- fc6/scale
I0829 16:18:16.201478 16790 net.cpp:380] relu6 -> fc6/relu
I0829 16:18:16.201704 16790 net.cpp:122] Setting up relu6
I0829 16:18:16.201712 16790 net.cpp:129] Top shape: 384 4096 (1572864)
I0829 16:18:16.201715 16790 net.cpp:137] Memory required for data: 2871748096
I0829 16:18:16.201720 16790 layer_factory.hpp:77] Creating layer drop6
I0829 16:18:16.201730 16790 net.cpp:84] Creating Layer drop6
I0829 16:18:16.201733 16790 net.cpp:406] drop6 <- fc6/relu
I0829 16:18:16.201738 16790 net.cpp:380] drop6 -> fc6/out
I0829 16:18:16.201774 16790 net.cpp:122] Setting up drop6
I0829 16:18:16.201781 16790 net.cpp:129] Top shape: 384 4096 (1572864)
I0829 16:18:16.201784 16790 net.cpp:137] Memory required for data: 2878039552
I0829 16:18:16.201788 16790 layer_factory.hpp:77] Creating layer fc7
I0829 16:18:16.201797 16790 net.cpp:84] Creating Layer fc7
I0829 16:18:16.201800 16790 net.cpp:406] fc7 <- fc6/out
I0829 16:18:16.201805 16790 net.cpp:380] fc7 -> fc7
I0829 16:18:16.333298 16790 net.cpp:122] Setting up fc7
I0829 16:18:16.333324 16790 net.cpp:129] Top shape: 384 4096 (1572864)
I0829 16:18:16.333328 16790 net.cpp:137] Memory required for data: 2884331008
I0829 16:18:16.333338 16790 layer_factory.hpp:77] Creating layer slicer_fc7
I0829 16:18:16.333351 16790 net.cpp:84] Creating Layer slicer_fc7
I0829 16:18:16.333358 16790 net.cpp:406] slicer_fc7 <- fc7
I0829 16:18:16.333365 16790 net.cpp:380] slicer_fc7 -> fc7_source
I0829 16:18:16.333375 16790 net.cpp:380] slicer_fc7 -> fc7_target
I0829 16:18:16.333412 16790 net.cpp:122] Setting up slicer_fc7
I0829 16:18:16.333420 16790 net.cpp:129] Top shape: 256 4096 (1048576)
I0829 16:18:16.333425 16790 net.cpp:129] Top shape: 128 4096 (524288)
I0829 16:18:16.333428 16790 net.cpp:137] Memory required for data: 2890622464
I0829 16:18:16.333433 16790 layer_factory.hpp:77] Creating layer fc7_source/bn
I0829 16:18:16.333441 16790 net.cpp:84] Creating Layer fc7_source/bn
I0829 16:18:16.333446 16790 net.cpp:406] fc7_source/bn <- fc7_source
I0829 16:18:16.333452 16790 net.cpp:380] fc7_source/bn -> fc7_source/bn
I0829 16:18:16.333606 16790 net.cpp:122] Setting up fc7_source/bn
I0829 16:18:16.333616 16790 net.cpp:129] Top shape: 256 4096 (1048576)
I0829 16:18:16.333619 16790 net.cpp:137] Memory required for data: 2894816768
I0829 16:18:16.333627 16790 layer_factory.hpp:77] Creating layer fc7_target/bn
I0829 16:18:16.333633 16790 net.cpp:84] Creating Layer fc7_target/bn
I0829 16:18:16.333637 16790 net.cpp:406] fc7_target/bn <- fc7_target
I0829 16:18:16.333642 16790 net.cpp:380] fc7_target/bn -> fc7_target/bn
I0829 16:18:16.333789 16790 net.cpp:122] Setting up fc7_target/bn
I0829 16:18:16.333797 16790 net.cpp:129] Top shape: 128 4096 (524288)
I0829 16:18:16.333802 16790 net.cpp:137] Memory required for data: 2896913920
I0829 16:18:16.333809 16790 layer_factory.hpp:77] Creating layer concat_wbn_7
I0829 16:18:16.333817 16790 net.cpp:84] Creating Layer concat_wbn_7
I0829 16:18:16.333822 16790 net.cpp:406] concat_wbn_7 <- fc7_source/bn
I0829 16:18:16.333827 16790 net.cpp:406] concat_wbn_7 <- fc7_target/bn
I0829 16:18:16.333830 16790 net.cpp:380] concat_wbn_7 -> fc7/bn
I0829 16:18:16.333848 16790 net.cpp:122] Setting up concat_wbn_7
I0829 16:18:16.333873 16790 net.cpp:129] Top shape: 384 4096 (1572864)
I0829 16:18:16.333876 16790 net.cpp:137] Memory required for data: 2903205376
I0829 16:18:16.333880 16790 layer_factory.hpp:77] Creating layer fc7_scale
I0829 16:18:16.333887 16790 net.cpp:84] Creating Layer fc7_scale
I0829 16:18:16.333894 16790 net.cpp:406] fc7_scale <- fc7/bn
I0829 16:18:16.333899 16790 net.cpp:380] fc7_scale -> fc7/scale
I0829 16:18:16.333933 16790 layer_factory.hpp:77] Creating layer fc7_scale
I0829 16:18:16.334022 16790 net.cpp:122] Setting up fc7_scale
I0829 16:18:16.334029 16790 net.cpp:129] Top shape: 384 4096 (1572864)
I0829 16:18:16.334034 16790 net.cpp:137] Memory required for data: 2909496832
I0829 16:18:16.334039 16790 layer_factory.hpp:77] Creating layer relu7
I0829 16:18:16.334046 16790 net.cpp:84] Creating Layer relu7
I0829 16:18:16.334049 16790 net.cpp:406] relu7 <- fc7/scale
I0829 16:18:16.334055 16790 net.cpp:380] relu7 -> fc7/relu
I0829 16:18:16.334800 16790 net.cpp:122] Setting up relu7
I0829 16:18:16.334812 16790 net.cpp:129] Top shape: 384 4096 (1572864)
I0829 16:18:16.334816 16790 net.cpp:137] Memory required for data: 2915788288
I0829 16:18:16.334821 16790 layer_factory.hpp:77] Creating layer drop7
I0829 16:18:16.334830 16790 net.cpp:84] Creating Layer drop7
I0829 16:18:16.334832 16790 net.cpp:406] drop7 <- fc7/relu
I0829 16:18:16.334838 16790 net.cpp:380] drop7 -> fc7/out
I0829 16:18:16.334873 16790 net.cpp:122] Setting up drop7
I0829 16:18:16.334880 16790 net.cpp:129] Top shape: 384 4096 (1572864)
I0829 16:18:16.334885 16790 net.cpp:137] Memory required for data: 2922079744
I0829 16:18:16.334889 16790 layer_factory.hpp:77] Creating layer bottleneck
I0829 16:18:16.334897 16790 net.cpp:84] Creating Layer bottleneck
I0829 16:18:16.334902 16790 net.cpp:406] bottleneck <- fc7/out
I0829 16:18:16.334906 16790 net.cpp:380] bottleneck -> bottleneck
I0829 16:18:16.347044 16790 net.cpp:122] Setting up bottleneck
I0829 16:18:16.347076 16790 net.cpp:129] Top shape: 384 256 (98304)
I0829 16:18:16.347081 16790 net.cpp:137] Memory required for data: 2922472960
I0829 16:18:16.347092 16790 layer_factory.hpp:77] Creating layer bottleneck_bottleneck_0_split
I0829 16:18:16.347105 16790 net.cpp:84] Creating Layer bottleneck_bottleneck_0_split
I0829 16:18:16.347111 16790 net.cpp:406] bottleneck_bottleneck_0_split <- bottleneck
I0829 16:18:16.347121 16790 net.cpp:380] bottleneck_bottleneck_0_split -> bottleneck_bottleneck_0_split_0
I0829 16:18:16.347132 16790 net.cpp:380] bottleneck_bottleneck_0_split -> bottleneck_bottleneck_0_split_1
I0829 16:18:16.347179 16790 net.cpp:122] Setting up bottleneck_bottleneck_0_split
I0829 16:18:16.347190 16790 net.cpp:129] Top shape: 384 256 (98304)
I0829 16:18:16.347195 16790 net.cpp:129] Top shape: 384 256 (98304)
I0829 16:18:16.347200 16790 net.cpp:137] Memory required for data: 2923259392
I0829 16:18:16.347205 16790 layer_factory.hpp:77] Creating layer slicer_bottle
I0829 16:18:16.347216 16790 net.cpp:84] Creating Layer slicer_bottle
I0829 16:18:16.347221 16790 net.cpp:406] slicer_bottle <- bottleneck_bottleneck_0_split_0
I0829 16:18:16.347229 16790 net.cpp:380] slicer_bottle -> bottleneck_source
I0829 16:18:16.347239 16790 net.cpp:380] slicer_bottle -> bottleneck_target
I0829 16:18:16.347283 16790 net.cpp:122] Setting up slicer_bottle
I0829 16:18:16.347292 16790 net.cpp:129] Top shape: 256 256 (65536)
I0829 16:18:16.347298 16790 net.cpp:129] Top shape: 128 256 (32768)
I0829 16:18:16.347302 16790 net.cpp:137] Memory required for data: 2923652608
I0829 16:18:16.347307 16790 layer_factory.hpp:77] Creating layer silence_target_feature
I0829 16:18:16.347314 16790 net.cpp:84] Creating Layer silence_target_feature
I0829 16:18:16.347319 16790 net.cpp:406] silence_target_feature <- bottleneck_target
I0829 16:18:16.347324 16790 net.cpp:122] Setting up silence_target_feature
I0829 16:18:16.347331 16790 net.cpp:137] Memory required for data: 2923652608
I0829 16:18:16.347334 16790 layer_factory.hpp:77] Creating layer grl
I0829 16:18:16.347342 16790 net.cpp:84] Creating Layer grl
I0829 16:18:16.347347 16790 net.cpp:406] grl <- bottleneck_source
I0829 16:18:16.347376 16790 net.cpp:380] grl -> grl
I0829 16:18:16.347388 16790 messenger.hpp:36] Adding listener for message SOLVER_ITER_CHANGED
I0829 16:18:16.347421 16790 net.cpp:122] Setting up grl
I0829 16:18:16.347430 16790 net.cpp:129] Top shape: 256 256 (65536)
I0829 16:18:16.347435 16790 net.cpp:137] Memory required for data: 2923914752
I0829 16:18:16.347441 16790 layer_factory.hpp:77] Creating layer dc_ip1
I0829 16:18:16.347450 16790 net.cpp:84] Creating Layer dc_ip1
I0829 16:18:16.347455 16790 net.cpp:406] dc_ip1 <- grl
I0829 16:18:16.347463 16790 net.cpp:380] dc_ip1 -> dc_ip1
I0829 16:18:16.351759 16790 net.cpp:122] Setting up dc_ip1
I0829 16:18:16.351783 16790 net.cpp:129] Top shape: 256 1024 (262144)
I0829 16:18:16.351788 16790 net.cpp:137] Memory required for data: 2924963328
I0829 16:18:16.351806 16790 layer_factory.hpp:77] Creating layer dc_relu1
I0829 16:18:16.351820 16790 net.cpp:84] Creating Layer dc_relu1
I0829 16:18:16.351828 16790 net.cpp:406] dc_relu1 <- dc_ip1
I0829 16:18:16.351837 16790 net.cpp:367] dc_relu1 -> dc_ip1 (in-place)
I0829 16:18:16.352110 16790 net.cpp:122] Setting up dc_relu1
I0829 16:18:16.352121 16790 net.cpp:129] Top shape: 256 1024 (262144)
I0829 16:18:16.352125 16790 net.cpp:137] Memory required for data: 2926011904
I0829 16:18:16.352130 16790 layer_factory.hpp:77] Creating layer dc_drop1
I0829 16:18:16.352140 16790 net.cpp:84] Creating Layer dc_drop1
I0829 16:18:16.352145 16790 net.cpp:406] dc_drop1 <- dc_ip1
I0829 16:18:16.352152 16790 net.cpp:367] dc_drop1 -> dc_ip1 (in-place)
I0829 16:18:16.352183 16790 net.cpp:122] Setting up dc_drop1
I0829 16:18:16.352193 16790 net.cpp:129] Top shape: 256 1024 (262144)
I0829 16:18:16.352198 16790 net.cpp:137] Memory required for data: 2927060480
I0829 16:18:16.352202 16790 layer_factory.hpp:77] Creating layer dc_ip2
I0829 16:18:16.352212 16790 net.cpp:84] Creating Layer dc_ip2
I0829 16:18:16.352219 16790 net.cpp:406] dc_ip2 <- dc_ip1
I0829 16:18:16.352228 16790 net.cpp:380] dc_ip2 -> dc_ip2
I0829 16:18:16.365739 16790 net.cpp:122] Setting up dc_ip2
I0829 16:18:16.365772 16790 net.cpp:129] Top shape: 256 1024 (262144)
I0829 16:18:16.365778 16790 net.cpp:137] Memory required for data: 2928109056
I0829 16:18:16.365790 16790 layer_factory.hpp:77] Creating layer dc_relu2
I0829 16:18:16.365804 16790 net.cpp:84] Creating Layer dc_relu2
I0829 16:18:16.365815 16790 net.cpp:406] dc_relu2 <- dc_ip2
I0829 16:18:16.365826 16790 net.cpp:367] dc_relu2 -> dc_ip2 (in-place)
I0829 16:18:16.366122 16790 net.cpp:122] Setting up dc_relu2
I0829 16:18:16.366134 16790 net.cpp:129] Top shape: 256 1024 (262144)
I0829 16:18:16.366139 16790 net.cpp:137] Memory required for data: 2929157632
I0829 16:18:16.366145 16790 layer_factory.hpp:77] Creating layer dc_drop2
I0829 16:18:16.366155 16790 net.cpp:84] Creating Layer dc_drop2
I0829 16:18:16.366163 16790 net.cpp:406] dc_drop2 <- dc_ip2
I0829 16:18:16.366171 16790 net.cpp:367] dc_drop2 -> dc_ip2 (in-place)
I0829 16:18:16.366204 16790 net.cpp:122] Setting up dc_drop2
I0829 16:18:16.366214 16790 net.cpp:129] Top shape: 256 1024 (262144)
I0829 16:18:16.366219 16790 net.cpp:137] Memory required for data: 2930206208
I0829 16:18:16.366225 16790 layer_factory.hpp:77] Creating layer dc_ip3
I0829 16:18:16.366235 16790 net.cpp:84] Creating Layer dc_ip3
I0829 16:18:16.366242 16790 net.cpp:406] dc_ip3 <- dc_ip2
I0829 16:18:16.366250 16790 net.cpp:380] dc_ip3 -> dc_ip3
I0829 16:18:16.366384 16790 net.cpp:122] Setting up dc_ip3
I0829 16:18:16.366395 16790 net.cpp:129] Top shape: 256 1 (256)
I0829 16:18:16.366400 16790 net.cpp:137] Memory required for data: 2930207232
I0829 16:18:16.366407 16790 layer_factory.hpp:77] Creating layer dc_ip3_dc_ip3_0_split
I0829 16:18:16.366415 16790 net.cpp:84] Creating Layer dc_ip3_dc_ip3_0_split
I0829 16:18:16.366421 16790 net.cpp:406] dc_ip3_dc_ip3_0_split <- dc_ip3
I0829 16:18:16.366428 16790 net.cpp:380] dc_ip3_dc_ip3_0_split -> dc_ip3_dc_ip3_0_split_0
I0829 16:18:16.366439 16790 net.cpp:380] dc_ip3_dc_ip3_0_split -> dc_ip3_dc_ip3_0_split_1
I0829 16:18:16.366479 16790 net.cpp:122] Setting up dc_ip3_dc_ip3_0_split
I0829 16:18:16.366504 16790 net.cpp:129] Top shape: 256 1 (256)
I0829 16:18:16.366510 16790 net.cpp:129] Top shape: 256 1 (256)
I0829 16:18:16.366515 16790 net.cpp:137] Memory required for data: 2930209280
I0829 16:18:16.366520 16790 layer_factory.hpp:77] Creating layer dc_loss
I0829 16:18:16.366533 16790 net.cpp:84] Creating Layer dc_loss
I0829 16:18:16.366539 16790 net.cpp:406] dc_loss <- dc_ip3_dc_ip3_0_split_0
I0829 16:18:16.366546 16790 net.cpp:406] dc_loss <- domain_labels_concat_domain_labels_0_split_0
I0829 16:18:16.366556 16790 net.cpp:380] dc_loss -> dc_loss
I0829 16:18:16.366619 16790 net.cpp:122] Setting up dc_loss
I0829 16:18:16.366628 16790 net.cpp:129] Top shape: (1)
I0829 16:18:16.366634 16790 net.cpp:132]     with loss weight 0.3
I0829 16:18:16.366657 16790 net.cpp:137] Memory required for data: 2930209284
I0829 16:18:16.366663 16790 layer_factory.hpp:77] Creating layer dc_accuracy
I0829 16:18:16.366672 16790 net.cpp:84] Creating Layer dc_accuracy
I0829 16:18:16.366677 16790 net.cpp:406] dc_accuracy <- dc_ip3_dc_ip3_0_split_1
I0829 16:18:16.366683 16790 net.cpp:406] dc_accuracy <- domain_labels_concat_domain_labels_0_split_1
I0829 16:18:16.366694 16790 net.cpp:380] dc_accuracy -> domain_accuracy
I0829 16:18:16.366705 16790 net.cpp:122] Setting up dc_accuracy
I0829 16:18:16.366713 16790 net.cpp:129] Top shape: (1)
I0829 16:18:16.366717 16790 net.cpp:137] Memory required for data: 2930209288
I0829 16:18:16.366722 16790 layer_factory.hpp:77] Creating layer office-fc8
I0829 16:18:16.366730 16790 net.cpp:84] Creating Layer office-fc8
I0829 16:18:16.366739 16790 net.cpp:406] office-fc8 <- bottleneck_bottleneck_0_split_1
I0829 16:18:16.366746 16790 net.cpp:380] office-fc8 -> fc8
I0829 16:18:16.368264 16790 net.cpp:122] Setting up office-fc8
I0829 16:18:16.368281 16790 net.cpp:129] Top shape: 384 31 (11904)
I0829 16:18:16.368286 16790 net.cpp:137] Memory required for data: 2930256904
I0829 16:18:16.368296 16790 layer_factory.hpp:77] Creating layer slicer_fc8
I0829 16:18:16.368309 16790 net.cpp:84] Creating Layer slicer_fc8
I0829 16:18:16.368316 16790 net.cpp:406] slicer_fc8 <- fc8
I0829 16:18:16.368325 16790 net.cpp:380] slicer_fc8 -> fc8_source
I0829 16:18:16.368335 16790 net.cpp:380] slicer_fc8 -> fc8_target
I0829 16:18:16.368384 16790 net.cpp:122] Setting up slicer_fc8
I0829 16:18:16.368393 16790 net.cpp:129] Top shape: 256 31 (7936)
I0829 16:18:16.368399 16790 net.cpp:129] Top shape: 128 31 (3968)
I0829 16:18:16.368403 16790 net.cpp:137] Memory required for data: 2930304520
I0829 16:18:16.368408 16790 layer_factory.hpp:77] Creating layer fc8_source/bn
I0829 16:18:16.368418 16790 net.cpp:84] Creating Layer fc8_source/bn
I0829 16:18:16.368425 16790 net.cpp:406] fc8_source/bn <- fc8_source
I0829 16:18:16.368433 16790 net.cpp:380] fc8_source/bn -> fc8_source/bn
I0829 16:18:16.368672 16790 net.cpp:122] Setting up fc8_source/bn
I0829 16:18:16.368682 16790 net.cpp:129] Top shape: 256 31 (7936)
I0829 16:18:16.368687 16790 net.cpp:137] Memory required for data: 2930336264
I0829 16:18:16.368697 16790 layer_factory.hpp:77] Creating layer fc8_target/bn
I0829 16:18:16.368710 16790 net.cpp:84] Creating Layer fc8_target/bn
I0829 16:18:16.368715 16790 net.cpp:406] fc8_target/bn <- fc8_target
I0829 16:18:16.368721 16790 net.cpp:380] fc8_target/bn -> fc8_target/bn
I0829 16:18:16.368950 16790 net.cpp:122] Setting up fc8_target/bn
I0829 16:18:16.368962 16790 net.cpp:129] Top shape: 128 31 (3968)
I0829 16:18:16.368966 16790 net.cpp:137] Memory required for data: 2930352136
I0829 16:18:16.368976 16790 layer_factory.hpp:77] Creating layer concat_wbn_8
I0829 16:18:16.368988 16790 net.cpp:84] Creating Layer concat_wbn_8
I0829 16:18:16.368994 16790 net.cpp:406] concat_wbn_8 <- fc8_source/bn
I0829 16:18:16.369000 16790 net.cpp:406] concat_wbn_8 <- fc8_target/bn
I0829 16:18:16.369007 16790 net.cpp:380] concat_wbn_8 -> fc8/bn
I0829 16:18:16.369035 16790 net.cpp:122] Setting up concat_wbn_8
I0829 16:18:16.369045 16790 net.cpp:129] Top shape: 384 31 (11904)
I0829 16:18:16.369050 16790 net.cpp:137] Memory required for data: 2930399752
I0829 16:18:16.369069 16790 layer_factory.hpp:77] Creating layer fc8_scale
I0829 16:18:16.369079 16790 net.cpp:84] Creating Layer fc8_scale
I0829 16:18:16.369087 16790 net.cpp:406] fc8_scale <- fc8/bn
I0829 16:18:16.369096 16790 net.cpp:380] fc8_scale -> fc8/scale
I0829 16:18:16.369148 16790 layer_factory.hpp:77] Creating layer fc8_scale
I0829 16:18:16.369284 16790 net.cpp:122] Setting up fc8_scale
I0829 16:18:16.369295 16790 net.cpp:129] Top shape: 384 31 (11904)
I0829 16:18:16.369300 16790 net.cpp:137] Memory required for data: 2930447368
I0829 16:18:16.369308 16790 layer_factory.hpp:77] Creating layer slicer_scorer
I0829 16:18:16.369315 16790 net.cpp:84] Creating Layer slicer_scorer
I0829 16:18:16.369325 16790 net.cpp:406] slicer_scorer <- fc8/scale
I0829 16:18:16.369333 16790 net.cpp:380] slicer_scorer -> score_source
I0829 16:18:16.369343 16790 net.cpp:380] slicer_scorer -> score_target
I0829 16:18:16.369400 16790 net.cpp:122] Setting up slicer_scorer
I0829 16:18:16.369410 16790 net.cpp:129] Top shape: 256 31 (7936)
I0829 16:18:16.369416 16790 net.cpp:129] Top shape: 128 31 (3968)
I0829 16:18:16.369421 16790 net.cpp:137] Memory required for data: 2930494984
I0829 16:18:16.369427 16790 layer_factory.hpp:77] Creating layer score_source_slicer_scorer_0_split
I0829 16:18:16.369437 16790 net.cpp:84] Creating Layer score_source_slicer_scorer_0_split
I0829 16:18:16.369442 16790 net.cpp:406] score_source_slicer_scorer_0_split <- score_source
I0829 16:18:16.369451 16790 net.cpp:380] score_source_slicer_scorer_0_split -> score_source_slicer_scorer_0_split_0
I0829 16:18:16.369458 16790 net.cpp:380] score_source_slicer_scorer_0_split -> score_source_slicer_scorer_0_split_1
I0829 16:18:16.369503 16790 net.cpp:122] Setting up score_source_slicer_scorer_0_split
I0829 16:18:16.369513 16790 net.cpp:129] Top shape: 256 31 (7936)
I0829 16:18:16.369519 16790 net.cpp:129] Top shape: 256 31 (7936)
I0829 16:18:16.369524 16790 net.cpp:137] Memory required for data: 2930558472
I0829 16:18:16.369529 16790 layer_factory.hpp:77] Creating layer loss
I0829 16:18:16.369544 16790 net.cpp:84] Creating Layer loss
I0829 16:18:16.369552 16790 net.cpp:406] loss <- score_source_slicer_scorer_0_split_0
I0829 16:18:16.369559 16790 net.cpp:406] loss <- label_label_0_split_0
I0829 16:18:16.369570 16790 net.cpp:380] loss -> loss
I0829 16:18:16.369580 16790 layer_factory.hpp:77] Creating layer loss
I0829 16:18:16.369951 16790 net.cpp:122] Setting up loss
I0829 16:18:16.369961 16790 net.cpp:129] Top shape: (1)
I0829 16:18:16.369967 16790 net.cpp:132]     with loss weight 1
I0829 16:18:16.369982 16790 net.cpp:137] Memory required for data: 2930558476
I0829 16:18:16.369987 16790 layer_factory.hpp:77] Creating layer entropy
I0829 16:18:16.369995 16790 net.cpp:84] Creating Layer entropy
I0829 16:18:16.370003 16790 net.cpp:406] entropy <- score_target
I0829 16:18:16.370012 16790 net.cpp:380] entropy -> entropy
I0829 16:18:16.370021 16790 layer_factory.hpp:77] Creating layer entropy
I0829 16:18:16.370935 16790 net.cpp:122] Setting up entropy
I0829 16:18:16.370951 16790 net.cpp:129] Top shape: (1)
I0829 16:18:16.370955 16790 net.cpp:132]     with loss weight 0.8
I0829 16:18:16.370965 16790 net.cpp:137] Memory required for data: 2930558480
I0829 16:18:16.370970 16790 layer_factory.hpp:77] Creating layer accuracy
I0829 16:18:16.370980 16790 net.cpp:84] Creating Layer accuracy
I0829 16:18:16.370986 16790 net.cpp:406] accuracy <- score_source_slicer_scorer_0_split_1
I0829 16:18:16.370993 16790 net.cpp:406] accuracy <- label_label_0_split_1
I0829 16:18:16.371001 16790 net.cpp:380] accuracy -> accuracy
I0829 16:18:16.371012 16790 net.cpp:122] Setting up accuracy
I0829 16:18:16.371018 16790 net.cpp:129] Top shape: (1)
I0829 16:18:16.371023 16790 net.cpp:137] Memory required for data: 2930558484
I0829 16:18:16.371028 16790 layer_factory.hpp:77] Creating layer silence_target
I0829 16:18:16.371035 16790 net.cpp:84] Creating Layer silence_target
I0829 16:18:16.371040 16790 net.cpp:406] silence_target <- t_label
I0829 16:18:16.371047 16790 net.cpp:122] Setting up silence_target
I0829 16:18:16.371062 16790 net.cpp:137] Memory required for data: 2930558484
I0829 16:18:16.371069 16790 net.cpp:200] silence_target does not need backward computation.
I0829 16:18:16.371079 16790 net.cpp:200] accuracy does not need backward computation.
I0829 16:18:16.371086 16790 net.cpp:198] entropy needs backward computation.
I0829 16:18:16.371093 16790 net.cpp:198] loss needs backward computation.
I0829 16:18:16.371099 16790 net.cpp:198] score_source_slicer_scorer_0_split needs backward computation.
I0829 16:18:16.371104 16790 net.cpp:198] slicer_scorer needs backward computation.
I0829 16:18:16.371110 16790 net.cpp:198] fc8_scale needs backward computation.
I0829 16:18:16.371116 16790 net.cpp:198] concat_wbn_8 needs backward computation.
I0829 16:18:16.371124 16790 net.cpp:198] fc8_target/bn needs backward computation.
I0829 16:18:16.371129 16790 net.cpp:198] fc8_source/bn needs backward computation.
I0829 16:18:16.371136 16790 net.cpp:198] slicer_fc8 needs backward computation.
I0829 16:18:16.371141 16790 net.cpp:198] office-fc8 needs backward computation.
I0829 16:18:16.371147 16790 net.cpp:200] dc_accuracy does not need backward computation.
I0829 16:18:16.371153 16790 net.cpp:198] dc_loss needs backward computation.
I0829 16:18:16.371160 16790 net.cpp:198] dc_ip3_dc_ip3_0_split needs backward computation.
I0829 16:18:16.371165 16790 net.cpp:198] dc_ip3 needs backward computation.
I0829 16:18:16.371171 16790 net.cpp:198] dc_drop2 needs backward computation.
I0829 16:18:16.371177 16790 net.cpp:198] dc_relu2 needs backward computation.
I0829 16:18:16.371181 16790 net.cpp:198] dc_ip2 needs backward computation.
I0829 16:18:16.371187 16790 net.cpp:198] dc_drop1 needs backward computation.
I0829 16:18:16.371196 16790 net.cpp:198] dc_relu1 needs backward computation.
I0829 16:18:16.371201 16790 net.cpp:198] dc_ip1 needs backward computation.
I0829 16:18:16.371206 16790 net.cpp:198] grl needs backward computation.
I0829 16:18:16.371210 16790 net.cpp:200] silence_target_feature does not need backward computation.
I0829 16:18:16.371217 16790 net.cpp:198] slicer_bottle needs backward computation.
I0829 16:18:16.371223 16790 net.cpp:198] bottleneck_bottleneck_0_split needs backward computation.
I0829 16:18:16.371228 16790 net.cpp:198] bottleneck needs backward computation.
I0829 16:18:16.371233 16790 net.cpp:198] drop7 needs backward computation.
I0829 16:18:16.371239 16790 net.cpp:198] relu7 needs backward computation.
I0829 16:18:16.371245 16790 net.cpp:198] fc7_scale needs backward computation.
I0829 16:18:16.371250 16790 net.cpp:198] concat_wbn_7 needs backward computation.
I0829 16:18:16.371256 16790 net.cpp:198] fc7_target/bn needs backward computation.
I0829 16:18:16.371263 16790 net.cpp:198] fc7_source/bn needs backward computation.
I0829 16:18:16.371268 16790 net.cpp:198] slicer_fc7 needs backward computation.
I0829 16:18:16.371273 16790 net.cpp:198] fc7 needs backward computation.
I0829 16:18:16.371279 16790 net.cpp:198] drop6 needs backward computation.
I0829 16:18:16.371285 16790 net.cpp:198] relu6 needs backward computation.
I0829 16:18:16.371291 16790 net.cpp:198] fc6_scale needs backward computation.
I0829 16:18:16.371296 16790 net.cpp:198] concat_wbn_6 needs backward computation.
I0829 16:18:16.371302 16790 net.cpp:198] fc6_target/bn needs backward computation.
I0829 16:18:16.371309 16790 net.cpp:198] fc6_source/bn needs backward computation.
I0829 16:18:16.371314 16790 net.cpp:198] slicer_fc6 needs backward computation.
I0829 16:18:16.371320 16790 net.cpp:198] fc6 needs backward computation.
I0829 16:18:16.371325 16790 net.cpp:198] pool5 needs backward computation.
I0829 16:18:16.371330 16790 net.cpp:198] relu5 needs backward computation.
I0829 16:18:16.371335 16790 net.cpp:198] conv5 needs backward computation.
I0829 16:18:16.371341 16790 net.cpp:198] relu4 needs backward computation.
I0829 16:18:16.371346 16790 net.cpp:198] conv4 needs backward computation.
I0829 16:18:16.371352 16790 net.cpp:198] relu3 needs backward computation.
I0829 16:18:16.371357 16790 net.cpp:198] conv3 needs backward computation.
I0829 16:18:16.371371 16790 net.cpp:198] norm2 needs backward computation.
I0829 16:18:16.371376 16790 net.cpp:198] pool2 needs backward computation.
I0829 16:18:16.371381 16790 net.cpp:198] relu2 needs backward computation.
I0829 16:18:16.371387 16790 net.cpp:198] conv2 needs backward computation.
I0829 16:18:16.371392 16790 net.cpp:198] norm1 needs backward computation.
I0829 16:18:16.371398 16790 net.cpp:198] pool1 needs backward computation.
I0829 16:18:16.371404 16790 net.cpp:198] relu1 needs backward computation.
I0829 16:18:16.371409 16790 net.cpp:198] conv1 needs backward computation.
I0829 16:18:16.371415 16790 net.cpp:200] domain_labels_concat_domain_labels_0_split does not need backward computation.
I0829 16:18:16.371421 16790 net.cpp:200] concat_domain_labels does not need backward computation.
I0829 16:18:16.371428 16790 net.cpp:200] label_label_0_split does not need backward computation.
I0829 16:18:16.371434 16790 net.cpp:200] label does not need backward computation.
I0829 16:18:16.371441 16790 net.cpp:200] data does not need backward computation.
I0829 16:18:16.371448 16790 net.cpp:200] target_domain_labels does not need backward computation.
I0829 16:18:16.371454 16790 net.cpp:200] source_domain_labels does not need backward computation.
I0829 16:18:16.371459 16790 net.cpp:200] target_data does not need backward computation.
I0829 16:18:16.371465 16790 net.cpp:200] s2_data does not need backward computation.
I0829 16:18:16.371469 16790 net.cpp:200] s1_data does not need backward computation.
I0829 16:18:16.371475 16790 net.cpp:242] This network produces output accuracy
I0829 16:18:16.371481 16790 net.cpp:242] This network produces output dc_loss
I0829 16:18:16.371487 16790 net.cpp:242] This network produces output domain_accuracy
I0829 16:18:16.371492 16790 net.cpp:242] This network produces output entropy
I0829 16:18:16.371498 16790 net.cpp:242] This network produces output loss
I0829 16:18:16.371559 16790 net.cpp:255] Network initialization done.
I0829 16:18:16.371862 16790 solver.cpp:72] Finetuning from /home/alfa/Documents/msda/mywork/pretrain/bvlc_reference_caffenet.caffemodel
I0829 16:18:16.544627 16790 upgrade_proto.cpp:46] Attempting to upgrade input file specified using deprecated transformation parameters: /home/alfa/Documents/msda/mywork/pretrain/bvlc_reference_caffenet.caffemodel
I0829 16:18:16.544653 16790 upgrade_proto.cpp:49] Successfully upgraded file specified using deprecated data transformation parameters.
W0829 16:18:16.544658 16790 upgrade_proto.cpp:51] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0829 16:18:16.544749 16790 upgrade_proto.cpp:55] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/alfa/Documents/msda/mywork/pretrain/bvlc_reference_caffenet.caffemodel
I0829 16:18:16.773216 16790 upgrade_proto.cpp:63] Successfully upgraded file specified using deprecated V1LayerParameter
I0829 16:18:16.816392 16790 net.cpp:744] Ignoring source layer fc8
I0829 16:18:16.827494 16790 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: /home/alfa/Documents/msda/mywork/models/aw2d/bn_with_dann/alexnet.prototxt
I0829 16:18:16.827515 16790 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0829 16:18:16.827522 16790 solver.cpp:190] Creating test net (#0) specified by net file: /home/alfa/Documents/msda/mywork/models/aw2d/bn_with_dann/alexnet.prototxt
I0829 16:18:16.827585 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer s1_data
I0829 16:18:16.827592 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer s2_data
I0829 16:18:16.827596 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer target_data
I0829 16:18:16.827600 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer source_domain_labels
I0829 16:18:16.827605 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer target_domain_labels
I0829 16:18:16.827623 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0829 16:18:16.827627 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer label
I0829 16:18:16.827630 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer concat_domain_labels
I0829 16:18:16.827642 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer slicer_fc6
I0829 16:18:16.827647 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer fc6_source/bn
I0829 16:18:16.827651 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer fc6_target/bn
I0829 16:18:16.827653 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer concat_wbn_6
I0829 16:18:16.827659 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer slicer_fc7
I0829 16:18:16.827664 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer fc7_source/bn
I0829 16:18:16.827668 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer fc7_target/bn
I0829 16:18:16.827672 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer concat_wbn_7
I0829 16:18:16.827678 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer slicer_bottle
I0829 16:18:16.827683 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer silence_target_feature
I0829 16:18:16.827688 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer grl
I0829 16:18:16.827692 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer dc_ip1
I0829 16:18:16.827695 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer dc_relu1
I0829 16:18:16.827699 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer dc_drop1
I0829 16:18:16.827702 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer dc_ip2
I0829 16:18:16.827706 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer dc_relu2
I0829 16:18:16.827729 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer dc_drop2
I0829 16:18:16.827738 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer dc_ip3
I0829 16:18:16.827741 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer dc_loss
I0829 16:18:16.827745 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer dc_accuracy
I0829 16:18:16.827750 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer slicer_fc8
I0829 16:18:16.827754 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer fc8_source/bn
I0829 16:18:16.827756 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer fc8_target/bn
I0829 16:18:16.827761 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer concat_wbn_8
I0829 16:18:16.827766 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer slicer_scorer
I0829 16:18:16.827771 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss
I0829 16:18:16.827775 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer entropy
I0829 16:18:16.827783 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy
I0829 16:18:16.827788 16790 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer silence_target
I0829 16:18:16.827981 16790 net.cpp:51] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  image_data_param {
    source: "/home/alfa/Documents/msda/mywork/data/office/office_d.txt"
    batch_size: 1
    shuffle: false
    new_height: 256
    new_width: 256
    is_color: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc6_target/bn"
  type: "BatchNorm"
  bottom: "fc6"
  top: "fc6/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    moving_average_fraction: 0.95
  }
}
layer {
  name: "fc6_scale"
  type: "Scale"
  bottom: "fc6/bn"
  top: "fc6/scale"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    axis: 1
    num_axes: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6/scale"
  top: "fc6/relu"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6/relu"
  top: "fc6/out"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6/out"
  top: "fc7"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_target/bn"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    moving_average_fraction: 0.95
  }
}
layer {
  name: "fc7_scale"
  type: "Scale"
  bottom: "fc7/bn"
  top: "fc7/scale"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    axis: 1
    num_axes: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7/scale"
  top: "fc7/relu"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7/relu"
  top: "fc7/out"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "bottleneck"
  type: "InnerProduct"
  bottom: "fc7/out"
  top: "bottleneck"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "office-fc8"
  type: "InnerProduct"
  bottom: "bottleneck"
  top: "fc8"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 31
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc8_target/bn"
  type: "BatchNorm"
  bottom: "fc8"
  top: "fc8/bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    moving_average_fraction: 0.95
  }
}
layer {
  name: "fc8_scale"
  type: "Scale"
  bottom: "fc8/bn"
  top: "fc8/scale"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    axis: 1
    num_axes: 1
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8/scale"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0829 16:18:16.828058 16790 layer_factory.hpp:77] Creating layer data
I0829 16:18:16.828071 16790 net.cpp:84] Creating Layer data
I0829 16:18:16.828078 16790 net.cpp:380] data -> data
I0829 16:18:16.828085 16790 net.cpp:380] data -> label
I0829 16:18:16.828094 16790 image_data_layer.cpp:38] Opening file /home/alfa/Documents/msda/mywork/data/office/office_d.txt
I0829 16:18:16.828290 16790 image_data_layer.cpp:63] A total of 498 images.
I0829 16:18:16.833596 16790 image_data_layer.cpp:90] output data size: 1,3,224,224
I0829 16:18:16.835597 16790 net.cpp:122] Setting up data
I0829 16:18:16.835614 16790 net.cpp:129] Top shape: 1 3 224 224 (150528)
I0829 16:18:16.835619 16790 net.cpp:129] Top shape: 1 (1)
I0829 16:18:16.835623 16790 net.cpp:137] Memory required for data: 602116
I0829 16:18:16.835629 16790 layer_factory.hpp:77] Creating layer conv1
I0829 16:18:16.835646 16790 net.cpp:84] Creating Layer conv1
I0829 16:18:16.835652 16790 net.cpp:406] conv1 <- data
I0829 16:18:16.835661 16790 net.cpp:380] conv1 -> conv1
I0829 16:18:16.837168 16790 net.cpp:122] Setting up conv1
I0829 16:18:16.837182 16790 net.cpp:129] Top shape: 1 96 54 54 (279936)
I0829 16:18:16.837188 16790 net.cpp:137] Memory required for data: 1721860
I0829 16:18:16.837199 16790 layer_factory.hpp:77] Creating layer relu1
I0829 16:18:16.837209 16790 net.cpp:84] Creating Layer relu1
I0829 16:18:16.837213 16790 net.cpp:406] relu1 <- conv1
I0829 16:18:16.837218 16790 net.cpp:367] relu1 -> conv1 (in-place)
I0829 16:18:16.837368 16790 net.cpp:122] Setting up relu1
I0829 16:18:16.837376 16790 net.cpp:129] Top shape: 1 96 54 54 (279936)
I0829 16:18:16.837379 16790 net.cpp:137] Memory required for data: 2841604
I0829 16:18:16.837383 16790 layer_factory.hpp:77] Creating layer pool1
I0829 16:18:16.837391 16790 net.cpp:84] Creating Layer pool1
I0829 16:18:16.837396 16790 net.cpp:406] pool1 <- conv1
I0829 16:18:16.837401 16790 net.cpp:380] pool1 -> pool1
I0829 16:18:16.837440 16790 net.cpp:122] Setting up pool1
I0829 16:18:16.837446 16790 net.cpp:129] Top shape: 1 96 27 27 (69984)
I0829 16:18:16.837450 16790 net.cpp:137] Memory required for data: 3121540
I0829 16:18:16.837455 16790 layer_factory.hpp:77] Creating layer norm1
I0829 16:18:16.837462 16790 net.cpp:84] Creating Layer norm1
I0829 16:18:16.837468 16790 net.cpp:406] norm1 <- pool1
I0829 16:18:16.837474 16790 net.cpp:380] norm1 -> norm1
I0829 16:18:16.837640 16790 net.cpp:122] Setting up norm1
I0829 16:18:16.837647 16790 net.cpp:129] Top shape: 1 96 27 27 (69984)
I0829 16:18:16.837651 16790 net.cpp:137] Memory required for data: 3401476
I0829 16:18:16.837656 16790 layer_factory.hpp:77] Creating layer conv2
I0829 16:18:16.837666 16790 net.cpp:84] Creating Layer conv2
I0829 16:18:16.837671 16790 net.cpp:406] conv2 <- norm1
I0829 16:18:16.837677 16790 net.cpp:380] conv2 -> conv2
I0829 16:18:16.842520 16790 net.cpp:122] Setting up conv2
I0829 16:18:16.842541 16790 net.cpp:129] Top shape: 1 256 27 27 (186624)
I0829 16:18:16.842545 16790 net.cpp:137] Memory required for data: 4147972
I0829 16:18:16.842558 16790 layer_factory.hpp:77] Creating layer relu2
I0829 16:18:16.842569 16790 net.cpp:84] Creating Layer relu2
I0829 16:18:16.842576 16790 net.cpp:406] relu2 <- conv2
I0829 16:18:16.842583 16790 net.cpp:367] relu2 -> conv2 (in-place)
I0829 16:18:16.843138 16790 net.cpp:122] Setting up relu2
I0829 16:18:16.843149 16790 net.cpp:129] Top shape: 1 256 27 27 (186624)
I0829 16:18:16.843154 16790 net.cpp:137] Memory required for data: 4894468
I0829 16:18:16.843161 16790 layer_factory.hpp:77] Creating layer pool2
I0829 16:18:16.843170 16790 net.cpp:84] Creating Layer pool2
I0829 16:18:16.843174 16790 net.cpp:406] pool2 <- conv2
I0829 16:18:16.843183 16790 net.cpp:380] pool2 -> pool2
I0829 16:18:16.843252 16790 net.cpp:122] Setting up pool2
I0829 16:18:16.843262 16790 net.cpp:129] Top shape: 1 256 13 13 (43264)
I0829 16:18:16.843268 16790 net.cpp:137] Memory required for data: 5067524
I0829 16:18:16.843273 16790 layer_factory.hpp:77] Creating layer norm2
I0829 16:18:16.843286 16790 net.cpp:84] Creating Layer norm2
I0829 16:18:16.843292 16790 net.cpp:406] norm2 <- pool2
I0829 16:18:16.843297 16790 net.cpp:380] norm2 -> norm2
I0829 16:18:16.843480 16790 net.cpp:122] Setting up norm2
I0829 16:18:16.843488 16790 net.cpp:129] Top shape: 1 256 13 13 (43264)
I0829 16:18:16.843492 16790 net.cpp:137] Memory required for data: 5240580
I0829 16:18:16.843497 16790 layer_factory.hpp:77] Creating layer conv3
I0829 16:18:16.843521 16790 net.cpp:84] Creating Layer conv3
I0829 16:18:16.843528 16790 net.cpp:406] conv3 <- norm2
I0829 16:18:16.843533 16790 net.cpp:380] conv3 -> conv3
I0829 16:18:16.852149 16790 net.cpp:122] Setting up conv3
I0829 16:18:16.852174 16790 net.cpp:129] Top shape: 1 384 13 13 (64896)
I0829 16:18:16.852176 16790 net.cpp:137] Memory required for data: 5500164
I0829 16:18:16.852190 16790 layer_factory.hpp:77] Creating layer relu3
I0829 16:18:16.852200 16790 net.cpp:84] Creating Layer relu3
I0829 16:18:16.852206 16790 net.cpp:406] relu3 <- conv3
I0829 16:18:16.852214 16790 net.cpp:367] relu3 -> conv3 (in-place)
I0829 16:18:16.852386 16790 net.cpp:122] Setting up relu3
I0829 16:18:16.852394 16790 net.cpp:129] Top shape: 1 384 13 13 (64896)
I0829 16:18:16.852398 16790 net.cpp:137] Memory required for data: 5759748
I0829 16:18:16.852403 16790 layer_factory.hpp:77] Creating layer conv4
I0829 16:18:16.852417 16790 net.cpp:84] Creating Layer conv4
I0829 16:18:16.852422 16790 net.cpp:406] conv4 <- conv3
I0829 16:18:16.852429 16790 net.cpp:380] conv4 -> conv4
I0829 16:18:16.860519 16790 net.cpp:122] Setting up conv4
I0829 16:18:16.860541 16790 net.cpp:129] Top shape: 1 384 13 13 (64896)
I0829 16:18:16.860546 16790 net.cpp:137] Memory required for data: 6019332
I0829 16:18:16.860555 16790 layer_factory.hpp:77] Creating layer relu4
I0829 16:18:16.860568 16790 net.cpp:84] Creating Layer relu4
I0829 16:18:16.860574 16790 net.cpp:406] relu4 <- conv4
I0829 16:18:16.860580 16790 net.cpp:367] relu4 -> conv4 (in-place)
I0829 16:18:16.861126 16790 net.cpp:122] Setting up relu4
I0829 16:18:16.861137 16790 net.cpp:129] Top shape: 1 384 13 13 (64896)
I0829 16:18:16.861141 16790 net.cpp:137] Memory required for data: 6278916
I0829 16:18:16.861146 16790 layer_factory.hpp:77] Creating layer conv5
I0829 16:18:16.861157 16790 net.cpp:84] Creating Layer conv5
I0829 16:18:16.861166 16790 net.cpp:406] conv5 <- conv4
I0829 16:18:16.861174 16790 net.cpp:380] conv5 -> conv5
I0829 16:18:16.867377 16790 net.cpp:122] Setting up conv5
I0829 16:18:16.867398 16790 net.cpp:129] Top shape: 1 256 13 13 (43264)
I0829 16:18:16.867403 16790 net.cpp:137] Memory required for data: 6451972
I0829 16:18:16.867421 16790 layer_factory.hpp:77] Creating layer relu5
I0829 16:18:16.867434 16790 net.cpp:84] Creating Layer relu5
I0829 16:18:16.867440 16790 net.cpp:406] relu5 <- conv5
I0829 16:18:16.867449 16790 net.cpp:367] relu5 -> conv5 (in-place)
I0829 16:18:16.867614 16790 net.cpp:122] Setting up relu5
I0829 16:18:16.867624 16790 net.cpp:129] Top shape: 1 256 13 13 (43264)
I0829 16:18:16.867627 16790 net.cpp:137] Memory required for data: 6625028
I0829 16:18:16.867632 16790 layer_factory.hpp:77] Creating layer pool5
I0829 16:18:16.867642 16790 net.cpp:84] Creating Layer pool5
I0829 16:18:16.867650 16790 net.cpp:406] pool5 <- conv5
I0829 16:18:16.867656 16790 net.cpp:380] pool5 -> pool5
I0829 16:18:16.867705 16790 net.cpp:122] Setting up pool5
I0829 16:18:16.867738 16790 net.cpp:129] Top shape: 1 256 6 6 (9216)
I0829 16:18:16.867745 16790 net.cpp:137] Memory required for data: 6661892
I0829 16:18:16.867750 16790 layer_factory.hpp:77] Creating layer fc6
I0829 16:18:16.867764 16790 net.cpp:84] Creating Layer fc6
I0829 16:18:16.867771 16790 net.cpp:406] fc6 <- pool5
I0829 16:18:16.867779 16790 net.cpp:380] fc6 -> fc6
I0829 16:18:17.156352 16790 net.cpp:122] Setting up fc6
I0829 16:18:17.156374 16790 net.cpp:129] Top shape: 1 4096 (4096)
I0829 16:18:17.156379 16790 net.cpp:137] Memory required for data: 6678276
I0829 16:18:17.156391 16790 layer_factory.hpp:77] Creating layer fc6_target/bn
I0829 16:18:17.156405 16790 net.cpp:84] Creating Layer fc6_target/bn
I0829 16:18:17.156414 16790 net.cpp:406] fc6_target/bn <- fc6
I0829 16:18:17.156426 16790 net.cpp:380] fc6_target/bn -> fc6/bn
I0829 16:18:17.156601 16790 net.cpp:122] Setting up fc6_target/bn
I0829 16:18:17.156611 16790 net.cpp:129] Top shape: 1 4096 (4096)
I0829 16:18:17.156615 16790 net.cpp:137] Memory required for data: 6694660
I0829 16:18:17.156626 16790 layer_factory.hpp:77] Creating layer fc6_scale
I0829 16:18:17.156651 16790 net.cpp:84] Creating Layer fc6_scale
I0829 16:18:17.156658 16790 net.cpp:406] fc6_scale <- fc6/bn
I0829 16:18:17.156666 16790 net.cpp:380] fc6_scale -> fc6/scale
I0829 16:18:17.156711 16790 layer_factory.hpp:77] Creating layer fc6_scale
I0829 16:18:17.156813 16790 net.cpp:122] Setting up fc6_scale
I0829 16:18:17.156822 16790 net.cpp:129] Top shape: 1 4096 (4096)
I0829 16:18:17.156826 16790 net.cpp:137] Memory required for data: 6711044
I0829 16:18:17.156842 16790 layer_factory.hpp:77] Creating layer relu6
I0829 16:18:17.156852 16790 net.cpp:84] Creating Layer relu6
I0829 16:18:17.156857 16790 net.cpp:406] relu6 <- fc6/scale
I0829 16:18:17.156864 16790 net.cpp:380] relu6 -> fc6/relu
I0829 16:18:17.157099 16790 net.cpp:122] Setting up relu6
I0829 16:18:17.157109 16790 net.cpp:129] Top shape: 1 4096 (4096)
I0829 16:18:17.157112 16790 net.cpp:137] Memory required for data: 6727428
I0829 16:18:17.157117 16790 layer_factory.hpp:77] Creating layer drop6
I0829 16:18:17.157129 16790 net.cpp:84] Creating Layer drop6
I0829 16:18:17.157137 16790 net.cpp:406] drop6 <- fc6/relu
I0829 16:18:17.157148 16790 net.cpp:380] drop6 -> fc6/out
I0829 16:18:17.157191 16790 net.cpp:122] Setting up drop6
I0829 16:18:17.157200 16790 net.cpp:129] Top shape: 1 4096 (4096)
I0829 16:18:17.157204 16790 net.cpp:137] Memory required for data: 6743812
I0829 16:18:17.157209 16790 layer_factory.hpp:77] Creating layer fc7
I0829 16:18:17.157219 16790 net.cpp:84] Creating Layer fc7
I0829 16:18:17.157229 16790 net.cpp:406] fc7 <- fc6/out
I0829 16:18:17.157239 16790 net.cpp:380] fc7 -> fc7
I0829 16:18:17.285779 16790 net.cpp:122] Setting up fc7
I0829 16:18:17.285806 16790 net.cpp:129] Top shape: 1 4096 (4096)
I0829 16:18:17.285811 16790 net.cpp:137] Memory required for data: 6760196
I0829 16:18:17.285822 16790 layer_factory.hpp:77] Creating layer fc7_target/bn
I0829 16:18:17.285842 16790 net.cpp:84] Creating Layer fc7_target/bn
I0829 16:18:17.285851 16790 net.cpp:406] fc7_target/bn <- fc7
I0829 16:18:17.285862 16790 net.cpp:380] fc7_target/bn -> fc7/bn
I0829 16:18:17.286229 16790 net.cpp:122] Setting up fc7_target/bn
I0829 16:18:17.286243 16790 net.cpp:129] Top shape: 1 4096 (4096)
I0829 16:18:17.286252 16790 net.cpp:137] Memory required for data: 6776580
I0829 16:18:17.286263 16790 layer_factory.hpp:77] Creating layer fc7_scale
I0829 16:18:17.286275 16790 net.cpp:84] Creating Layer fc7_scale
I0829 16:18:17.286286 16790 net.cpp:406] fc7_scale <- fc7/bn
I0829 16:18:17.286296 16790 net.cpp:380] fc7_scale -> fc7/scale
I0829 16:18:17.286365 16790 layer_factory.hpp:77] Creating layer fc7_scale
I0829 16:18:17.286578 16790 net.cpp:122] Setting up fc7_scale
I0829 16:18:17.286594 16790 net.cpp:129] Top shape: 1 4096 (4096)
I0829 16:18:17.286600 16790 net.cpp:137] Memory required for data: 6792964
I0829 16:18:17.286610 16790 layer_factory.hpp:77] Creating layer relu7
I0829 16:18:17.286623 16790 net.cpp:84] Creating Layer relu7
I0829 16:18:17.286630 16790 net.cpp:406] relu7 <- fc7/scale
I0829 16:18:17.286640 16790 net.cpp:380] relu7 -> fc7/relu
I0829 16:18:17.287035 16790 net.cpp:122] Setting up relu7
I0829 16:18:17.287050 16790 net.cpp:129] Top shape: 1 4096 (4096)
I0829 16:18:17.287056 16790 net.cpp:137] Memory required for data: 6809348
I0829 16:18:17.287061 16790 layer_factory.hpp:77] Creating layer drop7
I0829 16:18:17.287075 16790 net.cpp:84] Creating Layer drop7
I0829 16:18:17.287082 16790 net.cpp:406] drop7 <- fc7/relu
I0829 16:18:17.287092 16790 net.cpp:380] drop7 -> fc7/out
I0829 16:18:17.287158 16790 net.cpp:122] Setting up drop7
I0829 16:18:17.287173 16790 net.cpp:129] Top shape: 1 4096 (4096)
I0829 16:18:17.287179 16790 net.cpp:137] Memory required for data: 6825732
I0829 16:18:17.287184 16790 layer_factory.hpp:77] Creating layer bottleneck
I0829 16:18:17.287199 16790 net.cpp:84] Creating Layer bottleneck
I0829 16:18:17.287207 16790 net.cpp:406] bottleneck <- fc7/out
I0829 16:18:17.287220 16790 net.cpp:380] bottleneck -> bottleneck
I0829 16:18:17.296037 16790 net.cpp:122] Setting up bottleneck
I0829 16:18:17.296063 16790 net.cpp:129] Top shape: 1 256 (256)
I0829 16:18:17.296098 16790 net.cpp:137] Memory required for data: 6826756
I0829 16:18:17.296113 16790 layer_factory.hpp:77] Creating layer office-fc8
I0829 16:18:17.296126 16790 net.cpp:84] Creating Layer office-fc8
I0829 16:18:17.296133 16790 net.cpp:406] office-fc8 <- bottleneck
I0829 16:18:17.296144 16790 net.cpp:380] office-fc8 -> fc8
I0829 16:18:17.296449 16790 net.cpp:122] Setting up office-fc8
I0829 16:18:17.296460 16790 net.cpp:129] Top shape: 1 31 (31)
I0829 16:18:17.296468 16790 net.cpp:137] Memory required for data: 6826880
I0829 16:18:17.296479 16790 layer_factory.hpp:77] Creating layer fc8_target/bn
I0829 16:18:17.296494 16790 net.cpp:84] Creating Layer fc8_target/bn
I0829 16:18:17.296502 16790 net.cpp:406] fc8_target/bn <- fc8
I0829 16:18:17.296511 16790 net.cpp:380] fc8_target/bn -> fc8/bn
I0829 16:18:17.296866 16790 net.cpp:122] Setting up fc8_target/bn
I0829 16:18:17.296878 16790 net.cpp:129] Top shape: 1 31 (31)
I0829 16:18:17.296882 16790 net.cpp:137] Memory required for data: 6827004
I0829 16:18:17.296892 16790 layer_factory.hpp:77] Creating layer fc8_scale
I0829 16:18:17.296905 16790 net.cpp:84] Creating Layer fc8_scale
I0829 16:18:17.296914 16790 net.cpp:406] fc8_scale <- fc8/bn
I0829 16:18:17.296926 16790 net.cpp:380] fc8_scale -> fc8/scale
I0829 16:18:17.296994 16790 layer_factory.hpp:77] Creating layer fc8_scale
I0829 16:18:17.297132 16790 net.cpp:122] Setting up fc8_scale
I0829 16:18:17.297143 16790 net.cpp:129] Top shape: 1 31 (31)
I0829 16:18:17.297148 16790 net.cpp:137] Memory required for data: 6827128
I0829 16:18:17.297163 16790 layer_factory.hpp:77] Creating layer accuracy
I0829 16:18:17.297174 16790 net.cpp:84] Creating Layer accuracy
I0829 16:18:17.297201 16790 net.cpp:406] accuracy <- fc8/scale
I0829 16:18:17.297224 16790 net.cpp:406] accuracy <- label
I0829 16:18:17.297245 16790 net.cpp:380] accuracy -> accuracy
I0829 16:18:17.297262 16790 net.cpp:122] Setting up accuracy
I0829 16:18:17.297269 16790 net.cpp:129] Top shape: (1)
I0829 16:18:17.297273 16790 net.cpp:137] Memory required for data: 6827132
I0829 16:18:17.297279 16790 net.cpp:200] accuracy does not need backward computation.
I0829 16:18:17.297286 16790 net.cpp:200] fc8_scale does not need backward computation.
I0829 16:18:17.297291 16790 net.cpp:200] fc8_target/bn does not need backward computation.
I0829 16:18:17.297296 16790 net.cpp:200] office-fc8 does not need backward computation.
I0829 16:18:17.297300 16790 net.cpp:200] bottleneck does not need backward computation.
I0829 16:18:17.297307 16790 net.cpp:200] drop7 does not need backward computation.
I0829 16:18:17.297313 16790 net.cpp:200] relu7 does not need backward computation.
I0829 16:18:17.297318 16790 net.cpp:200] fc7_scale does not need backward computation.
I0829 16:18:17.297323 16790 net.cpp:200] fc7_target/bn does not need backward computation.
I0829 16:18:17.297330 16790 net.cpp:200] fc7 does not need backward computation.
I0829 16:18:17.297335 16790 net.cpp:200] drop6 does not need backward computation.
I0829 16:18:17.297340 16790 net.cpp:200] relu6 does not need backward computation.
I0829 16:18:17.297345 16790 net.cpp:200] fc6_scale does not need backward computation.
I0829 16:18:17.297351 16790 net.cpp:200] fc6_target/bn does not need backward computation.
I0829 16:18:17.297358 16790 net.cpp:200] fc6 does not need backward computation.
I0829 16:18:17.297363 16790 net.cpp:200] pool5 does not need backward computation.
I0829 16:18:17.297368 16790 net.cpp:200] relu5 does not need backward computation.
I0829 16:18:17.297374 16790 net.cpp:200] conv5 does not need backward computation.
I0829 16:18:17.297379 16790 net.cpp:200] relu4 does not need backward computation.
I0829 16:18:17.297384 16790 net.cpp:200] conv4 does not need backward computation.
I0829 16:18:17.297389 16790 net.cpp:200] relu3 does not need backward computation.
I0829 16:18:17.297395 16790 net.cpp:200] conv3 does not need backward computation.
I0829 16:18:17.297400 16790 net.cpp:200] norm2 does not need backward computation.
I0829 16:18:17.297405 16790 net.cpp:200] pool2 does not need backward computation.
I0829 16:18:17.297418 16790 net.cpp:200] relu2 does not need backward computation.
I0829 16:18:17.297425 16790 net.cpp:200] conv2 does not need backward computation.
I0829 16:18:17.297430 16790 net.cpp:200] norm1 does not need backward computation.
I0829 16:18:17.297435 16790 net.cpp:200] pool1 does not need backward computation.
I0829 16:18:17.297441 16790 net.cpp:200] relu1 does not need backward computation.
I0829 16:18:17.297446 16790 net.cpp:200] conv1 does not need backward computation.
I0829 16:18:17.297451 16790 net.cpp:200] data does not need backward computation.
I0829 16:18:17.297456 16790 net.cpp:242] This network produces output accuracy
I0829 16:18:17.297480 16790 net.cpp:255] Network initialization done.
I0829 16:18:17.297613 16790 solver.cpp:72] Finetuning from /home/alfa/Documents/msda/mywork/pretrain/bvlc_reference_caffenet.caffemodel
I0829 16:18:17.430344 16790 upgrade_proto.cpp:46] Attempting to upgrade input file specified using deprecated transformation parameters: /home/alfa/Documents/msda/mywork/pretrain/bvlc_reference_caffenet.caffemodel
I0829 16:18:17.430367 16790 upgrade_proto.cpp:49] Successfully upgraded file specified using deprecated data transformation parameters.
W0829 16:18:17.430371 16790 upgrade_proto.cpp:51] Note that future Caffe releases will only support transform_param messages for transformation fields.
I0829 16:18:17.430392 16790 upgrade_proto.cpp:55] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/alfa/Documents/msda/mywork/pretrain/bvlc_reference_caffenet.caffemodel
I0829 16:18:17.645428 16790 upgrade_proto.cpp:63] Successfully upgraded file specified using deprecated V1LayerParameter
I0829 16:18:17.689221 16790 net.cpp:744] Ignoring source layer fc8
I0829 16:18:17.689244 16790 net.cpp:744] Ignoring source layer loss
I0829 16:18:17.700011 16790 solver.cpp:57] Solver scaffolding done.
I0829 16:18:17.701522 16790 caffe.cpp:239] Starting Optimization
I0829 16:18:17.701534 16790 solver.cpp:289] Solving CaffeNet
I0829 16:18:17.701537 16790 solver.cpp:290] Learning Rate Policy: inv
I0829 16:18:17.705905 16790 solver.cpp:347] Iteration 0, Testing net (#0)
I0829 16:18:17.705924 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:18:17.705929 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:18:17.705932 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:18:17.705936 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:18:17.705940 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:18:17.705945 16790 net.cpp:676] Ignoring source layer label
I0829 16:18:17.705948 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:18:17.705955 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:18:17.705958 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:18:17.722021 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:18:17.722043 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:18:17.722096 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:18:17.728569 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:18:17.728588 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:18:17.728639 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:18:17.729290 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:18:17.729298 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:18:17.729302 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:18:17.729307 16790 net.cpp:676] Ignoring source layer grl
I0829 16:18:17.729312 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:18:17.729316 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:18:17.729321 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:18:17.729324 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:18:17.729329 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:18:17.729349 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:18:17.729354 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:18:17.729358 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:18:17.729364 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:18:17.729369 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:18:17.729418 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:18:17.729424 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:18:17.729467 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:18:17.729501 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:18:17.729507 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:18:17.729511 16790 net.cpp:676] Ignoring source layer loss
I0829 16:18:17.729516 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:18:17.729522 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:18:17.774196 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:18:23.680666 16790 solver.cpp:414]     Test net output #0: accuracy = 0.0361446
I0829 16:18:23.971421 16790 solver.cpp:239] Iteration 0 (-3.82248e+25 iter/s, 6.26949s/10 iters), loss = 6.44192
I0829 16:18:23.971462 16790 solver.cpp:258]     Train net output #0: accuracy = 0.0507812
I0829 16:18:23.971474 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.695248 (* 0.3 = 0.208574 loss)
I0829 16:18:23.971482 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:18:23.971489 16790 solver.cpp:258]     Train net output #3: entropy = 2.99988 (* 0.8 = 2.39991 loss)
I0829 16:18:23.971498 16790 solver.cpp:258]     Train net output #4: loss = 3.83344 (* 1 = 3.83344 loss)
I0829 16:18:23.971523 16790 sgd_solver.cpp:112] Iteration 0, lr = 0.001
I0829 16:18:30.290280 16790 solver.cpp:239] Iteration 10 (1.58267 iter/s, 6.31845s/10 iters), loss = 3.46337
I0829 16:18:30.290323 16790 solver.cpp:258]     Train net output #0: accuracy = 0.761719
I0829 16:18:30.290338 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.696633 (* 0.3 = 0.20899 loss)
I0829 16:18:30.290344 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:18:30.290352 16790 solver.cpp:258]     Train net output #3: entropy = 2.33129 (* 0.8 = 1.86503 loss)
I0829 16:18:30.290360 16790 solver.cpp:258]     Train net output #4: loss = 1.38935 (* 1 = 1.38935 loss)
I0829 16:18:30.290369 16790 sgd_solver.cpp:112] Iteration 10, lr = 0.000992565
I0829 16:18:37.729589 16790 solver.cpp:347] Iteration 20, Testing net (#0)
I0829 16:18:37.729616 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:18:37.729622 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:18:37.729626 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:18:37.729631 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:18:37.729636 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:18:37.729641 16790 net.cpp:676] Ignoring source layer label
I0829 16:18:37.729646 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:18:37.729650 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:18:37.729655 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:18:37.729671 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:18:37.729677 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:18:37.729682 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:18:37.729688 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:18:37.729696 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:18:37.729701 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:18:37.729709 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:18:37.729713 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:18:37.729719 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:18:37.729725 16790 net.cpp:676] Ignoring source layer grl
I0829 16:18:37.729748 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:18:37.729753 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:18:37.729758 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:18:37.729763 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:18:37.729768 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:18:37.729773 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:18:37.729779 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:18:37.729785 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:18:37.729790 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:18:37.729794 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:18:37.729802 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:18:37.729809 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:18:37.729812 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:18:37.729820 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:18:37.729828 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:18:37.729833 16790 net.cpp:676] Ignoring source layer loss
I0829 16:18:37.729837 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:18:37.729843 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:18:43.729506 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:18:43.800743 16790 solver.cpp:414]     Test net output #0: accuracy = 0.883534
I0829 16:18:44.096997 16790 solver.cpp:239] Iteration 20 (0.724329 iter/s, 13.8059s/10 iters), loss = 3.02582
I0829 16:18:44.097057 16790 solver.cpp:258]     Train net output #0: accuracy = 0.765625
I0829 16:18:44.097074 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.697363 (* 0.3 = 0.209209 loss)
I0829 16:18:44.097105 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:18:44.097126 16790 solver.cpp:258]     Train net output #3: entropy = 1.99646 (* 0.8 = 1.59717 loss)
I0829 16:18:44.097146 16790 solver.cpp:258]     Train net output #4: loss = 1.21945 (* 1 = 1.21945 loss)
I0829 16:18:44.097167 16790 sgd_solver.cpp:112] Iteration 20, lr = 0.000985258
I0829 16:18:52.008325 16790 solver.cpp:239] Iteration 30 (1.26409 iter/s, 7.9108s/10 iters), loss = 2.66075
I0829 16:18:52.008432 16790 solver.cpp:258]     Train net output #0: accuracy = 0.820312
I0829 16:18:52.008450 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.681007 (* 0.3 = 0.204302 loss)
I0829 16:18:52.008460 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:18:52.008471 16790 solver.cpp:258]     Train net output #3: entropy = 1.80429 (* 0.8 = 1.44343 loss)
I0829 16:18:52.008479 16790 solver.cpp:258]     Train net output #4: loss = 1.01302 (* 1 = 1.01302 loss)
I0829 16:18:52.008491 16790 sgd_solver.cpp:112] Iteration 30, lr = 0.000978075
I0829 16:18:59.309464 16790 solver.cpp:347] Iteration 40, Testing net (#0)
I0829 16:18:59.309489 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:18:59.309494 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:18:59.309499 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:18:59.309504 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:18:59.309509 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:18:59.309514 16790 net.cpp:676] Ignoring source layer label
I0829 16:18:59.309517 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:18:59.309525 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:18:59.309528 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:18:59.309538 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:18:59.309545 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:18:59.309551 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:18:59.309559 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:18:59.309566 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:18:59.309571 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:18:59.309577 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:18:59.309582 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:18:59.309587 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:18:59.309593 16790 net.cpp:676] Ignoring source layer grl
I0829 16:18:59.309598 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:18:59.309603 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:18:59.309608 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:18:59.309613 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:18:59.309620 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:18:59.309624 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:18:59.309631 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:18:59.309635 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:18:59.309643 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:18:59.309646 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:18:59.309651 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:18:59.309655 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:18:59.309664 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:18:59.309669 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:18:59.309672 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:18:59.309679 16790 net.cpp:676] Ignoring source layer loss
I0829 16:18:59.309684 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:18:59.309689 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:19:04.699769 16790 solver.cpp:414]     Test net output #0: accuracy = 0.895582
I0829 16:19:04.966154 16790 solver.cpp:239] Iteration 40 (0.771785 iter/s, 12.957s/10 iters), loss = 2.44513
I0829 16:19:04.966199 16790 solver.cpp:258]     Train net output #0: accuracy = 0.800781
I0829 16:19:04.966214 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.651628 (* 0.3 = 0.195488 loss)
I0829 16:19:04.966222 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:19:04.966228 16790 solver.cpp:258]     Train net output #3: entropy = 1.55074 (* 0.8 = 1.24059 loss)
I0829 16:19:04.966267 16790 solver.cpp:258]     Train net output #4: loss = 1.00905 (* 1 = 1.00905 loss)
I0829 16:19:04.966277 16790 sgd_solver.cpp:112] Iteration 40, lr = 0.000971013
I0829 16:19:11.873291 16790 solver.cpp:239] Iteration 50 (1.44787 iter/s, 6.90668s/10 iters), loss = 2.20287
I0829 16:19:11.873340 16790 solver.cpp:258]     Train net output #0: accuracy = 0.875
I0829 16:19:11.873358 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.596975 (* 0.3 = 0.179093 loss)
I0829 16:19:11.873366 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:19:11.873376 16790 solver.cpp:258]     Train net output #3: entropy = 1.51502 (* 0.8 = 1.21202 loss)
I0829 16:19:11.873386 16790 solver.cpp:258]     Train net output #4: loss = 0.811764 (* 1 = 0.811764 loss)
I0829 16:19:11.873397 16790 sgd_solver.cpp:112] Iteration 50, lr = 0.000964069
I0829 16:19:19.013098 16790 solver.cpp:347] Iteration 60, Testing net (#0)
I0829 16:19:19.013120 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:19:19.013124 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:19:19.013128 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:19:19.013130 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:19:19.013134 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:19:19.013137 16790 net.cpp:676] Ignoring source layer label
I0829 16:19:19.013140 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:19:19.013144 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:19:19.013146 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:19:19.013154 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:19:19.013159 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:19:19.013161 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:19:19.013165 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:19:19.013168 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:19:19.013172 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:19:19.013177 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:19:19.013180 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:19:19.013182 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:19:19.013186 16790 net.cpp:676] Ignoring source layer grl
I0829 16:19:19.013190 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:19:19.013192 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:19:19.013195 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:19:19.013198 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:19:19.013201 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:19:19.013203 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:19:19.013206 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:19:19.013211 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:19:19.013213 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:19:19.013216 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:19:19.013219 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:19:19.013222 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:19:19.013226 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:19:19.013229 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:19:19.013231 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:19:19.013236 16790 net.cpp:676] Ignoring source layer loss
I0829 16:19:19.013238 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:19:19.013242 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:19:24.157479 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:19:24.480590 16790 solver.cpp:414]     Test net output #0: accuracy = 0.905622
I0829 16:19:24.764736 16790 solver.cpp:239] Iteration 60 (0.775757 iter/s, 12.8906s/10 iters), loss = 2.18602
I0829 16:19:24.764794 16790 solver.cpp:258]     Train net output #0: accuracy = 0.855469
I0829 16:19:24.764822 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.640542 (* 0.3 = 0.192163 loss)
I0829 16:19:24.764830 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:19:24.764838 16790 solver.cpp:258]     Train net output #3: entropy = 1.42166 (* 0.8 = 1.13733 loss)
I0829 16:19:24.764847 16790 solver.cpp:258]     Train net output #4: loss = 0.856531 (* 1 = 0.856531 loss)
I0829 16:19:24.764858 16790 sgd_solver.cpp:112] Iteration 60, lr = 0.00095724
I0829 16:19:31.616016 16790 solver.cpp:239] Iteration 70 (1.45968 iter/s, 6.85082s/10 iters), loss = 2.02418
I0829 16:19:31.616056 16790 solver.cpp:258]     Train net output #0: accuracy = 0.882812
I0829 16:19:31.616067 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.793043 (* 0.3 = 0.237913 loss)
I0829 16:19:31.616072 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:19:31.616078 16790 solver.cpp:258]     Train net output #3: entropy = 1.34791 (* 0.8 = 1.07832 loss)
I0829 16:19:31.616083 16790 solver.cpp:258]     Train net output #4: loss = 0.707939 (* 1 = 0.707939 loss)
I0829 16:19:31.616091 16790 sgd_solver.cpp:112] Iteration 70, lr = 0.000950522
I0829 16:19:38.805162 16790 solver.cpp:347] Iteration 80, Testing net (#0)
I0829 16:19:38.805191 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:19:38.805197 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:19:38.805200 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:19:38.805204 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:19:38.805209 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:19:38.805213 16790 net.cpp:676] Ignoring source layer label
I0829 16:19:38.805217 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:19:38.805222 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:19:38.805227 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:19:38.805238 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:19:38.805243 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:19:38.805248 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:19:38.805258 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:19:38.805266 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:19:38.805271 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:19:38.805280 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:19:38.805287 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:19:38.805291 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:19:38.805297 16790 net.cpp:676] Ignoring source layer grl
I0829 16:19:38.805302 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:19:38.805308 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:19:38.805313 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:19:38.805317 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:19:38.805321 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:19:38.805326 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:19:38.805330 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:19:38.805335 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:19:38.805339 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:19:38.805346 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:19:38.805351 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:19:38.805354 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:19:38.805358 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:19:38.805366 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:19:38.805371 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:19:38.805395 16790 net.cpp:676] Ignoring source layer loss
I0829 16:19:38.805399 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:19:38.805407 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:19:44.113507 16790 solver.cpp:414]     Test net output #0: accuracy = 0.911647
I0829 16:19:44.400241 16790 solver.cpp:239] Iteration 80 (0.782263 iter/s, 12.7834s/10 iters), loss = 2.04959
I0829 16:19:44.400337 16790 solver.cpp:258]     Train net output #0: accuracy = 0.832031
I0829 16:19:44.400370 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.449286 (* 0.3 = 0.134786 loss)
I0829 16:19:44.400390 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:19:44.400414 16790 solver.cpp:258]     Train net output #3: entropy = 1.32551 (* 0.8 = 1.06041 loss)
I0829 16:19:44.400434 16790 solver.cpp:258]     Train net output #4: loss = 0.854401 (* 1 = 0.854401 loss)
I0829 16:19:44.400456 16790 sgd_solver.cpp:112] Iteration 80, lr = 0.000943913
I0829 16:19:51.328666 16790 solver.cpp:239] Iteration 90 (1.44344 iter/s, 6.92792s/10 iters), loss = 1.88363
I0829 16:19:51.328706 16790 solver.cpp:258]     Train net output #0: accuracy = 0.886719
I0829 16:19:51.328717 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.56972 (* 0.3 = 0.170916 loss)
I0829 16:19:51.328724 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:19:51.328732 16790 solver.cpp:258]     Train net output #3: entropy = 1.25384 (* 0.8 = 1.00307 loss)
I0829 16:19:51.328742 16790 solver.cpp:258]     Train net output #4: loss = 0.70965 (* 1 = 0.70965 loss)
I0829 16:19:51.328749 16790 sgd_solver.cpp:112] Iteration 90, lr = 0.000937411
I0829 16:19:58.840703 16790 solver.cpp:347] Iteration 100, Testing net (#0)
I0829 16:19:58.840836 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:19:58.840842 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:19:58.840845 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:19:58.840852 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:19:58.840855 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:19:58.840859 16790 net.cpp:676] Ignoring source layer label
I0829 16:19:58.840863 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:19:58.840869 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:19:58.840873 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:19:58.840886 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:19:58.840893 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:19:58.840899 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:19:58.840905 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:19:58.840911 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:19:58.840917 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:19:58.840924 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:19:58.840931 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:19:58.840935 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:19:58.840941 16790 net.cpp:676] Ignoring source layer grl
I0829 16:19:58.840946 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:19:58.840952 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:19:58.840956 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:19:58.840962 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:19:58.840967 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:19:58.840971 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:19:58.840978 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:19:58.840983 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:19:58.840991 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:19:58.840996 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:19:58.841001 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:19:58.841006 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:19:58.841015 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:19:58.841020 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:19:58.841027 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:19:58.841032 16790 net.cpp:676] Ignoring source layer loss
I0829 16:19:58.841037 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:19:58.841042 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:20:05.153867 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:20:06.007012 16790 solver.cpp:414]     Test net output #0: accuracy = 0.911647
I0829 16:20:06.282815 16790 solver.cpp:239] Iteration 100 (0.668752 iter/s, 14.9532s/10 iters), loss = 1.89631
I0829 16:20:06.282858 16790 solver.cpp:258]     Train net output #0: accuracy = 0.902344
I0829 16:20:06.282869 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.842927 (* 0.3 = 0.252878 loss)
I0829 16:20:06.282874 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:20:06.282881 16790 solver.cpp:258]     Train net output #3: entropy = 1.24691 (* 0.8 = 0.997532 loss)
I0829 16:20:06.282886 16790 solver.cpp:258]     Train net output #4: loss = 0.645905 (* 1 = 0.645905 loss)
I0829 16:20:06.282893 16790 sgd_solver.cpp:112] Iteration 100, lr = 0.000931013
I0829 16:20:13.361907 16790 solver.cpp:239] Iteration 110 (1.4127 iter/s, 7.07862s/10 iters), loss = 1.95329
I0829 16:20:13.361949 16790 solver.cpp:258]     Train net output #0: accuracy = 0.863281
I0829 16:20:13.361960 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.826127 (* 0.3 = 0.247838 loss)
I0829 16:20:13.361965 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:20:13.361994 16790 solver.cpp:258]     Train net output #3: entropy = 1.22636 (* 0.8 = 0.981091 loss)
I0829 16:20:13.361999 16790 solver.cpp:258]     Train net output #4: loss = 0.724363 (* 1 = 0.724363 loss)
I0829 16:20:13.362007 16790 sgd_solver.cpp:112] Iteration 110, lr = 0.000924715
I0829 16:20:20.779753 16790 solver.cpp:347] Iteration 120, Testing net (#0)
I0829 16:20:20.779772 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:20:20.779778 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:20:20.779780 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:20:20.779783 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:20:20.779786 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:20:20.779790 16790 net.cpp:676] Ignoring source layer label
I0829 16:20:20.779793 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:20:20.779796 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:20:20.779800 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:20:20.779808 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:20:20.779812 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:20:20.779820 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:20:20.779825 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:20:20.779834 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:20:20.779837 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:20:20.779844 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:20:20.779850 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:20:20.779853 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:20:20.779860 16790 net.cpp:676] Ignoring source layer grl
I0829 16:20:20.779862 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:20:20.779866 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:20:20.779872 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:20:20.779877 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:20:20.779882 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:20:20.779888 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:20:20.779893 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:20:20.779897 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:20:20.779903 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:20:20.779907 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:20:20.779914 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:20:20.779918 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:20:20.779923 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:20:20.779929 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:20:20.779932 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:20:20.779938 16790 net.cpp:676] Ignoring source layer loss
I0829 16:20:20.779942 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:20:20.779947 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:20:26.456862 16790 solver.cpp:414]     Test net output #0: accuracy = 0.921687
I0829 16:20:26.743165 16790 solver.cpp:239] Iteration 120 (0.74736 iter/s, 13.3804s/10 iters), loss = 1.76059
I0829 16:20:26.743252 16790 solver.cpp:258]     Train net output #0: accuracy = 0.886719
I0829 16:20:26.743294 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.566796 (* 0.3 = 0.170039 loss)
I0829 16:20:26.743309 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:20:26.743322 16790 solver.cpp:258]     Train net output #3: entropy = 1.11761 (* 0.8 = 0.894092 loss)
I0829 16:20:26.743331 16790 solver.cpp:258]     Train net output #4: loss = 0.696456 (* 1 = 0.696456 loss)
I0829 16:20:26.743341 16790 sgd_solver.cpp:112] Iteration 120, lr = 0.000918516
I0829 16:20:33.525291 16790 solver.cpp:239] Iteration 130 (1.47457 iter/s, 6.78164s/10 iters), loss = 1.80152
I0829 16:20:33.525420 16790 solver.cpp:258]     Train net output #0: accuracy = 0.886719
I0829 16:20:33.525434 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.605582 (* 0.3 = 0.181674 loss)
I0829 16:20:33.525439 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:20:33.525445 16790 solver.cpp:258]     Train net output #3: entropy = 1.1723 (* 0.8 = 0.937841 loss)
I0829 16:20:33.525450 16790 solver.cpp:258]     Train net output #4: loss = 0.682001 (* 1 = 0.682001 loss)
I0829 16:20:33.525460 16790 sgd_solver.cpp:112] Iteration 130, lr = 0.000912412
I0829 16:20:40.962033 16790 solver.cpp:347] Iteration 140, Testing net (#0)
I0829 16:20:40.962062 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:20:40.962067 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:20:40.962071 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:20:40.962075 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:20:40.962080 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:20:40.962085 16790 net.cpp:676] Ignoring source layer label
I0829 16:20:40.962090 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:20:40.962095 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:20:40.962100 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:20:40.962113 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:20:40.962121 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:20:40.962126 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:20:40.962134 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:20:40.962138 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:20:40.962144 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:20:40.962150 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:20:40.962158 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:20:40.962162 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:20:40.962167 16790 net.cpp:676] Ignoring source layer grl
I0829 16:20:40.962172 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:20:40.962178 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:20:40.962182 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:20:40.962191 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:20:40.962195 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:20:40.962200 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:20:40.962208 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:20:40.962211 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:20:40.962215 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:20:40.962224 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:20:40.962230 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:20:40.962236 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:20:40.962241 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:20:40.962249 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:20:40.962254 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:20:40.962261 16790 net.cpp:676] Ignoring source layer loss
I0829 16:20:40.962265 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:20:40.962272 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:20:45.750444 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:20:46.596192 16790 solver.cpp:414]     Test net output #0: accuracy = 0.913655
I0829 16:20:46.862151 16790 solver.cpp:239] Iteration 140 (0.749852 iter/s, 13.336s/10 iters), loss = 1.68261
I0829 16:20:46.862211 16790 solver.cpp:258]     Train net output #0: accuracy = 0.871094
I0829 16:20:46.862226 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.638532 (* 0.3 = 0.19156 loss)
I0829 16:20:46.862234 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:20:46.862243 16790 solver.cpp:258]     Train net output #3: entropy = 1.00136 (* 0.8 = 0.801089 loss)
I0829 16:20:46.862274 16790 solver.cpp:258]     Train net output #4: loss = 0.689959 (* 1 = 0.689959 loss)
I0829 16:20:46.862285 16790 sgd_solver.cpp:112] Iteration 140, lr = 0.000906403
I0829 16:20:53.476131 16790 solver.cpp:239] Iteration 150 (1.51205 iter/s, 6.61353s/10 iters), loss = 1.58588
I0829 16:20:53.476173 16790 solver.cpp:258]     Train net output #0: accuracy = 0.886719
I0829 16:20:53.476188 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.684466 (* 0.3 = 0.20534 loss)
I0829 16:20:53.476195 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:20:53.476203 16790 solver.cpp:258]     Train net output #3: entropy = 0.972758 (* 0.8 = 0.778206 loss)
I0829 16:20:53.476212 16790 solver.cpp:258]     Train net output #4: loss = 0.602332 (* 1 = 0.602332 loss)
I0829 16:20:53.476223 16790 sgd_solver.cpp:112] Iteration 150, lr = 0.000900485
I0829 16:21:00.911105 16790 solver.cpp:347] Iteration 160, Testing net (#0)
I0829 16:21:00.911134 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:21:00.911139 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:21:00.911144 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:21:00.911149 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:21:00.911154 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:21:00.911159 16790 net.cpp:676] Ignoring source layer label
I0829 16:21:00.911164 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:21:00.911168 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:21:00.911172 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:21:00.911185 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:21:00.911192 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:21:00.911198 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:21:00.911206 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:21:00.911209 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:21:00.911217 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:21:00.911223 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:21:00.911231 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:21:00.911234 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:21:00.911242 16790 net.cpp:676] Ignoring source layer grl
I0829 16:21:00.911247 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:21:00.911250 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:21:00.911254 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:21:00.911259 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:21:00.911263 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:21:00.911268 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:21:00.911273 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:21:00.911281 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:21:00.911286 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:21:00.911290 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:21:00.911295 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:21:00.911301 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:21:00.911306 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:21:00.911311 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:21:00.911319 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:21:00.911324 16790 net.cpp:676] Ignoring source layer loss
I0829 16:21:00.911327 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:21:00.911334 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:21:06.736519 16790 solver.cpp:414]     Test net output #0: accuracy = 0.927711
I0829 16:21:07.004500 16790 solver.cpp:239] Iteration 160 (0.739232 iter/s, 13.5275s/10 iters), loss = 1.55282
I0829 16:21:07.004561 16790 solver.cpp:258]     Train net output #0: accuracy = 0.9375
I0829 16:21:07.004578 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.673339 (* 0.3 = 0.202002 loss)
I0829 16:21:07.004585 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:21:07.004595 16790 solver.cpp:258]     Train net output #3: entropy = 1.03776 (* 0.8 = 0.830208 loss)
I0829 16:21:07.004604 16790 solver.cpp:258]     Train net output #4: loss = 0.520611 (* 1 = 0.520611 loss)
I0829 16:21:07.004616 16790 sgd_solver.cpp:112] Iteration 160, lr = 0.000894657
I0829 16:21:13.669132 16790 solver.cpp:239] Iteration 170 (1.50056 iter/s, 6.66418s/10 iters), loss = 1.48935
I0829 16:21:13.669181 16790 solver.cpp:258]     Train net output #0: accuracy = 0.902344
I0829 16:21:13.669196 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.694456 (* 0.3 = 0.208337 loss)
I0829 16:21:13.669204 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:21:13.669216 16790 solver.cpp:258]     Train net output #3: entropy = 0.87768 (* 0.8 = 0.702144 loss)
I0829 16:21:13.669226 16790 solver.cpp:258]     Train net output #4: loss = 0.578872 (* 1 = 0.578872 loss)
I0829 16:21:13.669237 16790 sgd_solver.cpp:112] Iteration 170, lr = 0.000888916
I0829 16:21:21.356226 16790 solver.cpp:347] Iteration 180, Testing net (#0)
I0829 16:21:21.356246 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:21:21.356251 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:21:21.356254 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:21:21.356256 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:21:21.356259 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:21:21.356263 16790 net.cpp:676] Ignoring source layer label
I0829 16:21:21.356266 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:21:21.356269 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:21:21.356272 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:21:21.356281 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:21:21.356284 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:21:21.356288 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:21:21.356294 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:21:21.356298 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:21:21.356302 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:21:21.356307 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:21:21.356310 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:21:21.356314 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:21:21.356317 16790 net.cpp:676] Ignoring source layer grl
I0829 16:21:21.356321 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:21:21.356325 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:21:21.356329 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:21:21.356333 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:21:21.356336 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:21:21.356340 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:21:21.356346 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:21:21.356349 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:21:21.356353 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:21:21.356356 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:21:21.356362 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:21:21.356366 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:21:21.356371 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:21:21.356389 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:21:21.356393 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:21:21.356415 16790 net.cpp:676] Ignoring source layer loss
I0829 16:21:21.356418 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:21:21.356421 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:21:26.072065 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:21:27.209794 16790 solver.cpp:414]     Test net output #0: accuracy = 0.925703
I0829 16:21:27.494192 16790 solver.cpp:239] Iteration 180 (0.723369 iter/s, 13.8242s/10 iters), loss = 1.40232
I0829 16:21:27.494402 16790 solver.cpp:258]     Train net output #0: accuracy = 0.945312
I0829 16:21:27.494479 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.679641 (* 0.3 = 0.203892 loss)
I0829 16:21:27.494559 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:21:27.494633 16790 solver.cpp:258]     Train net output #3: entropy = 0.913001 (* 0.8 = 0.730401 loss)
I0829 16:21:27.494704 16790 solver.cpp:258]     Train net output #4: loss = 0.468027 (* 1 = 0.468027 loss)
I0829 16:21:27.494778 16790 sgd_solver.cpp:112] Iteration 180, lr = 0.00088326
I0829 16:21:35.172302 16790 solver.cpp:239] Iteration 190 (1.30251 iter/s, 7.67746s/10 iters), loss = 1.61677
I0829 16:21:35.172338 16790 solver.cpp:258]     Train net output #0: accuracy = 0.914062
I0829 16:21:35.172349 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.684549 (* 0.3 = 0.205365 loss)
I0829 16:21:35.172355 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:21:35.172361 16790 solver.cpp:258]     Train net output #3: entropy = 1.07487 (* 0.8 = 0.859894 loss)
I0829 16:21:35.172368 16790 solver.cpp:258]     Train net output #4: loss = 0.551507 (* 1 = 0.551507 loss)
I0829 16:21:35.172374 16790 sgd_solver.cpp:112] Iteration 190, lr = 0.000877687
I0829 16:21:42.981884 16790 solver.cpp:347] Iteration 200, Testing net (#0)
I0829 16:21:42.981988 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:21:42.981993 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:21:42.981997 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:21:42.981999 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:21:42.982002 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:21:42.982007 16790 net.cpp:676] Ignoring source layer label
I0829 16:21:42.982012 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:21:42.982015 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:21:42.982019 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:21:42.982030 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:21:42.982034 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:21:42.982040 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:21:42.982045 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:21:42.982048 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:21:42.982051 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:21:42.982058 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:21:42.982060 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:21:42.982064 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:21:42.982067 16790 net.cpp:676] Ignoring source layer grl
I0829 16:21:42.982072 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:21:42.982079 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:21:42.982084 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:21:42.982089 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:21:42.982092 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:21:42.982096 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:21:42.982101 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:21:42.982105 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:21:42.982108 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:21:42.982111 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:21:42.982120 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:21:42.982123 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:21:42.982129 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:21:42.982134 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:21:42.982137 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:21:42.982141 16790 net.cpp:676] Ignoring source layer loss
I0829 16:21:42.982146 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:21:42.982153 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:21:48.719017 16790 solver.cpp:414]     Test net output #0: accuracy = 0.923695
I0829 16:21:48.985889 16790 solver.cpp:239] Iteration 200 (0.723969 iter/s, 13.8128s/10 iters), loss = 1.41469
I0829 16:21:48.985981 16790 solver.cpp:258]     Train net output #0: accuracy = 0.886719
I0829 16:21:48.986016 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.665314 (* 0.3 = 0.199594 loss)
I0829 16:21:48.986039 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:21:48.986065 16790 solver.cpp:258]     Train net output #3: entropy = 0.838765 (* 0.8 = 0.671012 loss)
I0829 16:21:48.986090 16790 solver.cpp:258]     Train net output #4: loss = 0.544088 (* 1 = 0.544088 loss)
I0829 16:21:48.986116 16790 sgd_solver.cpp:112] Iteration 200, lr = 0.000872196
I0829 16:21:55.885205 16790 solver.cpp:239] Iteration 210 (1.44952 iter/s, 6.89882s/10 iters), loss = 1.39553
I0829 16:21:55.885246 16790 solver.cpp:258]     Train net output #0: accuracy = 0.921875
I0829 16:21:55.885257 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.627664 (* 0.3 = 0.188299 loss)
I0829 16:21:55.885262 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:21:55.885269 16790 solver.cpp:258]     Train net output #3: entropy = 0.861233 (* 0.8 = 0.688987 loss)
I0829 16:21:55.885294 16790 solver.cpp:258]     Train net output #4: loss = 0.518242 (* 1 = 0.518242 loss)
I0829 16:21:55.885304 16790 sgd_solver.cpp:112] Iteration 210, lr = 0.000866784
I0829 16:22:03.315898 16790 solver.cpp:347] Iteration 220, Testing net (#0)
I0829 16:22:03.315919 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:22:03.315924 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:22:03.315927 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:22:03.315930 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:22:03.315933 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:22:03.315937 16790 net.cpp:676] Ignoring source layer label
I0829 16:22:03.315940 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:22:03.315943 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:22:03.315946 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:22:03.315955 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:22:03.315959 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:22:03.315963 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:22:03.315968 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:22:03.315970 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:22:03.315975 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:22:03.315979 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:22:03.315984 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:22:03.315986 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:22:03.315990 16790 net.cpp:676] Ignoring source layer grl
I0829 16:22:03.315992 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:22:03.315996 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:22:03.315999 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:22:03.316004 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:22:03.316007 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:22:03.316010 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:22:03.316013 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:22:03.316018 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:22:03.316021 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:22:03.316025 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:22:03.316030 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:22:03.316035 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:22:03.316038 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:22:03.316042 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:22:03.316045 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:22:03.316049 16790 net.cpp:676] Ignoring source layer loss
I0829 16:22:03.316056 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:22:03.316061 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:22:07.564793 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:22:08.898438 16790 solver.cpp:414]     Test net output #0: accuracy = 0.927711
I0829 16:22:09.163975 16790 solver.cpp:239] Iteration 220 (0.753127 iter/s, 13.278s/10 iters), loss = 1.37896
I0829 16:22:09.164029 16790 solver.cpp:258]     Train net output #0: accuracy = 0.933594
I0829 16:22:09.164046 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.668117 (* 0.3 = 0.200435 loss)
I0829 16:22:09.164053 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:22:09.164063 16790 solver.cpp:258]     Train net output #3: entropy = 0.863267 (* 0.8 = 0.690614 loss)
I0829 16:22:09.164073 16790 solver.cpp:258]     Train net output #4: loss = 0.487915 (* 1 = 0.487915 loss)
I0829 16:22:09.164083 16790 sgd_solver.cpp:112] Iteration 220, lr = 0.00086145
I0829 16:22:15.849495 16790 solver.cpp:239] Iteration 230 (1.49587 iter/s, 6.68507s/10 iters), loss = 1.32093
I0829 16:22:15.849617 16790 solver.cpp:258]     Train net output #0: accuracy = 0.921875
I0829 16:22:15.849630 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.687701 (* 0.3 = 0.20631 loss)
I0829 16:22:15.849637 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:22:15.849643 16790 solver.cpp:258]     Train net output #3: entropy = 0.81439 (* 0.8 = 0.651512 loss)
I0829 16:22:15.849650 16790 solver.cpp:258]     Train net output #4: loss = 0.463103 (* 1 = 0.463103 loss)
I0829 16:22:15.849658 16790 sgd_solver.cpp:112] Iteration 230, lr = 0.000856192
I0829 16:22:23.579541 16790 solver.cpp:347] Iteration 240, Testing net (#0)
I0829 16:22:23.579562 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:22:23.579566 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:22:23.579569 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:22:23.579572 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:22:23.579576 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:22:23.579579 16790 net.cpp:676] Ignoring source layer label
I0829 16:22:23.579582 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:22:23.579586 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:22:23.579588 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:22:23.579596 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:22:23.579601 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:22:23.579603 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:22:23.579608 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:22:23.579612 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:22:23.579615 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:22:23.579620 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:22:23.579625 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:22:23.579628 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:22:23.579632 16790 net.cpp:676] Ignoring source layer grl
I0829 16:22:23.579635 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:22:23.579639 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:22:23.579643 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:22:23.579646 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:22:23.579650 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:22:23.579653 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:22:23.579658 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:22:23.579663 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:22:23.579666 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:22:23.579670 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:22:23.579674 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:22:23.579679 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:22:23.579682 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:22:23.579687 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:22:23.579690 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:22:23.579694 16790 net.cpp:676] Ignoring source layer loss
I0829 16:22:23.579699 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:22:23.579701 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:22:29.281723 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:22:29.566596 16790 solver.cpp:239] Iteration 240 (0.729065 iter/s, 13.7162s/10 iters), loss = 1.20872
I0829 16:22:29.566689 16790 solver.cpp:258]     Train net output #0: accuracy = 0.9375
I0829 16:22:29.566715 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.686919 (* 0.3 = 0.206076 loss)
I0829 16:22:29.566723 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:22:29.566732 16790 solver.cpp:258]     Train net output #3: entropy = 0.717397 (* 0.8 = 0.573918 loss)
I0829 16:22:29.566766 16790 solver.cpp:258]     Train net output #4: loss = 0.428723 (* 1 = 0.428723 loss)
I0829 16:22:29.566778 16790 sgd_solver.cpp:112] Iteration 240, lr = 0.000851008
I0829 16:22:36.151185 16790 solver.cpp:239] Iteration 250 (1.51881 iter/s, 6.58411s/10 iters), loss = 1.22693
I0829 16:22:36.151228 16790 solver.cpp:258]     Train net output #0: accuracy = 0.929688
I0829 16:22:36.151239 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.693131 (* 0.3 = 0.207939 loss)
I0829 16:22:36.151247 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:22:36.151252 16790 solver.cpp:258]     Train net output #3: entropy = 0.717322 (* 0.8 = 0.573857 loss)
I0829 16:22:36.151258 16790 solver.cpp:258]     Train net output #4: loss = 0.445136 (* 1 = 0.445136 loss)
I0829 16:22:36.151265 16790 sgd_solver.cpp:112] Iteration 250, lr = 0.000845897
I0829 16:22:43.444891 16790 solver.cpp:347] Iteration 260, Testing net (#0)
I0829 16:22:43.444912 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:22:43.444917 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:22:43.444921 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:22:43.444924 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:22:43.444927 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:22:43.444931 16790 net.cpp:676] Ignoring source layer label
I0829 16:22:43.444934 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:22:43.444937 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:22:43.444941 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:22:43.444949 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:22:43.444957 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:22:43.444964 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:22:43.444969 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:22:43.444974 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:22:43.444978 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:22:43.444984 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:22:43.444989 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:22:43.444994 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:22:43.444998 16790 net.cpp:676] Ignoring source layer grl
I0829 16:22:43.445003 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:22:43.445006 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:22:43.445010 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:22:43.445014 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:22:43.445019 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:22:43.445024 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:22:43.445027 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:22:43.445031 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:22:43.445035 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:22:43.445040 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:22:43.445047 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:22:43.445051 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:22:43.445056 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:22:43.445061 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:22:43.445066 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:22:43.445075 16790 net.cpp:676] Ignoring source layer loss
I0829 16:22:43.445080 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:22:43.445085 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:22:47.220424 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:22:48.793437 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:22:49.059937 16790 solver.cpp:239] Iteration 260 (0.774715 iter/s, 12.908s/10 iters), loss = 1.36041
I0829 16:22:49.060000 16790 solver.cpp:258]     Train net output #0: accuracy = 0.929688
I0829 16:22:49.060022 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.691508 (* 0.3 = 0.207452 loss)
I0829 16:22:49.060030 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:22:49.060043 16790 solver.cpp:258]     Train net output #3: entropy = 0.870018 (* 0.8 = 0.696014 loss)
I0829 16:22:49.060052 16790 solver.cpp:258]     Train net output #4: loss = 0.456947 (* 1 = 0.456947 loss)
I0829 16:22:49.060062 16790 sgd_solver.cpp:112] Iteration 260, lr = 0.000840857
I0829 16:22:56.255386 16790 solver.cpp:239] Iteration 270 (1.38986 iter/s, 7.19498s/10 iters), loss = 1.23012
I0829 16:22:56.255429 16790 solver.cpp:258]     Train net output #0: accuracy = 0.921875
I0829 16:22:56.255442 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.679685 (* 0.3 = 0.203906 loss)
I0829 16:22:56.255448 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:22:56.255457 16790 solver.cpp:258]     Train net output #3: entropy = 0.721403 (* 0.8 = 0.577123 loss)
I0829 16:22:56.255492 16790 solver.cpp:258]     Train net output #4: loss = 0.449092 (* 1 = 0.449092 loss)
I0829 16:22:56.255517 16790 sgd_solver.cpp:112] Iteration 270, lr = 0.000835886
I0829 16:23:04.422468 16790 solver.cpp:347] Iteration 280, Testing net (#0)
I0829 16:23:04.422490 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:23:04.422494 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:23:04.422497 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:23:04.422500 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:23:04.422503 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:23:04.422508 16790 net.cpp:676] Ignoring source layer label
I0829 16:23:04.422510 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:23:04.422513 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:23:04.422515 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:23:04.422523 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:23:04.422528 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:23:04.422530 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:23:04.422536 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:23:04.422540 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:23:04.422544 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:23:04.422549 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:23:04.422551 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:23:04.422555 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:23:04.422559 16790 net.cpp:676] Ignoring source layer grl
I0829 16:23:04.422561 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:23:04.422564 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:23:04.422569 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:23:04.422571 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:23:04.422575 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:23:04.422577 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:23:04.422582 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:23:04.422585 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:23:04.422588 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:23:04.422592 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:23:04.422597 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:23:04.422600 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:23:04.422605 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:23:04.422610 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:23:04.422633 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:23:04.422637 16790 net.cpp:676] Ignoring source layer loss
I0829 16:23:04.422641 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:23:04.422644 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:23:09.990631 16790 solver.cpp:414]     Test net output #0: accuracy = 0.931727
I0829 16:23:10.257330 16790 solver.cpp:239] Iteration 280 (0.714229 iter/s, 14.0011s/10 iters), loss = 1.19109
I0829 16:23:10.257381 16790 solver.cpp:258]     Train net output #0: accuracy = 0.945312
I0829 16:23:10.257402 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.680622 (* 0.3 = 0.204187 loss)
I0829 16:23:10.257412 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:23:10.257421 16790 solver.cpp:258]     Train net output #3: entropy = 0.732971 (* 0.8 = 0.586377 loss)
I0829 16:23:10.257429 16790 solver.cpp:258]     Train net output #4: loss = 0.400524 (* 1 = 0.400524 loss)
I0829 16:23:10.257439 16790 sgd_solver.cpp:112] Iteration 280, lr = 0.000830984
I0829 16:23:17.276301 16790 solver.cpp:239] Iteration 290 (1.4248 iter/s, 7.01852s/10 iters), loss = 1.16266
I0829 16:23:17.276415 16790 solver.cpp:258]     Train net output #0: accuracy = 0.949219
I0829 16:23:17.276430 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.662254 (* 0.3 = 0.198676 loss)
I0829 16:23:17.276435 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:23:17.276444 16790 solver.cpp:258]     Train net output #3: entropy = 0.692009 (* 0.8 = 0.553607 loss)
I0829 16:23:17.276450 16790 solver.cpp:258]     Train net output #4: loss = 0.410382 (* 1 = 0.410382 loss)
I0829 16:23:17.276460 16790 sgd_solver.cpp:112] Iteration 290, lr = 0.000826148
I0829 16:23:24.842584 16790 solver.cpp:347] Iteration 300, Testing net (#0)
I0829 16:23:24.842609 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:23:24.842615 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:23:24.842619 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:23:24.842623 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:23:24.842628 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:23:24.842633 16790 net.cpp:676] Ignoring source layer label
I0829 16:23:24.842638 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:23:24.842641 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:23:24.842648 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:23:24.842656 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:23:24.842661 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:23:24.842666 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:23:24.842674 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:23:24.842679 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:23:24.842684 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:23:24.842689 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:23:24.842697 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:23:24.842701 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:23:24.842706 16790 net.cpp:676] Ignoring source layer grl
I0829 16:23:24.842710 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:23:24.842716 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:23:24.842720 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:23:24.842725 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:23:24.842730 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:23:24.842737 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:23:24.842742 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:23:24.842746 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:23:24.842751 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:23:24.842759 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:23:24.842764 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:23:24.842769 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:23:24.842773 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:23:24.842779 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:23:24.842785 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:23:24.842789 16790 net.cpp:676] Ignoring source layer loss
I0829 16:23:24.842793 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:23:24.842798 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:23:28.478410 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:23:30.318596 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:23:30.609987 16790 solver.cpp:239] Iteration 300 (0.750029 iter/s, 13.3328s/10 iters), loss = 1.17781
I0829 16:23:30.616750 16790 solver.cpp:258]     Train net output #0: accuracy = 0.933594
I0829 16:23:30.616780 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.68286 (* 0.3 = 0.204858 loss)
I0829 16:23:30.616787 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:23:30.616796 16790 solver.cpp:258]     Train net output #3: entropy = 0.699979 (* 0.8 = 0.559984 loss)
I0829 16:23:30.616837 16790 solver.cpp:258]     Train net output #4: loss = 0.412973 (* 1 = 0.412973 loss)
I0829 16:23:30.616847 16790 sgd_solver.cpp:112] Iteration 300, lr = 0.000821377
I0829 16:23:37.102952 16790 solver.cpp:239] Iteration 310 (1.54182 iter/s, 6.48582s/10 iters), loss = 1.11158
I0829 16:23:37.102991 16790 solver.cpp:258]     Train net output #0: accuracy = 0.941406
I0829 16:23:37.103003 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.688026 (* 0.3 = 0.206408 loss)
I0829 16:23:37.103009 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:23:37.103016 16790 solver.cpp:258]     Train net output #3: entropy = 0.630709 (* 0.8 = 0.504567 loss)
I0829 16:23:37.103022 16790 solver.cpp:258]     Train net output #4: loss = 0.400609 (* 1 = 0.400609 loss)
I0829 16:23:37.103032 16790 sgd_solver.cpp:112] Iteration 310, lr = 0.00081667
I0829 16:23:45.510344 16790 solver.cpp:347] Iteration 320, Testing net (#0)
I0829 16:23:45.510363 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:23:45.510367 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:23:45.510371 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:23:45.510375 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:23:45.510378 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:23:45.510383 16790 net.cpp:676] Ignoring source layer label
I0829 16:23:45.510386 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:23:45.510390 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:23:45.510393 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:23:45.510402 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:23:45.510406 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:23:45.510411 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:23:45.510416 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:23:45.510419 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:23:45.510423 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:23:45.510428 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:23:45.510432 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:23:45.510437 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:23:45.510440 16790 net.cpp:676] Ignoring source layer grl
I0829 16:23:45.510443 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:23:45.510447 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:23:45.510452 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:23:45.510457 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:23:45.510460 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:23:45.510464 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:23:45.510468 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:23:45.510471 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:23:45.510478 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:23:45.510481 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:23:45.510485 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:23:45.510490 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:23:45.510496 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:23:45.510501 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:23:45.510505 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:23:45.510509 16790 net.cpp:676] Ignoring source layer loss
I0829 16:23:45.510512 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:23:45.510516 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:23:50.733321 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:23:50.997225 16790 solver.cpp:239] Iteration 320 (0.719763 iter/s, 13.8935s/10 iters), loss = 1.22754
I0829 16:23:50.997290 16790 solver.cpp:258]     Train net output #0: accuracy = 0.910156
I0829 16:23:50.997305 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.6789 (* 0.3 = 0.20367 loss)
I0829 16:23:50.997314 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:23:50.997325 16790 solver.cpp:258]     Train net output #3: entropy = 0.681927 (* 0.8 = 0.545542 loss)
I0829 16:23:50.997334 16790 solver.cpp:258]     Train net output #4: loss = 0.478331 (* 1 = 0.478331 loss)
I0829 16:23:50.997344 16790 sgd_solver.cpp:112] Iteration 320, lr = 0.000812025
I0829 16:23:57.742111 16790 solver.cpp:239] Iteration 330 (1.4827 iter/s, 6.74444s/10 iters), loss = 1.17291
I0829 16:23:57.742152 16790 solver.cpp:258]     Train net output #0: accuracy = 0.9375
I0829 16:23:57.742166 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.691141 (* 0.3 = 0.207342 loss)
I0829 16:23:57.742173 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:23:57.742184 16790 solver.cpp:258]     Train net output #3: entropy = 0.684755 (* 0.8 = 0.547804 loss)
I0829 16:23:57.742194 16790 solver.cpp:258]     Train net output #4: loss = 0.417761 (* 1 = 0.417761 loss)
I0829 16:23:57.742205 16790 sgd_solver.cpp:112] Iteration 330, lr = 0.000807442
I0829 16:24:04.853166 16790 solver.cpp:347] Iteration 340, Testing net (#0)
I0829 16:24:04.853188 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:24:04.853193 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:24:04.853196 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:24:04.853199 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:24:04.853201 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:24:04.853207 16790 net.cpp:676] Ignoring source layer label
I0829 16:24:04.853209 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:24:04.853214 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:24:04.853217 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:24:04.853227 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:24:04.853231 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:24:04.853235 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:24:04.853241 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:24:04.853248 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:24:04.853252 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:24:04.853257 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:24:04.853260 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:24:04.853265 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:24:04.853267 16790 net.cpp:676] Ignoring source layer grl
I0829 16:24:04.853271 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:24:04.853274 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:24:04.853279 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:24:04.853283 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:24:04.853287 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:24:04.853292 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:24:04.853296 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:24:04.853301 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:24:04.853304 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:24:04.853309 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:24:04.853317 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:24:04.853320 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:24:04.853325 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:24:04.853332 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:24:04.853335 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:24:04.853354 16790 net.cpp:676] Ignoring source layer loss
I0829 16:24:04.853358 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:24:04.853363 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:24:09.740042 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:24:12.275143 16790 solver.cpp:414]     Test net output #0: accuracy = 0.927711
I0829 16:24:12.540210 16790 solver.cpp:239] Iteration 340 (0.675802 iter/s, 14.7972s/10 iters), loss = 1.05659
I0829 16:24:12.540297 16790 solver.cpp:258]     Train net output #0: accuracy = 0.949219
I0829 16:24:12.540309 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.699214 (* 0.3 = 0.209764 loss)
I0829 16:24:12.540316 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:24:12.540323 16790 solver.cpp:258]     Train net output #3: entropy = 0.615253 (* 0.8 = 0.492203 loss)
I0829 16:24:12.540330 16790 solver.cpp:258]     Train net output #4: loss = 0.354626 (* 1 = 0.354626 loss)
I0829 16:24:12.540340 16790 sgd_solver.cpp:112] Iteration 340, lr = 0.000802918
I0829 16:24:18.936024 16790 solver.cpp:239] Iteration 350 (1.56363 iter/s, 6.39536s/10 iters), loss = 1.11031
I0829 16:24:18.936064 16790 solver.cpp:258]     Train net output #0: accuracy = 0.945312
I0829 16:24:18.936074 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.665602 (* 0.3 = 0.199681 loss)
I0829 16:24:18.936080 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:24:18.936098 16790 solver.cpp:258]     Train net output #3: entropy = 0.658596 (* 0.8 = 0.526877 loss)
I0829 16:24:18.936107 16790 solver.cpp:258]     Train net output #4: loss = 0.383756 (* 1 = 0.383756 loss)
I0829 16:24:18.936117 16790 sgd_solver.cpp:112] Iteration 350, lr = 0.000798454
I0829 16:24:25.987956 16790 solver.cpp:347] Iteration 360, Testing net (#0)
I0829 16:24:25.988061 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:24:25.988066 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:24:25.988070 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:24:25.988073 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:24:25.988076 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:24:25.988080 16790 net.cpp:676] Ignoring source layer label
I0829 16:24:25.988085 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:24:25.988088 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:24:25.988091 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:24:25.988101 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:24:25.988106 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:24:25.988111 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:24:25.988116 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:24:25.988121 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:24:25.988126 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:24:25.988131 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:24:25.988135 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:24:25.988139 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:24:25.988142 16790 net.cpp:676] Ignoring source layer grl
I0829 16:24:25.988147 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:24:25.988150 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:24:25.988155 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:24:25.988159 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:24:25.988163 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:24:25.988170 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:24:25.988174 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:24:25.988178 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:24:25.988183 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:24:25.988188 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:24:25.988191 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:24:25.988194 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:24:25.988199 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:24:25.988204 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:24:25.988209 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:24:25.988212 16790 net.cpp:676] Ignoring source layer loss
I0829 16:24:25.988216 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:24:25.988220 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:24:32.651202 16790 solver.cpp:414]     Test net output #0: accuracy = 0.927711
I0829 16:24:32.931973 16790 solver.cpp:239] Iteration 360 (0.714534 iter/s, 13.9951s/10 iters), loss = 1.11034
I0829 16:24:32.932060 16790 solver.cpp:258]     Train net output #0: accuracy = 0.9375
I0829 16:24:32.932082 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.669401 (* 0.3 = 0.20082 loss)
I0829 16:24:32.932091 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:24:32.932102 16790 solver.cpp:258]     Train net output #3: entropy = 0.64083 (* 0.8 = 0.512664 loss)
I0829 16:24:32.932116 16790 solver.cpp:258]     Train net output #4: loss = 0.396859 (* 1 = 0.396859 loss)
I0829 16:24:32.932126 16790 sgd_solver.cpp:112] Iteration 360, lr = 0.000794046
I0829 16:24:39.179409 16790 solver.cpp:239] Iteration 370 (1.60077 iter/s, 6.24699s/10 iters), loss = 1.05466
I0829 16:24:39.179445 16790 solver.cpp:258]     Train net output #0: accuracy = 0.957031
I0829 16:24:39.179456 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.677415 (* 0.3 = 0.203224 loss)
I0829 16:24:39.179461 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:24:39.179467 16790 solver.cpp:258]     Train net output #3: entropy = 0.626644 (* 0.8 = 0.501315 loss)
I0829 16:24:39.179491 16790 solver.cpp:258]     Train net output #4: loss = 0.350117 (* 1 = 0.350117 loss)
I0829 16:24:39.179499 16790 sgd_solver.cpp:112] Iteration 370, lr = 0.000789695
I0829 16:24:46.154513 16790 solver.cpp:347] Iteration 380, Testing net (#0)
I0829 16:24:46.154536 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:24:46.154541 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:24:46.154546 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:24:46.154551 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:24:46.154554 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:24:46.154561 16790 net.cpp:676] Ignoring source layer label
I0829 16:24:46.154570 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:24:46.154575 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:24:46.154579 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:24:46.154589 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:24:46.154594 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:24:46.154599 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:24:46.154604 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:24:46.154609 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:24:46.154614 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:24:46.154620 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:24:46.154624 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:24:46.154629 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:24:46.154634 16790 net.cpp:676] Ignoring source layer grl
I0829 16:24:46.154639 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:24:46.154642 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:24:46.154646 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:24:46.154651 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:24:46.154655 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:24:46.154660 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:24:46.154665 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:24:46.154671 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:24:46.154676 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:24:46.154680 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:24:46.154686 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:24:46.154695 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:24:46.154702 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:24:46.154707 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:24:46.154711 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:24:46.154717 16790 net.cpp:676] Ignoring source layer loss
I0829 16:24:46.154721 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:24:46.154726 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:24:49.321864 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:24:51.658509 16790 solver.cpp:414]     Test net output #0: accuracy = 0.927711
I0829 16:24:51.927868 16790 solver.cpp:239] Iteration 380 (0.784455 iter/s, 12.7477s/10 iters), loss = 0.981983
I0829 16:24:51.927924 16790 solver.cpp:258]     Train net output #0: accuracy = 0.9375
I0829 16:24:51.927943 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.679772 (* 0.3 = 0.203932 loss)
I0829 16:24:51.927953 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:24:51.927963 16790 solver.cpp:258]     Train net output #3: entropy = 0.514503 (* 0.8 = 0.411603 loss)
I0829 16:24:51.927971 16790 solver.cpp:258]     Train net output #4: loss = 0.366449 (* 1 = 0.366449 loss)
I0829 16:24:51.927981 16790 sgd_solver.cpp:112] Iteration 380, lr = 0.0007854
I0829 16:24:58.290819 16790 solver.cpp:239] Iteration 390 (1.5717 iter/s, 6.36254s/10 iters), loss = 1.02389
I0829 16:24:58.290942 16790 solver.cpp:258]     Train net output #0: accuracy = 0.960938
I0829 16:24:58.290953 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.694359 (* 0.3 = 0.208308 loss)
I0829 16:24:58.290958 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:24:58.290966 16790 solver.cpp:258]     Train net output #3: entropy = 0.573204 (* 0.8 = 0.458563 loss)
I0829 16:24:58.290971 16790 solver.cpp:258]     Train net output #4: loss = 0.357018 (* 1 = 0.357018 loss)
I0829 16:24:58.290977 16790 sgd_solver.cpp:112] Iteration 390, lr = 0.000781158
I0829 16:25:05.355646 16790 solver.cpp:347] Iteration 400, Testing net (#0)
I0829 16:25:05.355669 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:25:05.355672 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:25:05.355675 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:25:05.355679 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:25:05.355682 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:25:05.355686 16790 net.cpp:676] Ignoring source layer label
I0829 16:25:05.355690 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:25:05.355693 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:25:05.355697 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:25:05.355706 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:25:05.355765 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:25:05.355772 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:25:05.355777 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:25:05.355780 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:25:05.355783 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:25:05.355788 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:25:05.355793 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:25:05.355798 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:25:05.355801 16790 net.cpp:676] Ignoring source layer grl
I0829 16:25:05.355805 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:25:05.355811 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:25:05.355815 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:25:05.355820 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:25:05.355823 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:25:05.355828 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:25:05.355832 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:25:05.355835 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:25:05.355839 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:25:05.355842 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:25:05.355846 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:25:05.355851 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:25:05.355856 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:25:05.355862 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:25:05.355867 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:25:05.355871 16790 net.cpp:676] Ignoring source layer loss
I0829 16:25:05.355875 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:25:05.355880 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:25:10.782444 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:25:11.045266 16790 solver.cpp:239] Iteration 400 (0.784092 iter/s, 12.7536s/10 iters), loss = 0.979531
I0829 16:25:11.045339 16790 solver.cpp:258]     Train net output #0: accuracy = 0.957031
I0829 16:25:11.045356 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.659261 (* 0.3 = 0.197778 loss)
I0829 16:25:11.045364 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:25:11.045375 16790 solver.cpp:258]     Train net output #3: entropy = 0.530059 (* 0.8 = 0.424047 loss)
I0829 16:25:11.045404 16790 solver.cpp:258]     Train net output #4: loss = 0.357706 (* 1 = 0.357706 loss)
I0829 16:25:11.045416 16790 sgd_solver.cpp:112] Iteration 400, lr = 0.00077697
I0829 16:25:17.611634 16790 solver.cpp:239] Iteration 410 (1.52301 iter/s, 6.56592s/10 iters), loss = 0.978249
I0829 16:25:17.611665 16790 solver.cpp:258]     Train net output #0: accuracy = 0.941406
I0829 16:25:17.611675 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.662516 (* 0.3 = 0.198755 loss)
I0829 16:25:17.611680 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:25:17.611687 16790 solver.cpp:258]     Train net output #3: entropy = 0.501648 (* 0.8 = 0.401319 loss)
I0829 16:25:17.611692 16790 solver.cpp:258]     Train net output #4: loss = 0.378176 (* 1 = 0.378176 loss)
I0829 16:25:17.611701 16790 sgd_solver.cpp:112] Iteration 410, lr = 0.000772833
I0829 16:25:24.791898 16790 solver.cpp:347] Iteration 420, Testing net (#0)
I0829 16:25:24.791918 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:25:24.791923 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:25:24.791925 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:25:24.791929 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:25:24.791931 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:25:24.791935 16790 net.cpp:676] Ignoring source layer label
I0829 16:25:24.791939 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:25:24.791941 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:25:24.791944 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:25:24.791954 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:25:24.791959 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:25:24.791962 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:25:24.791967 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:25:24.791971 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:25:24.791975 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:25:24.791981 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:25:24.791985 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:25:24.791990 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:25:24.791993 16790 net.cpp:676] Ignoring source layer grl
I0829 16:25:24.791997 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:25:24.792001 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:25:24.792006 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:25:24.792008 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:25:24.792012 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:25:24.792016 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:25:24.792019 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:25:24.792022 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:25:24.792026 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:25:24.792029 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:25:24.792033 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:25:24.792037 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:25:24.792040 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:25:24.792044 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:25:24.792047 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:25:24.792052 16790 net.cpp:676] Ignoring source layer loss
I0829 16:25:24.792057 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:25:24.792060 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:25:28.904652 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:25:31.955979 16790 solver.cpp:414]     Test net output #0: accuracy = 0.927711
I0829 16:25:32.245067 16790 solver.cpp:239] Iteration 420 (0.683406 iter/s, 14.6326s/10 iters), loss = 0.934951
I0829 16:25:32.245108 16790 solver.cpp:258]     Train net output #0: accuracy = 0.9375
I0829 16:25:32.245118 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.666407 (* 0.3 = 0.199922 loss)
I0829 16:25:32.245122 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:25:32.245129 16790 solver.cpp:258]     Train net output #3: entropy = 0.467672 (* 0.8 = 0.374138 loss)
I0829 16:25:32.245134 16790 solver.cpp:258]     Train net output #4: loss = 0.360891 (* 1 = 0.360891 loss)
I0829 16:25:32.245141 16790 sgd_solver.cpp:112] Iteration 420, lr = 0.000768748
I0829 16:25:38.517699 16790 solver.cpp:239] Iteration 430 (1.59433 iter/s, 6.27224s/10 iters), loss = 1.01409
I0829 16:25:38.517731 16790 solver.cpp:258]     Train net output #0: accuracy = 0.929688
I0829 16:25:38.517741 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.67025 (* 0.3 = 0.201075 loss)
I0829 16:25:38.517745 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:25:38.517751 16790 solver.cpp:258]     Train net output #3: entropy = 0.530772 (* 0.8 = 0.424617 loss)
I0829 16:25:38.517760 16790 solver.cpp:258]     Train net output #4: loss = 0.388402 (* 1 = 0.388402 loss)
I0829 16:25:38.517765 16790 sgd_solver.cpp:112] Iteration 430, lr = 0.000764712
I0829 16:25:45.568625 16790 solver.cpp:347] Iteration 440, Testing net (#0)
I0829 16:25:45.568647 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:25:45.568651 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:25:45.568655 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:25:45.568657 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:25:45.568660 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:25:45.568665 16790 net.cpp:676] Ignoring source layer label
I0829 16:25:45.568667 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:25:45.568670 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:25:45.568672 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:25:45.568682 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:25:45.568686 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:25:45.568689 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:25:45.568696 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:25:45.568699 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:25:45.568706 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:25:45.568709 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:25:45.568712 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:25:45.568717 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:25:45.568719 16790 net.cpp:676] Ignoring source layer grl
I0829 16:25:45.568723 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:25:45.568727 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:25:45.568730 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:25:45.568733 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:25:45.568738 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:25:45.568742 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:25:45.568744 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:25:45.568747 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:25:45.568751 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:25:45.568754 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:25:45.568760 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:25:45.568764 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:25:45.568769 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:25:45.568773 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:25:45.568792 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:25:45.568796 16790 net.cpp:676] Ignoring source layer loss
I0829 16:25:45.568799 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:25:45.568805 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:25:52.022496 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:25:52.287547 16790 solver.cpp:239] Iteration 440 (0.726267 iter/s, 13.769s/10 iters), loss = 0.92805
I0829 16:25:52.287614 16790 solver.cpp:258]     Train net output #0: accuracy = 0.949219
I0829 16:25:52.287631 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.663958 (* 0.3 = 0.199187 loss)
I0829 16:25:52.287641 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:25:52.287650 16790 solver.cpp:258]     Train net output #3: entropy = 0.479253 (* 0.8 = 0.383402 loss)
I0829 16:25:52.287660 16790 solver.cpp:258]     Train net output #4: loss = 0.345461 (* 1 = 0.345461 loss)
I0829 16:25:52.287672 16790 sgd_solver.cpp:112] Iteration 440, lr = 0.000760726
I0829 16:25:58.658617 16790 solver.cpp:239] Iteration 450 (1.5697 iter/s, 6.37064s/10 iters), loss = 0.982106
I0829 16:25:58.658656 16790 solver.cpp:258]     Train net output #0: accuracy = 0.953125
I0829 16:25:58.658666 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.678208 (* 0.3 = 0.203462 loss)
I0829 16:25:58.658671 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:25:58.658679 16790 solver.cpp:258]     Train net output #3: entropy = 0.56331 (* 0.8 = 0.450648 loss)
I0829 16:25:58.658685 16790 solver.cpp:258]     Train net output #4: loss = 0.327996 (* 1 = 0.327996 loss)
I0829 16:25:58.658692 16790 sgd_solver.cpp:112] Iteration 450, lr = 0.000756788
I0829 16:26:05.637571 16790 solver.cpp:347] Iteration 460, Testing net (#0)
I0829 16:26:05.637652 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:26:05.637658 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:26:05.637662 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:26:05.637666 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:26:05.637671 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:26:05.637676 16790 net.cpp:676] Ignoring source layer label
I0829 16:26:05.637681 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:26:05.637686 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:26:05.637691 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:26:05.637701 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:26:05.637707 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:26:05.637712 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:26:05.637719 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:26:05.637727 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:26:05.637730 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:26:05.637737 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:26:05.637742 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:26:05.637748 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:26:05.637753 16790 net.cpp:676] Ignoring source layer grl
I0829 16:26:05.637756 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:26:05.637766 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:26:05.637770 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:26:05.637775 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:26:05.637780 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:26:05.637785 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:26:05.637789 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:26:05.637794 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:26:05.637799 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:26:05.637804 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:26:05.637809 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:26:05.637812 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:26:05.637817 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:26:05.637825 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:26:05.637830 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:26:05.637835 16790 net.cpp:676] Ignoring source layer loss
I0829 16:26:05.637838 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:26:05.637845 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:26:08.080919 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:26:10.967927 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:26:11.226755 16790 solver.cpp:239] Iteration 460 (0.79571 iter/s, 12.5674s/10 iters), loss = 0.911493
I0829 16:26:11.226851 16790 solver.cpp:258]     Train net output #0: accuracy = 0.957031
I0829 16:26:11.226881 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.682967 (* 0.3 = 0.20489 loss)
I0829 16:26:11.226900 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:26:11.226922 16790 solver.cpp:258]     Train net output #3: entropy = 0.480079 (* 0.8 = 0.384063 loss)
I0829 16:26:11.226945 16790 solver.cpp:258]     Train net output #4: loss = 0.32254 (* 1 = 0.32254 loss)
I0829 16:26:11.226967 16790 sgd_solver.cpp:112] Iteration 460, lr = 0.000752897
I0829 16:26:17.619469 16790 solver.cpp:239] Iteration 470 (1.56439 iter/s, 6.39225s/10 iters), loss = 1.0502
I0829 16:26:17.619509 16790 solver.cpp:258]     Train net output #0: accuracy = 0.960938
I0829 16:26:17.619521 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.686723 (* 0.3 = 0.206017 loss)
I0829 16:26:17.619526 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:26:17.619552 16790 solver.cpp:258]     Train net output #3: entropy = 0.655118 (* 0.8 = 0.524094 loss)
I0829 16:26:17.619560 16790 solver.cpp:258]     Train net output #4: loss = 0.320092 (* 1 = 0.320092 loss)
I0829 16:26:17.619570 16790 sgd_solver.cpp:112] Iteration 470, lr = 0.000749052
I0829 16:26:24.596313 16790 solver.cpp:347] Iteration 480, Testing net (#0)
I0829 16:26:24.596335 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:26:24.596339 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:26:24.596343 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:26:24.596345 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:26:24.596349 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:26:24.596352 16790 net.cpp:676] Ignoring source layer label
I0829 16:26:24.596355 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:26:24.596359 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:26:24.596361 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:26:24.596369 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:26:24.596377 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:26:24.596382 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:26:24.596390 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:26:24.596395 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:26:24.596400 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:26:24.596407 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:26:24.596411 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:26:24.596417 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:26:24.596421 16790 net.cpp:676] Ignoring source layer grl
I0829 16:26:24.596426 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:26:24.596431 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:26:24.596434 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:26:24.596439 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:26:24.596441 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:26:24.596446 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:26:24.596449 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:26:24.596457 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:26:24.596462 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:26:24.596464 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:26:24.596470 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:26:24.596474 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:26:24.596479 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:26:24.596483 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:26:24.596487 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:26:24.596493 16790 net.cpp:676] Ignoring source layer loss
I0829 16:26:24.596495 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:26:24.596498 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:26:29.861033 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:26:30.142833 16790 solver.cpp:239] Iteration 480 (0.798555 iter/s, 12.5226s/10 iters), loss = 0.8327
I0829 16:26:30.142920 16790 solver.cpp:258]     Train net output #0: accuracy = 0.992188
I0829 16:26:30.142941 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.671479 (* 0.3 = 0.201444 loss)
I0829 16:26:30.142948 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:26:30.142959 16790 solver.cpp:258]     Train net output #3: entropy = 0.500318 (* 0.8 = 0.400254 loss)
I0829 16:26:30.142968 16790 solver.cpp:258]     Train net output #4: loss = 0.231002 (* 1 = 0.231002 loss)
I0829 16:26:30.142978 16790 sgd_solver.cpp:112] Iteration 480, lr = 0.000745253
I0829 16:26:36.771333 16790 solver.cpp:239] Iteration 490 (1.50874 iter/s, 6.62804s/10 iters), loss = 0.827786
I0829 16:26:36.771441 16790 solver.cpp:258]     Train net output #0: accuracy = 0.949219
I0829 16:26:36.771453 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.690514 (* 0.3 = 0.207154 loss)
I0829 16:26:36.771458 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:26:36.771464 16790 solver.cpp:258]     Train net output #3: entropy = 0.420227 (* 0.8 = 0.336182 loss)
I0829 16:26:36.771472 16790 solver.cpp:258]     Train net output #4: loss = 0.28445 (* 1 = 0.28445 loss)
I0829 16:26:36.771479 16790 sgd_solver.cpp:112] Iteration 490, lr = 0.000741499
I0829 16:26:43.780706 16790 solver.cpp:347] Iteration 500, Testing net (#0)
I0829 16:26:43.780730 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:26:43.780735 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:26:43.780737 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:26:43.780740 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:26:43.780745 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:26:43.780748 16790 net.cpp:676] Ignoring source layer label
I0829 16:26:43.780752 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:26:43.780755 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:26:43.780758 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:26:43.780768 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:26:43.780774 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:26:43.780781 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:26:43.780786 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:26:43.780791 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:26:43.780797 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:26:43.780803 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:26:43.780808 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:26:43.780812 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:26:43.780815 16790 net.cpp:676] Ignoring source layer grl
I0829 16:26:43.780820 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:26:43.780823 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:26:43.780827 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:26:43.780830 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:26:43.780833 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:26:43.780840 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:26:43.780846 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:26:43.780853 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:26:43.780858 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:26:43.780863 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:26:43.780867 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:26:43.780870 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:26:43.780875 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:26:43.780882 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:26:43.780889 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:26:43.780894 16790 net.cpp:676] Ignoring source layer loss
I0829 16:26:43.780896 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:26:43.780902 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:26:45.866456 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:26:48.995462 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:26:49.262997 16790 solver.cpp:239] Iteration 500 (0.800586 iter/s, 12.4909s/10 iters), loss = 0.868753
I0829 16:26:49.263077 16790 solver.cpp:258]     Train net output #0: accuracy = 0.96875
I0829 16:26:49.263095 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.669427 (* 0.3 = 0.200828 loss)
I0829 16:26:49.263105 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:26:49.263115 16790 solver.cpp:258]     Train net output #3: entropy = 0.471157 (* 0.8 = 0.376926 loss)
I0829 16:26:49.263152 16790 solver.cpp:258]     Train net output #4: loss = 0.290999 (* 1 = 0.290999 loss)
I0829 16:26:49.263164 16790 sgd_solver.cpp:112] Iteration 500, lr = 0.000737788
I0829 16:26:55.631292 16790 solver.cpp:239] Iteration 510 (1.57039 iter/s, 6.36785s/10 iters), loss = 0.912607
I0829 16:26:55.631333 16790 solver.cpp:258]     Train net output #0: accuracy = 0.953125
I0829 16:26:55.631347 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.682351 (* 0.3 = 0.204705 loss)
I0829 16:26:55.631361 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:26:55.631373 16790 solver.cpp:258]     Train net output #3: entropy = 0.515577 (* 0.8 = 0.412461 loss)
I0829 16:26:55.631383 16790 solver.cpp:258]     Train net output #4: loss = 0.29544 (* 1 = 0.29544 loss)
I0829 16:26:55.631394 16790 sgd_solver.cpp:112] Iteration 510, lr = 0.00073412
I0829 16:27:02.778653 16790 solver.cpp:347] Iteration 520, Testing net (#0)
I0829 16:27:02.778678 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:27:02.778682 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:27:02.778687 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:27:02.778692 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:27:02.778695 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:27:02.778703 16790 net.cpp:676] Ignoring source layer label
I0829 16:27:02.778707 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:27:02.778717 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:27:02.778731 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:27:02.778746 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:27:02.778753 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:27:02.778759 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:27:02.778767 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:27:02.778772 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:27:02.778781 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:27:02.778789 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:27:02.778795 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:27:02.778800 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:27:02.778803 16790 net.cpp:676] Ignoring source layer grl
I0829 16:27:02.778812 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:27:02.778820 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:27:02.778825 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:27:02.778832 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:27:02.778838 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:27:02.778844 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:27:02.778849 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:27:02.778856 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:27:02.778861 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:27:02.778867 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:27:02.778873 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:27:02.778882 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:27:02.778890 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:27:02.778897 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:27:02.778903 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:27:02.778908 16790 net.cpp:676] Ignoring source layer loss
I0829 16:27:02.778918 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:27:02.778924 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:27:07.997160 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:27:08.263751 16790 solver.cpp:239] Iteration 520 (0.791661 iter/s, 12.6317s/10 iters), loss = 1.00405
I0829 16:27:08.263788 16790 solver.cpp:258]     Train net output #0: accuracy = 0.949219
I0829 16:27:08.263800 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.677116 (* 0.3 = 0.203135 loss)
I0829 16:27:08.263811 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:27:08.263825 16790 solver.cpp:258]     Train net output #3: entropy = 0.576812 (* 0.8 = 0.46145 loss)
I0829 16:27:08.263836 16790 solver.cpp:258]     Train net output #4: loss = 0.339464 (* 1 = 0.339464 loss)
I0829 16:27:08.263847 16790 sgd_solver.cpp:112] Iteration 520, lr = 0.000730495
I0829 16:27:14.789976 16790 solver.cpp:239] Iteration 530 (1.53238 iter/s, 6.52581s/10 iters), loss = 0.826416
I0829 16:27:14.790015 16790 solver.cpp:258]     Train net output #0: accuracy = 0.976562
I0829 16:27:14.790026 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.67144 (* 0.3 = 0.201432 loss)
I0829 16:27:14.790031 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:27:14.790040 16790 solver.cpp:258]     Train net output #3: entropy = 0.460076 (* 0.8 = 0.368061 loss)
I0829 16:27:14.790045 16790 solver.cpp:258]     Train net output #4: loss = 0.256923 (* 1 = 0.256923 loss)
I0829 16:27:14.790053 16790 sgd_solver.cpp:112] Iteration 530, lr = 0.000726911
I0829 16:27:21.832195 16790 solver.cpp:347] Iteration 540, Testing net (#0)
I0829 16:27:21.832218 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:27:21.832222 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:27:21.832227 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:27:21.832229 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:27:21.832234 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:27:21.832237 16790 net.cpp:676] Ignoring source layer label
I0829 16:27:21.832242 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:27:21.832244 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:27:21.832248 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:27:21.832257 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:27:21.832259 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:27:21.832263 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:27:21.832267 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:27:21.832270 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:27:21.832274 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:27:21.832279 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:27:21.832283 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:27:21.832285 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:27:21.832288 16790 net.cpp:676] Ignoring source layer grl
I0829 16:27:21.832291 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:27:21.832294 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:27:21.832298 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:27:21.832301 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:27:21.832304 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:27:21.832306 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:27:21.832310 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:27:21.832314 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:27:21.832316 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:27:21.832320 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:27:21.832324 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:27:21.832327 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:27:21.832331 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:27:21.832335 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:27:21.832339 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:27:21.832358 16790 net.cpp:676] Ignoring source layer loss
I0829 16:27:21.832361 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:27:21.832365 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:27:23.667083 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:27:27.088156 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:27:27.361057 16790 solver.cpp:239] Iteration 540 (0.795524 iter/s, 12.5703s/10 iters), loss = 0.822501
I0829 16:27:27.361117 16790 solver.cpp:258]     Train net output #0: accuracy = 0.980469
I0829 16:27:27.361132 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.671323 (* 0.3 = 0.201397 loss)
I0829 16:27:27.361146 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:27:27.361156 16790 solver.cpp:258]     Train net output #3: entropy = 0.431762 (* 0.8 = 0.34541 loss)
I0829 16:27:27.361166 16790 solver.cpp:258]     Train net output #4: loss = 0.275694 (* 1 = 0.275694 loss)
I0829 16:27:27.361176 16790 sgd_solver.cpp:112] Iteration 540, lr = 0.000723368
I0829 16:27:33.758939 16790 solver.cpp:239] Iteration 550 (1.56312 iter/s, 6.39746s/10 iters), loss = 0.779657
I0829 16:27:33.758975 16790 solver.cpp:258]     Train net output #0: accuracy = 0.980469
I0829 16:27:33.758985 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.672267 (* 0.3 = 0.20168 loss)
I0829 16:27:33.758991 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:27:33.758997 16790 solver.cpp:258]     Train net output #3: entropy = 0.406179 (* 0.8 = 0.324943 loss)
I0829 16:27:33.759003 16790 solver.cpp:258]     Train net output #4: loss = 0.253034 (* 1 = 0.253034 loss)
I0829 16:27:33.759011 16790 sgd_solver.cpp:112] Iteration 550, lr = 0.000719865
I0829 16:27:40.804129 16790 solver.cpp:347] Iteration 560, Testing net (#0)
I0829 16:27:40.804210 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:27:40.804215 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:27:40.804219 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:27:40.804224 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:27:40.804229 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:27:40.804234 16790 net.cpp:676] Ignoring source layer label
I0829 16:27:40.804242 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:27:40.804250 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:27:40.804260 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:27:40.804271 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:27:40.804280 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:27:40.804291 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:27:40.804301 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:27:40.804312 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:27:40.804322 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:27:40.804334 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:27:40.804345 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:27:40.804350 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:27:40.804358 16790 net.cpp:676] Ignoring source layer grl
I0829 16:27:40.804366 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:27:40.804374 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:27:40.804379 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:27:40.804388 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:27:40.804394 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:27:40.804404 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:27:40.804409 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:27:40.804416 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:27:40.804422 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:27:40.804433 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:27:40.804440 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:27:40.804447 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:27:40.804455 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:27:40.804464 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:27:40.804471 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:27:40.804479 16790 net.cpp:676] Ignoring source layer loss
I0829 16:27:40.804486 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:27:40.804493 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:27:47.010826 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:27:47.269533 16790 solver.cpp:239] Iteration 560 (0.740203 iter/s, 13.5098s/10 iters), loss = 0.829111
I0829 16:27:47.269599 16790 solver.cpp:258]     Train net output #0: accuracy = 0.949219
I0829 16:27:47.269619 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.683334 (* 0.3 = 0.205 loss)
I0829 16:27:47.269628 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:27:47.269635 16790 solver.cpp:258]     Train net output #3: entropy = 0.428474 (* 0.8 = 0.342779 loss)
I0829 16:27:47.269644 16790 solver.cpp:258]     Train net output #4: loss = 0.281332 (* 1 = 0.281332 loss)
I0829 16:27:47.269655 16790 sgd_solver.cpp:112] Iteration 560, lr = 0.000716402
I0829 16:27:53.733829 16790 solver.cpp:239] Iteration 570 (1.54706 iter/s, 6.46386s/10 iters), loss = 0.865793
I0829 16:27:53.733868 16790 solver.cpp:258]     Train net output #0: accuracy = 0.945312
I0829 16:27:53.733880 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.679904 (* 0.3 = 0.203971 loss)
I0829 16:27:53.733888 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:27:53.733896 16790 solver.cpp:258]     Train net output #3: entropy = 0.460396 (* 0.8 = 0.368317 loss)
I0829 16:27:53.733924 16790 solver.cpp:258]     Train net output #4: loss = 0.293504 (* 1 = 0.293504 loss)
I0829 16:27:53.733935 16790 sgd_solver.cpp:112] Iteration 570, lr = 0.000712977
I0829 16:28:01.384840 16790 solver.cpp:347] Iteration 580, Testing net (#0)
I0829 16:28:01.384860 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:28:01.384865 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:28:01.384869 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:28:01.384872 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:28:01.384876 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:28:01.384882 16790 net.cpp:676] Ignoring source layer label
I0829 16:28:01.384886 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:28:01.384892 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:28:01.384897 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:28:01.384912 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:28:01.384919 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:28:01.384927 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:28:01.384932 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:28:01.384938 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:28:01.384944 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:28:01.384951 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:28:01.384956 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:28:01.384961 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:28:01.384966 16790 net.cpp:676] Ignoring source layer grl
I0829 16:28:01.384974 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:28:01.384976 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:28:01.384981 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:28:01.384985 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:28:01.384991 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:28:01.384994 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:28:01.384997 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:28:01.385000 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:28:01.385004 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:28:01.385010 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:28:01.385022 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:28:01.385027 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:28:01.385031 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:28:01.385036 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:28:01.385040 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:28:01.385043 16790 net.cpp:676] Ignoring source layer loss
I0829 16:28:01.385046 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:28:01.385051 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:28:03.086763 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:28:06.732156 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:28:06.997812 16790 solver.cpp:239] Iteration 580 (0.753966 iter/s, 13.2632s/10 iters), loss = 0.847373
I0829 16:28:06.997866 16790 solver.cpp:258]     Train net output #0: accuracy = 0.976562
I0829 16:28:06.997886 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.68413 (* 0.3 = 0.205239 loss)
I0829 16:28:06.997901 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:28:06.997911 16790 solver.cpp:258]     Train net output #3: entropy = 0.471045 (* 0.8 = 0.376836 loss)
I0829 16:28:06.997925 16790 solver.cpp:258]     Train net output #4: loss = 0.265298 (* 1 = 0.265298 loss)
I0829 16:28:06.997933 16790 sgd_solver.cpp:112] Iteration 580, lr = 0.00070959
I0829 16:28:13.358397 16790 solver.cpp:239] Iteration 590 (1.57229 iter/s, 6.36017s/10 iters), loss = 0.756907
I0829 16:28:13.358533 16790 solver.cpp:258]     Train net output #0: accuracy = 0.972656
I0829 16:28:13.358546 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.687756 (* 0.3 = 0.206327 loss)
I0829 16:28:13.358556 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:28:13.358561 16790 solver.cpp:258]     Train net output #3: entropy = 0.37753 (* 0.8 = 0.302024 loss)
I0829 16:28:13.358568 16790 solver.cpp:258]     Train net output #4: loss = 0.248556 (* 1 = 0.248556 loss)
I0829 16:28:13.358575 16790 sgd_solver.cpp:112] Iteration 590, lr = 0.00070624
I0829 16:28:20.405916 16790 solver.cpp:347] Iteration 600, Testing net (#0)
I0829 16:28:20.405937 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:28:20.405942 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:28:20.405946 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:28:20.405948 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:28:20.405951 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:28:20.405956 16790 net.cpp:676] Ignoring source layer label
I0829 16:28:20.405961 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:28:20.405966 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:28:20.405973 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:28:20.405987 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:28:20.405990 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:28:20.405995 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:28:20.406002 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:28:20.406008 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:28:20.406013 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:28:20.406018 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:28:20.406023 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:28:20.406028 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:28:20.406033 16790 net.cpp:676] Ignoring source layer grl
I0829 16:28:20.406039 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:28:20.406044 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:28:20.406049 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:28:20.406055 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:28:20.406061 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:28:20.406066 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:28:20.406072 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:28:20.406077 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:28:20.406083 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:28:20.406087 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:28:20.406095 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:28:20.406100 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:28:20.406106 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:28:20.406116 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:28:20.406121 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:28:20.406128 16790 net.cpp:676] Ignoring source layer loss
I0829 16:28:20.406134 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:28:20.406141 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:28:26.454042 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:28:26.733677 16790 solver.cpp:239] Iteration 600 (0.747697 iter/s, 13.3744s/10 iters), loss = 0.766993
I0829 16:28:26.733728 16790 solver.cpp:258]     Train net output #0: accuracy = 0.960938
I0829 16:28:26.733743 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.673097 (* 0.3 = 0.201929 loss)
I0829 16:28:26.733769 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:28:26.733794 16790 solver.cpp:258]     Train net output #3: entropy = 0.375528 (* 0.8 = 0.300423 loss)
I0829 16:28:26.733839 16790 solver.cpp:258]     Train net output #4: loss = 0.264642 (* 1 = 0.264642 loss)
I0829 16:28:26.733862 16790 sgd_solver.cpp:112] Iteration 600, lr = 0.000702927
I0829 16:28:33.125656 16790 solver.cpp:239] Iteration 610 (1.56456 iter/s, 6.39156s/10 iters), loss = 0.767705
I0829 16:28:33.125695 16790 solver.cpp:258]     Train net output #0: accuracy = 0.96875
I0829 16:28:33.125710 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.674535 (* 0.3 = 0.202361 loss)
I0829 16:28:33.125717 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:28:33.125728 16790 solver.cpp:258]     Train net output #3: entropy = 0.36458 (* 0.8 = 0.291664 loss)
I0829 16:28:33.125737 16790 solver.cpp:258]     Train net output #4: loss = 0.273681 (* 1 = 0.273681 loss)
I0829 16:28:33.125749 16790 sgd_solver.cpp:112] Iteration 610, lr = 0.00069965
I0829 16:28:40.170466 16790 solver.cpp:347] Iteration 620, Testing net (#0)
I0829 16:28:40.170485 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:28:40.170490 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:28:40.170492 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:28:40.170495 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:28:40.170500 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:28:40.170503 16790 net.cpp:676] Ignoring source layer label
I0829 16:28:40.170506 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:28:40.170508 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:28:40.170512 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:28:40.170521 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:28:40.170526 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:28:40.170529 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:28:40.170536 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:28:40.170539 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:28:40.170543 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:28:40.170547 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:28:40.170552 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:28:40.170555 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:28:40.170560 16790 net.cpp:676] Ignoring source layer grl
I0829 16:28:40.170564 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:28:40.170567 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:28:40.170572 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:28:40.170574 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:28:40.170578 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:28:40.170583 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:28:40.170585 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:28:40.170588 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:28:40.170593 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:28:40.170596 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:28:40.170600 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:28:40.170605 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:28:40.170608 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:28:40.170614 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:28:40.170621 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:28:40.170627 16790 net.cpp:676] Ignoring source layer loss
I0829 16:28:40.170631 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:28:40.170635 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:28:41.590150 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:28:45.482223 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:28:45.749838 16790 solver.cpp:239] Iteration 620 (0.792177 iter/s, 12.6234s/10 iters), loss = 0.793015
I0829 16:28:45.749889 16790 solver.cpp:258]     Train net output #0: accuracy = 0.960938
I0829 16:28:45.749902 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.655998 (* 0.3 = 0.196799 loss)
I0829 16:28:45.749908 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:28:45.749914 16790 solver.cpp:258]     Train net output #3: entropy = 0.417046 (* 0.8 = 0.333637 loss)
I0829 16:28:45.749920 16790 solver.cpp:258]     Train net output #4: loss = 0.262578 (* 1 = 0.262578 loss)
I0829 16:28:45.749927 16790 sgd_solver.cpp:112] Iteration 620, lr = 0.000696408
I0829 16:28:52.119334 16790 solver.cpp:239] Iteration 630 (1.57009 iter/s, 6.36908s/10 iters), loss = 0.780848
I0829 16:28:52.119369 16790 solver.cpp:258]     Train net output #0: accuracy = 0.960938
I0829 16:28:52.119379 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.688071 (* 0.3 = 0.206421 loss)
I0829 16:28:52.119383 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:28:52.119390 16790 solver.cpp:258]     Train net output #3: entropy = 0.378525 (* 0.8 = 0.30282 loss)
I0829 16:28:52.119395 16790 solver.cpp:258]     Train net output #4: loss = 0.271607 (* 1 = 0.271607 loss)
I0829 16:28:52.119405 16790 sgd_solver.cpp:112] Iteration 630, lr = 0.000693201
I0829 16:28:59.155833 16790 solver.cpp:347] Iteration 640, Testing net (#0)
I0829 16:28:59.155853 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:28:59.155858 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:28:59.155861 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:28:59.155864 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:28:59.155867 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:28:59.155871 16790 net.cpp:676] Ignoring source layer label
I0829 16:28:59.155874 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:28:59.155877 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:28:59.155880 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:28:59.155889 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:28:59.155894 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:28:59.155896 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:28:59.155901 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:28:59.155905 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:28:59.155910 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:28:59.155915 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:28:59.155918 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:28:59.155921 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:28:59.155925 16790 net.cpp:676] Ignoring source layer grl
I0829 16:28:59.155928 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:28:59.155932 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:28:59.155936 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:28:59.155939 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:28:59.155942 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:28:59.155946 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:28:59.155951 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:28:59.155953 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:28:59.155956 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:28:59.155961 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:28:59.155964 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:28:59.155972 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:28:59.155978 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:28:59.155987 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:28:59.155990 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:28:59.156013 16790 net.cpp:676] Ignoring source layer loss
I0829 16:28:59.156018 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:28:59.156021 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:29:04.390666 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:29:04.657114 16790 solver.cpp:239] Iteration 640 (0.797636 iter/s, 12.537s/10 iters), loss = 0.849491
I0829 16:29:04.657200 16790 solver.cpp:258]     Train net output #0: accuracy = 0.957031
I0829 16:29:04.657222 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.679716 (* 0.3 = 0.203915 loss)
I0829 16:29:04.657230 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:29:04.657240 16790 solver.cpp:258]     Train net output #3: entropy = 0.45105 (* 0.8 = 0.36084 loss)
I0829 16:29:04.657250 16790 solver.cpp:258]     Train net output #4: loss = 0.284736 (* 1 = 0.284736 loss)
I0829 16:29:04.657261 16790 sgd_solver.cpp:112] Iteration 640, lr = 0.000690029
I0829 16:29:10.881209 16790 solver.cpp:239] Iteration 650 (1.60677 iter/s, 6.22366s/10 iters), loss = 0.73713
I0829 16:29:10.881250 16790 solver.cpp:258]     Train net output #0: accuracy = 0.96875
I0829 16:29:10.881263 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.669746 (* 0.3 = 0.200924 loss)
I0829 16:29:10.881269 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:29:10.881278 16790 solver.cpp:258]     Train net output #3: entropy = 0.355277 (* 0.8 = 0.284221 loss)
I0829 16:29:10.881289 16790 solver.cpp:258]     Train net output #4: loss = 0.251985 (* 1 = 0.251985 loss)
I0829 16:29:10.881299 16790 sgd_solver.cpp:112] Iteration 650, lr = 0.00068689
I0829 16:29:18.039979 16790 solver.cpp:347] Iteration 660, Testing net (#0)
I0829 16:29:18.040084 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:29:18.040091 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:29:18.040094 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:29:18.040098 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:29:18.040102 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:29:18.040107 16790 net.cpp:676] Ignoring source layer label
I0829 16:29:18.040112 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:29:18.040117 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:29:18.040122 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:29:18.040132 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:29:18.040138 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:29:18.040143 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:29:18.040148 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:29:18.040156 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:29:18.040161 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:29:18.040168 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:29:18.040171 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:29:18.040179 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:29:18.040185 16790 net.cpp:676] Ignoring source layer grl
I0829 16:29:18.040191 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:29:18.040195 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:29:18.040202 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:29:18.040205 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:29:18.040210 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:29:18.040216 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:29:18.040220 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:29:18.040225 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:29:18.040233 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:29:18.040238 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:29:18.040246 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:29:18.040251 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:29:18.040256 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:29:18.040263 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:29:18.040271 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:29:18.040274 16790 net.cpp:676] Ignoring source layer loss
I0829 16:29:18.040279 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:29:18.040285 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:29:19.099728 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:29:23.252866 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:29:23.544072 16790 solver.cpp:239] Iteration 660 (0.789758 iter/s, 12.6621s/10 iters), loss = 0.725636
I0829 16:29:23.544131 16790 solver.cpp:258]     Train net output #0: accuracy = 0.964844
I0829 16:29:23.544147 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.674043 (* 0.3 = 0.202213 loss)
I0829 16:29:23.544153 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:29:23.544163 16790 solver.cpp:258]     Train net output #3: entropy = 0.346448 (* 0.8 = 0.277159 loss)
I0829 16:29:23.544174 16790 solver.cpp:258]     Train net output #4: loss = 0.246265 (* 1 = 0.246265 loss)
I0829 16:29:23.544184 16790 sgd_solver.cpp:112] Iteration 660, lr = 0.000683784
I0829 16:29:29.795516 16790 solver.cpp:239] Iteration 670 (1.59974 iter/s, 6.25103s/10 iters), loss = 0.814768
I0829 16:29:29.795552 16790 solver.cpp:258]     Train net output #0: accuracy = 0.949219
I0829 16:29:29.795560 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.668292 (* 0.3 = 0.200488 loss)
I0829 16:29:29.795565 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:29:29.795595 16790 solver.cpp:258]     Train net output #3: entropy = 0.403569 (* 0.8 = 0.322855 loss)
I0829 16:29:29.795601 16790 solver.cpp:258]     Train net output #4: loss = 0.291426 (* 1 = 0.291426 loss)
I0829 16:29:29.795608 16790 sgd_solver.cpp:112] Iteration 670, lr = 0.000680711
I0829 16:29:36.866852 16790 solver.cpp:347] Iteration 680, Testing net (#0)
I0829 16:29:36.866871 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:29:36.866875 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:29:36.866879 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:29:36.866883 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:29:36.866885 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:29:36.866889 16790 net.cpp:676] Ignoring source layer label
I0829 16:29:36.866892 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:29:36.866896 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:29:36.866899 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:29:36.866907 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:29:36.866910 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:29:36.866914 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:29:36.866919 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:29:36.866922 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:29:36.866925 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:29:36.866931 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:29:36.866935 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:29:36.866938 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:29:36.866941 16790 net.cpp:676] Ignoring source layer grl
I0829 16:29:36.866945 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:29:36.866948 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:29:36.866951 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:29:36.866955 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:29:36.866957 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:29:36.866961 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:29:36.866964 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:29:36.866967 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:29:36.866971 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:29:36.866976 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:29:36.866979 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:29:36.866983 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:29:36.866987 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:29:36.866991 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:29:36.866994 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:29:36.866997 16790 net.cpp:676] Ignoring source layer loss
I0829 16:29:36.867002 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:29:36.867004 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:29:42.179374 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:29:42.445504 16790 solver.cpp:239] Iteration 680 (0.790561 iter/s, 12.6492s/10 iters), loss = 0.730784
I0829 16:29:42.445585 16790 solver.cpp:258]     Train net output #0: accuracy = 0.992188
I0829 16:29:42.445601 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.675333 (* 0.3 = 0.2026 loss)
I0829 16:29:42.445610 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:29:42.445618 16790 solver.cpp:258]     Train net output #3: entropy = 0.425204 (* 0.8 = 0.340163 loss)
I0829 16:29:42.445627 16790 solver.cpp:258]     Train net output #4: loss = 0.188021 (* 1 = 0.188021 loss)
I0829 16:29:42.445638 16790 sgd_solver.cpp:112] Iteration 680, lr = 0.00067767
I0829 16:29:48.855489 16790 solver.cpp:239] Iteration 690 (1.56017 iter/s, 6.40954s/10 iters), loss = 0.712494
I0829 16:29:48.855597 16790 solver.cpp:258]     Train net output #0: accuracy = 0.964844
I0829 16:29:48.855608 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.690687 (* 0.3 = 0.207206 loss)
I0829 16:29:48.855617 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:29:48.855623 16790 solver.cpp:258]     Train net output #3: entropy = 0.326176 (* 0.8 = 0.260941 loss)
I0829 16:29:48.855630 16790 solver.cpp:258]     Train net output #4: loss = 0.244347 (* 1 = 0.244347 loss)
I0829 16:29:48.855638 16790 sgd_solver.cpp:112] Iteration 690, lr = 0.00067466
I0829 16:29:56.026288 16790 solver.cpp:347] Iteration 700, Testing net (#0)
I0829 16:29:56.026307 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:29:56.026311 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:29:56.026315 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:29:56.026319 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:29:56.026321 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:29:56.026324 16790 net.cpp:676] Ignoring source layer label
I0829 16:29:56.026329 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:29:56.026331 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:29:56.026335 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:29:56.026342 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:29:56.026346 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:29:56.026350 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:29:56.026355 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:29:56.026357 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:29:56.026361 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:29:56.026366 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:29:56.026370 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:29:56.026372 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:29:56.026376 16790 net.cpp:676] Ignoring source layer grl
I0829 16:29:56.026379 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:29:56.026382 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:29:56.026386 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:29:56.026391 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:29:56.026393 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:29:56.026397 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:29:56.026401 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:29:56.026405 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:29:56.026409 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:29:56.026412 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:29:56.026417 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:29:56.026420 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:29:56.026423 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:29:56.026427 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:29:56.026432 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:29:56.026438 16790 net.cpp:676] Ignoring source layer loss
I0829 16:29:56.026443 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:29:56.026445 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:29:56.882747 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:30:01.301822 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:30:01.568785 16790 solver.cpp:239] Iteration 700 (0.786629 iter/s, 12.7125s/10 iters), loss = 0.743158
I0829 16:30:01.568842 16790 solver.cpp:258]     Train net output #0: accuracy = 0.96875
I0829 16:30:01.568855 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.68159 (* 0.3 = 0.204477 loss)
I0829 16:30:01.568861 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:30:01.568869 16790 solver.cpp:258]     Train net output #3: entropy = 0.391293 (* 0.8 = 0.313034 loss)
I0829 16:30:01.568900 16790 solver.cpp:258]     Train net output #4: loss = 0.225647 (* 1 = 0.225647 loss)
I0829 16:30:01.568910 16790 sgd_solver.cpp:112] Iteration 700, lr = 0.000671681
I0829 16:30:08.027346 16790 solver.cpp:239] Iteration 710 (1.54843 iter/s, 6.45814s/10 iters), loss = 0.716371
I0829 16:30:08.027381 16790 solver.cpp:258]     Train net output #0: accuracy = 0.972656
I0829 16:30:08.027390 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.685299 (* 0.3 = 0.20559 loss)
I0829 16:30:08.027395 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:30:08.027401 16790 solver.cpp:258]     Train net output #3: entropy = 0.336289 (* 0.8 = 0.269031 loss)
I0829 16:30:08.027407 16790 solver.cpp:258]     Train net output #4: loss = 0.24175 (* 1 = 0.24175 loss)
I0829 16:30:08.027413 16790 sgd_solver.cpp:112] Iteration 710, lr = 0.000668733
I0829 16:30:15.148932 16790 solver.cpp:347] Iteration 720, Testing net (#0)
I0829 16:30:15.148953 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:30:15.148957 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:30:15.148962 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:30:15.148964 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:30:15.148967 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:30:15.148970 16790 net.cpp:676] Ignoring source layer label
I0829 16:30:15.148973 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:30:15.148977 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:30:15.148980 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:30:15.148988 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:30:15.148993 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:30:15.148996 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:30:15.149001 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:30:15.149004 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:30:15.149008 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:30:15.149013 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:30:15.149016 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:30:15.149019 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:30:15.149024 16790 net.cpp:676] Ignoring source layer grl
I0829 16:30:15.149029 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:30:15.149031 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:30:15.149034 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:30:15.149039 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:30:15.149042 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:30:15.149046 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:30:15.149049 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:30:15.149052 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:30:15.149055 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:30:15.149058 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:30:15.149062 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:30:15.149065 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:30:15.149070 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:30:15.149073 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:30:15.149077 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:30:15.149080 16790 net.cpp:676] Ignoring source layer loss
I0829 16:30:15.149083 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:30:15.149087 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:30:20.458055 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:30:20.741065 16790 solver.cpp:239] Iteration 720 (0.786598 iter/s, 12.713s/10 iters), loss = 0.693988
I0829 16:30:20.741123 16790 solver.cpp:258]     Train net output #0: accuracy = 0.976562
I0829 16:30:20.741135 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.671185 (* 0.3 = 0.201355 loss)
I0829 16:30:20.741140 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:30:20.741147 16790 solver.cpp:258]     Train net output #3: entropy = 0.341451 (* 0.8 = 0.273161 loss)
I0829 16:30:20.741153 16790 solver.cpp:258]     Train net output #4: loss = 0.219472 (* 1 = 0.219472 loss)
I0829 16:30:20.741161 16790 sgd_solver.cpp:112] Iteration 720, lr = 0.000665815
I0829 16:30:27.274204 16790 solver.cpp:239] Iteration 730 (1.53076 iter/s, 6.53271s/10 iters), loss = 0.718826
I0829 16:30:27.274240 16790 solver.cpp:258]     Train net output #0: accuracy = 0.980469
I0829 16:30:27.274250 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.690405 (* 0.3 = 0.207122 loss)
I0829 16:30:27.274256 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:30:27.274262 16790 solver.cpp:258]     Train net output #3: entropy = 0.378303 (* 0.8 = 0.302643 loss)
I0829 16:30:27.274268 16790 solver.cpp:258]     Train net output #4: loss = 0.209062 (* 1 = 0.209062 loss)
I0829 16:30:27.274274 16790 sgd_solver.cpp:112] Iteration 730, lr = 0.000662927
I0829 16:30:34.417788 16790 solver.cpp:347] Iteration 740, Testing net (#0)
I0829 16:30:34.417809 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:30:34.417811 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:30:34.417814 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:30:34.417819 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:30:34.417821 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:30:34.417824 16790 net.cpp:676] Ignoring source layer label
I0829 16:30:34.417827 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:30:34.417831 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:30:34.417834 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:30:34.417842 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:30:34.417846 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:30:34.417850 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:30:34.417855 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:30:34.417857 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:30:34.417861 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:30:34.417866 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:30:34.417870 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:30:34.417873 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:30:34.417876 16790 net.cpp:676] Ignoring source layer grl
I0829 16:30:34.417881 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:30:34.417883 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:30:34.417888 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:30:34.417891 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:30:34.417896 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:30:34.417898 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:30:34.417902 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:30:34.417906 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:30:34.417909 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:30:34.417912 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:30:34.417915 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:30:34.417918 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:30:34.417922 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:30:34.417927 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:30:34.417929 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:30:34.417953 16790 net.cpp:676] Ignoring source layer loss
I0829 16:30:34.417958 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:30:34.417960 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:30:35.053851 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:30:39.727975 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:30:39.994166 16790 solver.cpp:239] Iteration 740 (0.786212 iter/s, 12.7192s/10 iters), loss = 0.696161
I0829 16:30:39.994223 16790 solver.cpp:258]     Train net output #0: accuracy = 0.984375
I0829 16:30:39.994235 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.694362 (* 0.3 = 0.208309 loss)
I0829 16:30:39.994241 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:30:39.994248 16790 solver.cpp:258]     Train net output #3: entropy = 0.363002 (* 0.8 = 0.290401 loss)
I0829 16:30:39.994256 16790 solver.cpp:258]     Train net output #4: loss = 0.197451 (* 1 = 0.197451 loss)
I0829 16:30:39.994261 16790 sgd_solver.cpp:112] Iteration 740, lr = 0.000660067
I0829 16:30:46.405637 16790 solver.cpp:239] Iteration 750 (1.55981 iter/s, 6.41105s/10 iters), loss = 0.673512
I0829 16:30:46.405673 16790 solver.cpp:258]     Train net output #0: accuracy = 0.984375
I0829 16:30:46.405683 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.66813 (* 0.3 = 0.200439 loss)
I0829 16:30:46.405688 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:30:46.405692 16790 solver.cpp:258]     Train net output #3: entropy = 0.319285 (* 0.8 = 0.255428 loss)
I0829 16:30:46.405699 16790 solver.cpp:258]     Train net output #4: loss = 0.217645 (* 1 = 0.217645 loss)
I0829 16:30:46.405706 16790 sgd_solver.cpp:112] Iteration 750, lr = 0.000657236
I0829 16:30:53.582963 16790 solver.cpp:347] Iteration 760, Testing net (#0)
I0829 16:30:53.583051 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:30:53.583056 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:30:53.583060 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:30:53.583062 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:30:53.583065 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:30:53.583070 16790 net.cpp:676] Ignoring source layer label
I0829 16:30:53.583072 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:30:53.583075 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:30:53.583077 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:30:53.583086 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:30:53.583089 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:30:53.583093 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:30:53.583097 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:30:53.583102 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:30:53.583106 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:30:53.583111 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:30:53.583113 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:30:53.583117 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:30:53.583120 16790 net.cpp:676] Ignoring source layer grl
I0829 16:30:53.583123 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:30:53.583127 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:30:53.583129 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:30:53.583132 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:30:53.583135 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:30:53.583139 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:30:53.583143 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:30:53.583147 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:30:53.583149 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:30:53.583153 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:30:53.583158 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:30:53.583160 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:30:53.583163 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:30:53.583168 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:30:53.583171 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:30:53.583175 16790 net.cpp:676] Ignoring source layer loss
I0829 16:30:53.583178 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:30:53.583182 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:30:58.892288 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:30:59.153367 16790 solver.cpp:239] Iteration 760 (0.7845 iter/s, 12.747s/10 iters), loss = 0.709778
I0829 16:30:59.153421 16790 solver.cpp:258]     Train net output #0: accuracy = 0.976562
I0829 16:30:59.153432 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.674485 (* 0.3 = 0.202346 loss)
I0829 16:30:59.153439 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:30:59.153445 16790 solver.cpp:258]     Train net output #3: entropy = 0.3615 (* 0.8 = 0.2892 loss)
I0829 16:30:59.153450 16790 solver.cpp:258]     Train net output #4: loss = 0.218232 (* 1 = 0.218232 loss)
I0829 16:30:59.153456 16790 sgd_solver.cpp:112] Iteration 760, lr = 0.000654434
I0829 16:31:05.492483 16790 solver.cpp:239] Iteration 770 (1.57761 iter/s, 6.3387s/10 iters), loss = 0.647193
I0829 16:31:05.492521 16790 solver.cpp:258]     Train net output #0: accuracy = 0.984375
I0829 16:31:05.492529 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.675492 (* 0.3 = 0.202648 loss)
I0829 16:31:05.492534 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:31:05.492542 16790 solver.cpp:258]     Train net output #3: entropy = 0.307497 (* 0.8 = 0.245998 loss)
I0829 16:31:05.492565 16790 solver.cpp:258]     Train net output #4: loss = 0.198548 (* 1 = 0.198548 loss)
I0829 16:31:05.492574 16790 sgd_solver.cpp:112] Iteration 770, lr = 0.000651659
I0829 16:31:12.700454 16790 solver.cpp:347] Iteration 780, Testing net (#0)
I0829 16:31:12.700474 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:31:12.700479 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:31:12.700481 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:31:12.700484 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:31:12.700487 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:31:12.700491 16790 net.cpp:676] Ignoring source layer label
I0829 16:31:12.700495 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:31:12.700497 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:31:12.700500 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:31:12.700508 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:31:12.700511 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:31:12.700515 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:31:12.700520 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:31:12.700523 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:31:12.700526 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:31:12.700531 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:31:12.700536 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:31:12.700538 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:31:12.700541 16790 net.cpp:676] Ignoring source layer grl
I0829 16:31:12.700544 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:31:12.700547 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:31:12.700551 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:31:12.700553 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:31:12.700556 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:31:12.700561 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:31:12.700564 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:31:12.700567 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:31:12.700572 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:31:12.700575 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:31:12.700579 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:31:12.700583 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:31:12.700587 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:31:12.700592 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:31:12.700595 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:31:12.700599 16790 net.cpp:676] Ignoring source layer loss
I0829 16:31:12.700603 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:31:12.700606 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:31:13.019294 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:31:17.973057 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:31:18.254273 16790 solver.cpp:239] Iteration 780 (0.783635 iter/s, 12.761s/10 iters), loss = 0.684897
I0829 16:31:18.254334 16790 solver.cpp:258]     Train net output #0: accuracy = 0.972656
I0829 16:31:18.254345 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.686079 (* 0.3 = 0.205824 loss)
I0829 16:31:18.254350 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:31:18.254356 16790 solver.cpp:258]     Train net output #3: entropy = 0.340172 (* 0.8 = 0.272138 loss)
I0829 16:31:18.254362 16790 solver.cpp:258]     Train net output #4: loss = 0.206936 (* 1 = 0.206936 loss)
I0829 16:31:18.254369 16790 sgd_solver.cpp:112] Iteration 780, lr = 0.000648911
I0829 16:31:24.691776 16790 solver.cpp:239] Iteration 790 (1.5535 iter/s, 6.43707s/10 iters), loss = 0.658916
I0829 16:31:24.691890 16790 solver.cpp:258]     Train net output #0: accuracy = 0.96875
I0829 16:31:24.691901 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.674626 (* 0.3 = 0.202388 loss)
I0829 16:31:24.691906 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:31:24.691911 16790 solver.cpp:258]     Train net output #3: entropy = 0.304597 (* 0.8 = 0.243677 loss)
I0829 16:31:24.691917 16790 solver.cpp:258]     Train net output #4: loss = 0.212851 (* 1 = 0.212851 loss)
I0829 16:31:24.691926 16790 sgd_solver.cpp:112] Iteration 790, lr = 0.00064619
I0829 16:31:31.792209 16790 solver.cpp:347] Iteration 800, Testing net (#0)
I0829 16:31:31.792229 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:31:31.792232 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:31:31.792237 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:31:31.792239 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:31:31.792243 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:31:31.792246 16790 net.cpp:676] Ignoring source layer label
I0829 16:31:31.792249 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:31:31.792253 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:31:31.792256 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:31:31.792264 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:31:31.792268 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:31:31.792273 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:31:31.792277 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:31:31.792280 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:31:31.792285 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:31:31.792292 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:31:31.792295 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:31:31.792299 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:31:31.792304 16790 net.cpp:676] Ignoring source layer grl
I0829 16:31:31.792306 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:31:31.792311 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:31:31.792315 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:31:31.792320 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:31:31.792325 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:31:31.792327 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:31:31.792331 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:31:31.792335 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:31:31.792341 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:31:31.792346 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:31:31.792349 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:31:31.792353 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:31:31.792359 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:31:31.792363 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:31:31.792367 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:31:31.792373 16790 net.cpp:676] Ignoring source layer loss
I0829 16:31:31.792376 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:31:31.792382 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:31:37.046865 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:31:37.310369 16790 solver.cpp:239] Iteration 800 (0.792533 iter/s, 12.6178s/10 iters), loss = 0.656321
I0829 16:31:37.310422 16790 solver.cpp:258]     Train net output #0: accuracy = 0.992188
I0829 16:31:37.310434 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.669158 (* 0.3 = 0.200747 loss)
I0829 16:31:37.310438 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:31:37.310446 16790 solver.cpp:258]     Train net output #3: entropy = 0.318636 (* 0.8 = 0.254909 loss)
I0829 16:31:37.310472 16790 solver.cpp:258]     Train net output #4: loss = 0.200665 (* 1 = 0.200665 loss)
I0829 16:31:37.310479 16790 sgd_solver.cpp:112] Iteration 800, lr = 0.000643496
I0829 16:31:43.712642 16790 solver.cpp:239] Iteration 810 (1.56205 iter/s, 6.40185s/10 iters), loss = 0.649355
I0829 16:31:43.712679 16790 solver.cpp:258]     Train net output #0: accuracy = 0.972656
I0829 16:31:43.712689 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.685513 (* 0.3 = 0.205654 loss)
I0829 16:31:43.712693 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:31:43.712699 16790 solver.cpp:258]     Train net output #3: entropy = 0.293845 (* 0.8 = 0.235076 loss)
I0829 16:31:43.712705 16790 solver.cpp:258]     Train net output #4: loss = 0.208624 (* 1 = 0.208624 loss)
I0829 16:31:43.712712 16790 sgd_solver.cpp:112] Iteration 810, lr = 0.000640827
I0829 16:31:50.759384 16790 solver.cpp:347] Iteration 820, Testing net (#0)
I0829 16:31:50.759403 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:31:50.759407 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:31:50.759410 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:31:50.759413 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:31:50.759416 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:31:50.759420 16790 net.cpp:676] Ignoring source layer label
I0829 16:31:50.759423 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:31:50.759426 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:31:50.759429 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:31:50.759439 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:31:50.759443 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:31:50.759445 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:31:50.759450 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:31:50.759454 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:31:50.759457 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:31:50.759461 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:31:50.759465 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:31:50.759469 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:31:50.759472 16790 net.cpp:676] Ignoring source layer grl
I0829 16:31:50.759476 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:31:50.759479 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:31:50.759483 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:31:50.759486 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:31:50.759490 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:31:50.759492 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:31:50.759496 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:31:50.759498 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:31:50.759502 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:31:50.759505 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:31:50.759511 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:31:50.759515 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:31:50.759517 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:31:50.759521 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:31:50.759526 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:31:50.759528 16790 net.cpp:676] Ignoring source layer loss
I0829 16:31:50.759532 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:31:50.759536 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:31:50.765553 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:31:55.995077 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:31:56.253778 16790 solver.cpp:239] Iteration 820 (0.797423 iter/s, 12.5404s/10 iters), loss = 0.675343
I0829 16:31:56.253831 16790 solver.cpp:258]     Train net output #0: accuracy = 0.984375
I0829 16:31:56.253844 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.678001 (* 0.3 = 0.2034 loss)
I0829 16:31:56.253849 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:31:56.253855 16790 solver.cpp:258]     Train net output #3: entropy = 0.356284 (* 0.8 = 0.285027 loss)
I0829 16:31:56.253861 16790 solver.cpp:258]     Train net output #4: loss = 0.186916 (* 1 = 0.186916 loss)
I0829 16:31:56.253870 16790 sgd_solver.cpp:112] Iteration 820, lr = 0.000638185
I0829 16:32:02.788528 16790 solver.cpp:239] Iteration 830 (1.53038 iter/s, 6.53432s/10 iters), loss = 0.623534
I0829 16:32:02.788564 16790 solver.cpp:258]     Train net output #0: accuracy = 0.976562
I0829 16:32:02.788574 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.67633 (* 0.3 = 0.202899 loss)
I0829 16:32:02.788579 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:32:02.788585 16790 solver.cpp:258]     Train net output #3: entropy = 0.286221 (* 0.8 = 0.228977 loss)
I0829 16:32:02.788591 16790 solver.cpp:258]     Train net output #4: loss = 0.191658 (* 1 = 0.191658 loss)
I0829 16:32:02.788597 16790 sgd_solver.cpp:112] Iteration 830, lr = 0.000635568
I0829 16:32:09.918076 16790 solver.cpp:347] Iteration 840, Testing net (#0)
I0829 16:32:09.918097 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:32:09.918100 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:32:09.918103 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:32:09.918107 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:32:09.918109 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:32:09.918112 16790 net.cpp:676] Ignoring source layer label
I0829 16:32:09.918115 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:32:09.918119 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:32:09.918123 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:32:09.918130 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:32:09.918133 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:32:09.918138 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:32:09.918143 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:32:09.918145 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:32:09.918148 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:32:09.918154 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:32:09.918157 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:32:09.918160 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:32:09.918165 16790 net.cpp:676] Ignoring source layer grl
I0829 16:32:09.918169 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:32:09.918172 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:32:09.918176 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:32:09.918180 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:32:09.918185 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:32:09.918190 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:32:09.918192 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:32:09.918195 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:32:09.918200 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:32:09.918203 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:32:09.918207 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:32:09.918211 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:32:09.918216 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:32:09.918220 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:32:09.918223 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:32:09.918248 16790 net.cpp:676] Ignoring source layer loss
I0829 16:32:09.918253 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:32:09.918256 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:32:15.032838 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:32:15.106854 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:32:15.386523 16790 solver.cpp:239] Iteration 840 (0.793824 iter/s, 12.5972s/10 iters), loss = 0.720665
I0829 16:32:15.386584 16790 solver.cpp:258]     Train net output #0: accuracy = 0.980469
I0829 16:32:15.386595 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.67116 (* 0.3 = 0.201348 loss)
I0829 16:32:15.386600 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:32:15.386606 16790 solver.cpp:258]     Train net output #3: entropy = 0.389832 (* 0.8 = 0.311865 loss)
I0829 16:32:15.386612 16790 solver.cpp:258]     Train net output #4: loss = 0.207452 (* 1 = 0.207452 loss)
I0829 16:32:15.386620 16790 sgd_solver.cpp:112] Iteration 840, lr = 0.000632975
I0829 16:32:21.899075 16790 solver.cpp:239] Iteration 850 (1.5356 iter/s, 6.51212s/10 iters), loss = 0.665745
I0829 16:32:21.899109 16790 solver.cpp:258]     Train net output #0: accuracy = 0.976562
I0829 16:32:21.899118 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.682864 (* 0.3 = 0.204859 loss)
I0829 16:32:21.899123 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:32:21.899130 16790 solver.cpp:258]     Train net output #3: entropy = 0.336722 (* 0.8 = 0.269377 loss)
I0829 16:32:21.899137 16790 solver.cpp:258]     Train net output #4: loss = 0.191509 (* 1 = 0.191509 loss)
I0829 16:32:21.899142 16790 sgd_solver.cpp:112] Iteration 850, lr = 0.000630407
I0829 16:32:29.000494 16790 solver.cpp:347] Iteration 860, Testing net (#0)
I0829 16:32:29.000597 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:32:29.000602 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:32:29.000605 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:32:29.000607 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:32:29.000610 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:32:29.000615 16790 net.cpp:676] Ignoring source layer label
I0829 16:32:29.000618 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:32:29.000622 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:32:29.000624 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:32:29.000633 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:32:29.000636 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:32:29.000641 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:32:29.000646 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:32:29.000650 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:32:29.000654 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:32:29.000659 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:32:29.000663 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:32:29.000666 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:32:29.000670 16790 net.cpp:676] Ignoring source layer grl
I0829 16:32:29.000674 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:32:29.000676 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:32:29.000681 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:32:29.000684 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:32:29.000687 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:32:29.000691 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:32:29.000695 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:32:29.000699 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:32:29.000701 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:32:29.000705 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:32:29.000710 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:32:29.000712 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:32:29.000717 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:32:29.000721 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:32:29.000726 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:32:29.000730 16790 net.cpp:676] Ignoring source layer loss
I0829 16:32:29.000732 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:32:29.000736 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:32:34.189232 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:32:34.446985 16790 solver.cpp:239] Iteration 860 (0.796993 iter/s, 12.5472s/10 iters), loss = 0.651714
I0829 16:32:34.447041 16790 solver.cpp:258]     Train net output #0: accuracy = 0.980469
I0829 16:32:34.447053 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.666001 (* 0.3 = 0.1998 loss)
I0829 16:32:34.447059 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:32:34.447065 16790 solver.cpp:258]     Train net output #3: entropy = 0.327253 (* 0.8 = 0.261802 loss)
I0829 16:32:34.447070 16790 solver.cpp:258]     Train net output #4: loss = 0.190111 (* 1 = 0.190111 loss)
I0829 16:32:34.447077 16790 sgd_solver.cpp:112] Iteration 860, lr = 0.000627864
I0829 16:32:40.836910 16790 solver.cpp:239] Iteration 870 (1.56507 iter/s, 6.3895s/10 iters), loss = 0.62132
I0829 16:32:40.836946 16790 solver.cpp:258]     Train net output #0: accuracy = 0.992188
I0829 16:32:40.836956 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.67341 (* 0.3 = 0.202023 loss)
I0829 16:32:40.836959 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:32:40.836966 16790 solver.cpp:258]     Train net output #3: entropy = 0.3189 (* 0.8 = 0.25512 loss)
I0829 16:32:40.836989 16790 solver.cpp:258]     Train net output #4: loss = 0.164177 (* 1 = 0.164177 loss)
I0829 16:32:40.836997 16790 sgd_solver.cpp:112] Iteration 870, lr = 0.000625344
I0829 16:32:47.913362 16790 solver.cpp:347] Iteration 880, Testing net (#0)
I0829 16:32:47.913381 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:32:47.913388 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:32:47.913390 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:32:47.913393 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:32:47.913396 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:32:47.913400 16790 net.cpp:676] Ignoring source layer label
I0829 16:32:47.913403 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:32:47.913406 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:32:47.913409 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:32:47.913417 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:32:47.913420 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:32:47.913424 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:32:47.913429 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:32:47.913431 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:32:47.913435 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:32:47.913441 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:32:47.913444 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:32:47.913449 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:32:47.913451 16790 net.cpp:676] Ignoring source layer grl
I0829 16:32:47.913455 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:32:47.913460 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:32:47.913462 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:32:47.913466 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:32:47.913470 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:32:47.913473 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:32:47.913476 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:32:47.913480 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:32:47.913483 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:32:47.913487 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:32:47.913491 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:32:47.913494 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:32:47.913497 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:32:47.913502 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:32:47.913506 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:32:47.913508 16790 net.cpp:676] Ignoring source layer loss
I0829 16:32:47.913512 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:32:47.913516 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:32:52.779165 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:32:53.105386 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:32:53.367727 16790 solver.cpp:239] Iteration 880 (0.798081 iter/s, 12.5301s/10 iters), loss = 0.655267
I0829 16:32:53.367765 16790 solver.cpp:258]     Train net output #0: accuracy = 0.984375
I0829 16:32:53.367775 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.679648 (* 0.3 = 0.203895 loss)
I0829 16:32:53.367780 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:32:53.367789 16790 solver.cpp:258]     Train net output #3: entropy = 0.323369 (* 0.8 = 0.258695 loss)
I0829 16:32:53.367796 16790 solver.cpp:258]     Train net output #4: loss = 0.192678 (* 1 = 0.192678 loss)
I0829 16:32:53.367803 16790 sgd_solver.cpp:112] Iteration 880, lr = 0.000622847
I0829 16:32:59.820894 16790 solver.cpp:239] Iteration 890 (1.54973 iter/s, 6.45276s/10 iters), loss = 0.616073
I0829 16:32:59.821003 16790 solver.cpp:258]     Train net output #0: accuracy = 0.980469
I0829 16:32:59.821017 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.681845 (* 0.3 = 0.204554 loss)
I0829 16:32:59.821020 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:32:59.821027 16790 solver.cpp:258]     Train net output #3: entropy = 0.282792 (* 0.8 = 0.226233 loss)
I0829 16:32:59.821032 16790 solver.cpp:258]     Train net output #4: loss = 0.185286 (* 1 = 0.185286 loss)
I0829 16:32:59.821039 16790 sgd_solver.cpp:112] Iteration 890, lr = 0.000620374
I0829 16:33:06.978979 16790 solver.cpp:347] Iteration 900, Testing net (#0)
I0829 16:33:06.978998 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:33:06.979002 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:33:06.979005 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:33:06.979008 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:33:06.979012 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:33:06.979014 16790 net.cpp:676] Ignoring source layer label
I0829 16:33:06.979018 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:33:06.979022 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:33:06.979024 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:33:06.979032 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:33:06.979037 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:33:06.979039 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:33:06.979043 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:33:06.979046 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:33:06.979050 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:33:06.979055 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:33:06.979059 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:33:06.979064 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:33:06.979068 16790 net.cpp:676] Ignoring source layer grl
I0829 16:33:06.979071 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:33:06.979074 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:33:06.979079 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:33:06.979081 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:33:06.979084 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:33:06.979087 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:33:06.979090 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:33:06.979094 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:33:06.979097 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:33:06.979100 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:33:06.979104 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:33:06.979107 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:33:06.979111 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:33:06.979116 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:33:06.979120 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:33:06.979125 16790 net.cpp:676] Ignoring source layer loss
I0829 16:33:06.979127 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:33:06.979131 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:33:12.167732 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:33:12.440917 16790 solver.cpp:239] Iteration 900 (0.792443 iter/s, 12.6192s/10 iters), loss = 0.651679
I0829 16:33:12.440975 16790 solver.cpp:258]     Train net output #0: accuracy = 0.988281
I0829 16:33:12.440986 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.683505 (* 0.3 = 0.205052 loss)
I0829 16:33:12.440990 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:33:12.440997 16790 solver.cpp:258]     Train net output #3: entropy = 0.342504 (* 0.8 = 0.274003 loss)
I0829 16:33:12.441021 16790 solver.cpp:258]     Train net output #4: loss = 0.172624 (* 1 = 0.172624 loss)
I0829 16:33:12.441030 16790 sgd_solver.cpp:112] Iteration 900, lr = 0.000617924
I0829 16:33:18.968497 16790 solver.cpp:239] Iteration 910 (1.53206 iter/s, 6.52714s/10 iters), loss = 0.666269
I0829 16:33:18.968533 16790 solver.cpp:258]     Train net output #0: accuracy = 0.988281
I0829 16:33:18.968542 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.680648 (* 0.3 = 0.204195 loss)
I0829 16:33:18.968547 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:33:18.968552 16790 solver.cpp:258]     Train net output #3: entropy = 0.402237 (* 0.8 = 0.32179 loss)
I0829 16:33:18.968559 16790 solver.cpp:258]     Train net output #4: loss = 0.140285 (* 1 = 0.140285 loss)
I0829 16:33:18.968564 16790 sgd_solver.cpp:112] Iteration 910, lr = 0.000615496
I0829 16:33:26.042081 16790 solver.cpp:347] Iteration 920, Testing net (#0)
I0829 16:33:26.042100 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:33:26.042105 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:33:26.042109 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:33:26.042111 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:33:26.042114 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:33:26.042119 16790 net.cpp:676] Ignoring source layer label
I0829 16:33:26.042121 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:33:26.042124 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:33:26.042127 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:33:26.042136 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:33:26.042140 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:33:26.042142 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:33:26.042147 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:33:26.042152 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:33:26.042155 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:33:26.042160 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:33:26.042163 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:33:26.042170 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:33:26.042172 16790 net.cpp:676] Ignoring source layer grl
I0829 16:33:26.042176 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:33:26.042178 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:33:26.042182 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:33:26.042184 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:33:26.042187 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:33:26.042191 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:33:26.042194 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:33:26.042198 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:33:26.042201 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:33:26.042204 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:33:26.042212 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:33:26.042215 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:33:26.042218 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:33:26.042222 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:33:26.042225 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:33:26.042230 16790 net.cpp:676] Ignoring source layer loss
I0829 16:33:26.042232 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:33:26.042237 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:33:30.753114 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:33:31.332911 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:33:31.592806 16790 solver.cpp:239] Iteration 920 (0.79217 iter/s, 12.6236s/10 iters), loss = 0.650878
I0829 16:33:31.592860 16790 solver.cpp:258]     Train net output #0: accuracy = 0.980469
I0829 16:33:31.592872 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.670586 (* 0.3 = 0.201176 loss)
I0829 16:33:31.592878 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:33:31.592885 16790 solver.cpp:258]     Train net output #3: entropy = 0.331168 (* 0.8 = 0.264934 loss)
I0829 16:33:31.592890 16790 solver.cpp:258]     Train net output #4: loss = 0.184768 (* 1 = 0.184768 loss)
I0829 16:33:31.592898 16790 sgd_solver.cpp:112] Iteration 920, lr = 0.00061309
I0829 16:33:37.929994 16790 solver.cpp:239] Iteration 930 (1.57809 iter/s, 6.33677s/10 iters), loss = 0.621728
I0829 16:33:37.930028 16790 solver.cpp:258]     Train net output #0: accuracy = 0.96875
I0829 16:33:37.930038 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.673476 (* 0.3 = 0.202043 loss)
I0829 16:33:37.930043 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:33:37.930049 16790 solver.cpp:258]     Train net output #3: entropy = 0.278717 (* 0.8 = 0.222973 loss)
I0829 16:33:37.930058 16790 solver.cpp:258]     Train net output #4: loss = 0.196712 (* 1 = 0.196712 loss)
I0829 16:33:37.930063 16790 sgd_solver.cpp:112] Iteration 930, lr = 0.000610706
I0829 16:33:45.256942 16790 solver.cpp:347] Iteration 940, Testing net (#0)
I0829 16:33:45.256963 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:33:45.256966 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:33:45.256969 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:33:45.256973 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:33:45.256975 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:33:45.256979 16790 net.cpp:676] Ignoring source layer label
I0829 16:33:45.256983 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:33:45.256985 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:33:45.256989 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:33:45.256996 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:33:45.256999 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:33:45.257004 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:33:45.257011 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:33:45.257014 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:33:45.257019 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:33:45.257025 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:33:45.257028 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:33:45.257032 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:33:45.257035 16790 net.cpp:676] Ignoring source layer grl
I0829 16:33:45.257040 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:33:45.257042 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:33:45.257046 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:33:45.257050 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:33:45.257053 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:33:45.257056 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:33:45.257061 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:33:45.257063 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:33:45.257067 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:33:45.257073 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:33:45.257079 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:33:45.257084 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:33:45.257091 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:33:45.257095 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:33:45.257115 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:33:45.257119 16790 net.cpp:676] Ignoring source layer loss
I0829 16:33:45.257124 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:33:45.257129 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:33:50.473204 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:33:50.739527 16790 solver.cpp:239] Iteration 940 (0.780715 iter/s, 12.8088s/10 iters), loss = 0.58538
I0829 16:33:50.739586 16790 solver.cpp:258]     Train net output #0: accuracy = 0.984375
I0829 16:33:50.739599 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.670245 (* 0.3 = 0.201074 loss)
I0829 16:33:50.739605 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:33:50.739612 16790 solver.cpp:258]     Train net output #3: entropy = 0.261472 (* 0.8 = 0.209178 loss)
I0829 16:33:50.739619 16790 solver.cpp:258]     Train net output #4: loss = 0.175129 (* 1 = 0.175129 loss)
I0829 16:33:50.739626 16790 sgd_solver.cpp:112] Iteration 940, lr = 0.000608343
I0829 16:33:57.224915 16790 solver.cpp:239] Iteration 950 (1.54203 iter/s, 6.48496s/10 iters), loss = 0.544303
I0829 16:33:57.224948 16790 solver.cpp:258]     Train net output #0: accuracy = 0.996094
I0829 16:33:57.224959 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.6728 (* 0.3 = 0.20184 loss)
I0829 16:33:57.224963 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:33:57.224969 16790 solver.cpp:258]     Train net output #3: entropy = 0.252948 (* 0.8 = 0.202358 loss)
I0829 16:33:57.224975 16790 solver.cpp:258]     Train net output #4: loss = 0.140105 (* 1 = 0.140105 loss)
I0829 16:33:57.224982 16790 sgd_solver.cpp:112] Iteration 950, lr = 0.000606002
I0829 16:34:04.383610 16790 solver.cpp:347] Iteration 960, Testing net (#0)
I0829 16:34:04.383690 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:34:04.383695 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:34:04.383699 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:34:04.383702 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:34:04.383704 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:34:04.383708 16790 net.cpp:676] Ignoring source layer label
I0829 16:34:04.383728 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:34:04.383731 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:34:04.383735 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:34:04.383744 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:34:04.383750 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:34:04.383754 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:34:04.383759 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:34:04.383764 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:34:04.383769 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:34:04.383772 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:34:04.383777 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:34:04.383780 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:34:04.383783 16790 net.cpp:676] Ignoring source layer grl
I0829 16:34:04.383787 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:34:04.383790 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:34:04.383793 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:34:04.383797 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:34:04.383800 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:34:04.383805 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:34:04.383807 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:34:04.383811 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:34:04.383814 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:34:04.383817 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:34:04.383821 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:34:04.383828 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:34:04.383832 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:34:04.383836 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:34:04.383839 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:34:04.383846 16790 net.cpp:676] Ignoring source layer loss
I0829 16:34:04.383850 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:34:04.383854 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:34:08.844321 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:34:09.688767 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:34:09.969331 16790 solver.cpp:239] Iteration 960 (0.784704 iter/s, 12.7437s/10 iters), loss = 0.624602
I0829 16:34:09.969389 16790 solver.cpp:258]     Train net output #0: accuracy = 0.96875
I0829 16:34:09.969400 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.680696 (* 0.3 = 0.204209 loss)
I0829 16:34:09.969405 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:34:09.969411 16790 solver.cpp:258]     Train net output #3: entropy = 0.273036 (* 0.8 = 0.218429 loss)
I0829 16:34:09.969418 16790 solver.cpp:258]     Train net output #4: loss = 0.201965 (* 1 = 0.201965 loss)
I0829 16:34:09.969424 16790 sgd_solver.cpp:112] Iteration 960, lr = 0.000603682
I0829 16:34:16.382432 16790 solver.cpp:239] Iteration 970 (1.55941 iter/s, 6.41267s/10 iters), loss = 0.585464
I0829 16:34:16.382467 16790 solver.cpp:258]     Train net output #0: accuracy = 0.976562
I0829 16:34:16.382477 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.67316 (* 0.3 = 0.201948 loss)
I0829 16:34:16.382481 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:34:16.382508 16790 solver.cpp:258]     Train net output #3: entropy = 0.258481 (* 0.8 = 0.206785 loss)
I0829 16:34:16.382513 16790 solver.cpp:258]     Train net output #4: loss = 0.176731 (* 1 = 0.176731 loss)
I0829 16:34:16.382520 16790 sgd_solver.cpp:112] Iteration 970, lr = 0.000601382
I0829 16:34:23.530851 16790 solver.cpp:347] Iteration 980, Testing net (#0)
I0829 16:34:23.530870 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:34:23.530875 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:34:23.530879 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:34:23.530881 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:34:23.530885 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:34:23.530889 16790 net.cpp:676] Ignoring source layer label
I0829 16:34:23.530892 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:34:23.530895 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:34:23.530899 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:34:23.530906 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:34:23.530910 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:34:23.530912 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:34:23.530918 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:34:23.530921 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:34:23.530925 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:34:23.530930 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:34:23.530933 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:34:23.530936 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:34:23.530939 16790 net.cpp:676] Ignoring source layer grl
I0829 16:34:23.530942 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:34:23.530947 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:34:23.530949 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:34:23.530953 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:34:23.530956 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:34:23.530961 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:34:23.530963 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:34:23.530966 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:34:23.530970 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:34:23.530974 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:34:23.530979 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:34:23.530982 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:34:23.530987 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:34:23.530993 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:34:23.530997 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:34:23.531000 16790 net.cpp:676] Ignoring source layer loss
I0829 16:34:23.531003 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:34:23.531008 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:34:28.757390 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:34:29.019261 16790 solver.cpp:239] Iteration 980 (0.791385 iter/s, 12.6361s/10 iters), loss = 0.58919
I0829 16:34:29.019320 16790 solver.cpp:258]     Train net output #0: accuracy = 0.988281
I0829 16:34:29.019333 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.689683 (* 0.3 = 0.206905 loss)
I0829 16:34:29.019337 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:34:29.019343 16790 solver.cpp:258]     Train net output #3: entropy = 0.275234 (* 0.8 = 0.220187 loss)
I0829 16:34:29.019349 16790 solver.cpp:258]     Train net output #4: loss = 0.162097 (* 1 = 0.162097 loss)
I0829 16:34:29.019357 16790 sgd_solver.cpp:112] Iteration 980, lr = 0.000599102
I0829 16:34:35.391758 16790 solver.cpp:239] Iteration 990 (1.56935 iter/s, 6.37207s/10 iters), loss = 0.597925
I0829 16:34:35.391868 16790 solver.cpp:258]     Train net output #0: accuracy = 0.972656
I0829 16:34:35.391880 16790 solver.cpp:258]     Train net output #1: dc_loss = 0.668362 (* 0.3 = 0.200509 loss)
I0829 16:34:35.391886 16790 solver.cpp:258]     Train net output #2: domain_accuracy = 1
I0829 16:34:35.391891 16790 solver.cpp:258]     Train net output #3: entropy = 0.266897 (* 0.8 = 0.213518 loss)
I0829 16:34:35.391897 16790 solver.cpp:258]     Train net output #4: loss = 0.183898 (* 1 = 0.183898 loss)
I0829 16:34:35.391904 16790 sgd_solver.cpp:112] Iteration 990, lr = 0.000596843
I0829 16:34:42.480109 16790 solver.cpp:464] Snapshotting to binary proto file snapshots/aw2d-bn_with_dann-alexnet_iter_1000.caffemodel
I0829 16:34:43.381335 16790 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/aw2d-bn_with_dann-alexnet_iter_1000.solverstate
I0829 16:34:43.790022 16790 solver.cpp:327] Iteration 1000, loss = 0.547383
I0829 16:34:43.790047 16790 solver.cpp:347] Iteration 1000, Testing net (#0)
I0829 16:34:43.790053 16790 net.cpp:676] Ignoring source layer s1_data
I0829 16:34:43.790057 16790 net.cpp:676] Ignoring source layer s2_data
I0829 16:34:43.790060 16790 net.cpp:676] Ignoring source layer target_data
I0829 16:34:43.790062 16790 net.cpp:676] Ignoring source layer source_domain_labels
I0829 16:34:43.790066 16790 net.cpp:676] Ignoring source layer target_domain_labels
I0829 16:34:43.790071 16790 net.cpp:676] Ignoring source layer label
I0829 16:34:43.790073 16790 net.cpp:676] Ignoring source layer label_label_0_split
I0829 16:34:43.790076 16790 net.cpp:676] Ignoring source layer concat_domain_labels
I0829 16:34:43.790081 16790 net.cpp:676] Ignoring source layer domain_labels_concat_domain_labels_0_split
I0829 16:34:43.790089 16790 net.cpp:676] Ignoring source layer slicer_fc6
I0829 16:34:43.790092 16790 net.cpp:676] Ignoring source layer fc6_source/bn
I0829 16:34:43.790096 16790 net.cpp:676] Ignoring source layer concat_wbn_6
I0829 16:34:43.790100 16790 net.cpp:676] Ignoring source layer slicer_fc7
I0829 16:34:43.790103 16790 net.cpp:676] Ignoring source layer fc7_source/bn
I0829 16:34:43.790108 16790 net.cpp:676] Ignoring source layer concat_wbn_7
I0829 16:34:43.790112 16790 net.cpp:676] Ignoring source layer bottleneck_bottleneck_0_split
I0829 16:34:43.790117 16790 net.cpp:676] Ignoring source layer slicer_bottle
I0829 16:34:43.790119 16790 net.cpp:676] Ignoring source layer silence_target_feature
I0829 16:34:43.790122 16790 net.cpp:676] Ignoring source layer grl
I0829 16:34:43.790125 16790 net.cpp:676] Ignoring source layer dc_ip1
I0829 16:34:43.790128 16790 net.cpp:676] Ignoring source layer dc_relu1
I0829 16:34:43.790132 16790 net.cpp:676] Ignoring source layer dc_drop1
I0829 16:34:43.790134 16790 net.cpp:676] Ignoring source layer dc_ip2
I0829 16:34:43.790138 16790 net.cpp:676] Ignoring source layer dc_relu2
I0829 16:34:43.790143 16790 net.cpp:676] Ignoring source layer dc_drop2
I0829 16:34:43.790145 16790 net.cpp:676] Ignoring source layer dc_ip3
I0829 16:34:43.790148 16790 net.cpp:676] Ignoring source layer dc_ip3_dc_ip3_0_split
I0829 16:34:43.790151 16790 net.cpp:676] Ignoring source layer dc_loss
I0829 16:34:43.790155 16790 net.cpp:676] Ignoring source layer dc_accuracy
I0829 16:34:43.790158 16790 net.cpp:676] Ignoring source layer slicer_fc8
I0829 16:34:43.790163 16790 net.cpp:676] Ignoring source layer fc8_source/bn
I0829 16:34:43.790166 16790 net.cpp:676] Ignoring source layer concat_wbn_8
I0829 16:34:43.790170 16790 net.cpp:676] Ignoring source layer slicer_scorer
I0829 16:34:43.790174 16790 net.cpp:676] Ignoring source layer score_source_slicer_scorer_0_split
I0829 16:34:43.790177 16790 net.cpp:676] Ignoring source layer loss
I0829 16:34:43.790181 16790 net.cpp:676] Ignoring source layer entropy
I0829 16:34:43.790185 16790 net.cpp:676] Ignoring source layer silence_target
I0829 16:34:47.999366 16790 blocking_queue.cpp:49] Waiting for data
I0829 16:34:49.105177 16790 solver.cpp:414]     Test net output #0: accuracy = 0.929719
I0829 16:34:49.105208 16790 solver.cpp:332] Optimization Done.
I0829 16:34:49.105243 16790 caffe.cpp:250] Optimization Done.
