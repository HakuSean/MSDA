# # --- source data combined 

# layer {
#   name: "data"
#   type: "ImageData"
#   top: "data"
#   top: "labels"
#   include {
#     phase: TRAIN
#   }
#   transform_param {
#     crop_size: 224
#     mirror: true
#     mean_value: 104
#     mean_value: 117
#     mean_value: 123

#   }
#   image_data_param {
#     batch_size: 24
#     source: "/home/alfa/Documents/msda/mywork/data/pacs/pacs_no_a.txt"
#     shuffle: true
#     is_color: true
#     new_height: 256
#     new_width: 256
  
#   }
# }

# -------------------- source data not combined
layer {
  name: "data-source1"
  type: "ImageData"
  top: "data-source1"
  top: "labels-source1"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 224
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123

  }
  image_data_param {
    batch_size: 8
    source: "/home/alfa/Documents/msda/mywork/data/pacs/pacs_p.txt"
    shuffle: true
    is_color: true
    new_height: 256
    new_width: 256
  
  }
}

layer {
  name: "data-source2"
  type: "ImageData"
  top: "data-source2"
  top: "labels-source2"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 224
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123

  }
  image_data_param {
    batch_size: 8
    source: "/home/alfa/Documents/msda/mywork/data/pacs/pacs_c.txt"
    shuffle: true
    is_color: true
    new_height: 256
    new_width: 256
  
  }
}


layer {
  name: "data-source3"
  type: "ImageData"
  top: "data-source3"
  top: "labels-source3"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 224
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123

  }
  image_data_param {
    batch_size: 8
    source: "/home/alfa/Documents/msda/mywork/data/pacs/pacs_s.txt"
    shuffle: true
    is_color: true
    new_height: 256
    new_width: 256
  
  }
}

layer {
  name: "data-4"
  type: "ImageData"
  top: "data-target"
  top: "labels-target"
  include {
    phase: TRAIN
  }
  transform_param {
   crop_size: 224
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123

  }
  image_data_param {
    batch_size: 16
    source: "/home/alfa/Documents/msda/mywork/data/pacs/pacs_a.txt"
    shuffle: true
    is_color: true
    new_height: 256
    new_width: 256
  
  }
}

layer{
    name: "data-concat"
    type: "Concat"
    bottom: "data-source1"
    bottom: "data-source2"
    bottom: "data-source3"
    bottom: "data-target"
    top: "data"
    include {
        phase: TRAIN
    }
    concat_param {
        axis: 0
    }
}

layer{
    name: "labels-concat"
    type: "Concat"
    bottom: "labels-source1"
    bottom: "labels-source2"
    bottom: "labels-source3"
    top: "labels"
    include {
        phase: TRAIN
    }
    concat_param {
        axis: 0
    }
}

# ---------- target data

layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "labels"
  include {
    phase: TEST
  }
  transform_param {
   crop_size: 224
    mirror: false
    mean_value: 104
    mean_value: 117
    mean_value: 123

  }
  image_data_param {
    batch_size: 1
    source: "/home/alfa/Documents/msda/mywork/data/pacs/pacs_a.txt"
    shuffle: false
    is_color: true
    new_height: 256
    new_width: 256
  }
}

# ----------------------------- dummy labels
layer {
  name: "source1_domain_labels"
  type: "DummyData"
  top: "source1_domain_labels"
  dummy_data_param {
    data_filler {
      type: "constant"
      value: 0
    }
    num: 8 # original is 64
    channels: 1
    height: 1
    width: 1
  }
  include: { 
    phase: TRAIN
  }
}

layer {
  name: "source2_domain_labels"
  type: "DummyData"
  top: "source2_domain_labels"
  dummy_data_param {
    data_filler {
      type: "constant"
      value: 0
    }
    num: 8 # original is 64
    channels: 1
    height: 1
    width: 1
  }
  include: {
    phase: TRAIN
  }
}

layer {
  name: "source3_domain_labels"
  type: "DummyData"
  top: "source3_domain_labels"
  dummy_data_param {
    data_filler {
      type: "constant"
      value: 0
    }
    num: 8 # original is 64
    channels: 1
    height: 1
    width: 1
  }
  include: {
    phase: TRAIN
  }
}

layer {
  name: "target_domain_labels"
  type: "DummyData"
  top: "target_domain_labels"
  dummy_data_param {
    data_filler {
      type: "constant"
      value: 1
    }
    num: 16
    channels: 1
    height: 1
    width: 1
  }
  include: {
    phase: TRAIN
  }
}

layer {
  name: "concat_domain_labels"
  type: "Concat"
  bottom: "source1_domain_labels"
  bottom: "source2_domain_labels"
  bottom: "source3_domain_labels"
  bottom: "target_domain_labels"
  top: "dc_labels"
  concat_param {
    concat_dim: 0
  }
  include: {
    phase: TRAIN
  }
}

# --------------------- start convs
layer {
    bottom: "data"
    top: "conv1"
    name: "conv1"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 7
        pad: 3
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "conv1"
    top: "conv1"
    name: "bn_conv1"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
}

layer {
    bottom: "conv1"
    top: "conv1"
    name: "scale_conv1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "conv1"
    top: "conv1"
    name: "conv1_relu"
    type: "ReLU"
}

layer {
    bottom: "conv1"
    top: "pool1"
    name: "pool1"
    type: "Pooling"
    pooling_param {
        kernel_size: 3
        stride: 2
        pool: MAX
    }
}

layer {
    bottom: "pool1"
    top: "res2a_branch1"
    name: "res2a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 1
        pad: 0
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res2a_branch1"
    top: "res2a_branch1"
    name: "bn2a_branch1"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res2a_branch1"
    top: "res2a_branch1"
    name: "scale2a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "pool1"
    top: "res2a_branch2a"
    name: "res2a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "bn2a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "scale2a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "res2a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res2a_branch2a"
    top: "res2a_branch2b"
    name: "res2a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res2a_branch2b"
    top: "res2a_branch2b"
    name: "bn2a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res2a_branch2b"
    top: "res2a_branch2b"
    name: "scale2a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2a_branch1"
    bottom: "res2a_branch2b"
    top: "res2a"
    name: "res2a"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res2a"
    top: "res2a"
    name: "res2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res2a"
    top: "res2b_branch2a"
    name: "res2b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "bn2b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "scale2b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "res2b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res2b_branch2a"
    top: "res2b_branch2b"
    name: "res2b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res2b_branch2b"
    top: "res2b_branch2b"
    name: "bn2b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res2b_branch2b"
    top: "res2b_branch2b"
    name: "scale2b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2a"
    bottom: "res2b_branch2b"
    top: "res2b"
    name: "res2b"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res2b"
    top: "res2b"
    name: "res2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res2b"
    top: "res3a_branch1"
    name: "res3a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 1
        pad: 0
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res3a_branch1"
    top: "res3a_branch1"
    name: "bn3a_branch1"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res3a_branch1"
    top: "res3a_branch1"
    name: "scale3a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2b"
    top: "res3a_branch2a"
    name: "res3a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "bn3a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "scale3a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "res3a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res3a_branch2a"
    top: "res3a_branch2b"
    name: "res3a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res3a_branch2b"
    top: "res3a_branch2b"
    name: "bn3a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res3a_branch2b"
    top: "res3a_branch2b"
    name: "scale3a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3a_branch1"
    bottom: "res3a_branch2b"
    top: "res3a"
    name: "res3a"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res3a"
    top: "res3a"
    name: "res3a_relu"
    type: "ReLU"
}

layer {
    bottom: "res3a"
    top: "res3b_branch2a"
    name: "res3b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "bn3b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "scale3b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "res3b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res3b_branch2a"
    top: "res3b_branch2b"
    name: "res3b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res3b_branch2b"
    top: "res3b_branch2b"
    name: "bn3b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res3b_branch2b"
    top: "res3b_branch2b"
    name: "scale3b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3a"
    bottom: "res3b_branch2b"
    top: "res3b"
    name: "res3b"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res3b"
    top: "res3b"
    name: "res3b_relu"
    type: "ReLU"
}

layer {
    bottom: "res3b"
    top: "res4a_branch1"
    name: "res4a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res4a_branch1"
    top: "res4a_branch1"
    name: "bn4a_branch1"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res4a_branch1"
    top: "res4a_branch1"
    name: "scale4a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3b"
    top: "res4a_branch2a"
    name: "res4a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "bn4a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "scale4a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "res4a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4a_branch2a"
    top: "res4a_branch2b"
    name: "res4a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res4a_branch2b"
    top: "res4a_branch2b"
    name: "bn4a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res4a_branch2b"
    top: "res4a_branch2b"
    name: "scale4a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4a_branch1"
    bottom: "res4a_branch2b"
    top: "res4a"
    name: "res4a"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res4a"
    top: "res4a"
    name: "res4a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4a"
    top: "res4b_branch2a"
    name: "res4b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "bn4b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "scale4b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "res4b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4b_branch2a"
    top: "res4b_branch2b"
    name: "res4b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res4b_branch2b"
    top: "res4b_branch2b"
    name: "bn4b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res4b_branch2b"
    top: "res4b_branch2b"
    name: "scale4b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4a"
    bottom: "res4b_branch2b"
    top: "res4b"
    name: "res4b"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res4b"
    top: "res4b"
    name: "res4b_relu"
    type: "ReLU"
}

layer {
    bottom: "res4b"
    top: "res5a_branch1"
    name: "res5a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res5a_branch1"
    top: "res5a_branch1"
    name: "bn5a_branch1"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res5a_branch1"
    top: "res5a_branch1"
    name: "scale5a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4b"
    top: "res5a_branch2a"
    name: "res5a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        pad: 1
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res5a_branch2a"
    top: "res5a_branch2a"
    name: "bn5a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res5a_branch2a"
    top: "res5a_branch2a"
    name: "scale5a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5a_branch2a"
    top: "res5a_branch2a"
    name: "res5a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res5a_branch2a"
    top: "res5a_branch2b"
    name: "res5a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res5a_branch2b"
    top: "res5a_branch2b"
    name: "bn5a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res5a_branch2b"
    top: "res5a_branch2b"
    name: "scale5a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5a_branch1"
    bottom: "res5a_branch2b"
    top: "res5a"
    name: "res5a"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res5a"
    top: "res5a"
    name: "res5a_relu"
    type: "ReLU"
}

layer {
    bottom: "res5a"
    top: "res5b_branch2a"
    name: "res5b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res5b_branch2a"
    top: "res5b_branch2a"
    name: "bn5b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res5b_branch2a"
    top: "res5b_branch2a"
    name: "scale5b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5b_branch2a"
    top: "res5b_branch2a"
    name: "res5b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res5b_branch2a"
    top: "res5b_branch2b"
    name: "res5b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res5b_branch2b"
    top: "res5b_branch2b"
    name: "bn5b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
    }
    
}

layer {
    bottom: "res5b_branch2b"
    top: "res5b_branch2b"
    name: "scale5b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5a"
    bottom: "res5b_branch2b"
    top: "res5b"
    name: "res5b"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res5b"
    top: "res5b"
    name: "res5b_relu"
    type: "ReLU"
}

layer {
    bottom: "res5b"
    top: "pool5"
    name: "pool5"
    type: "Pooling"
    pooling_param {
        kernel_size: 7 # in boosting, they use global_pooling: true, why?
        stride: 1
        pool: AVE
    }
}

# ------------------- DANN
# ----------------------------------------------------------------------------
layer {
  name: "bottleneck"
  type: "InnerProduct"
  bottom: "pool5"
  top: "bottleneck"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}

# -----------------------------------------------------------------------------
# ----------------------------------------------------------- Gradient reversal
# -----------------------------------------------------------------------------
layer {
  name: "grl"
  type: "GradientScaler"
  bottom: "bottleneck"
  top: "grl"
  gradient_scaler_param {
    lower_bound: 0.0
    upper_bound: 1.0
    alpha: 10.0
    max_iter: 1000
  }
  include: { phase: TRAIN }
}

# -----------------------------------------------------------------------------
# ----------------------------------------------------------- Domain classifier
# -----------------------------------------------------------------------------
layer {
  name: "dc_ip1"
  type: "InnerProduct"
  bottom: "grl"
  top: "dc_ip1"
  param {
    lr_mult: 10
  }
  param {
    lr_mult: 20
  }
  inner_product_param {
    num_output: 3072
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
  include: { phase: TRAIN }
}
layer {
  name: "dc_relu1"
  type: "ReLU"
  bottom: "dc_ip1"
  top: "dc_ip1"
  include: { phase: TRAIN }
}
layer {
  name: "dc_drop1"
  type: "Dropout"
  bottom: "dc_ip1"
  top: "dc_ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
  include: { phase: TRAIN }
}
# ----------------------------------------------------------------------------
layer {
  name: "dc_ip2"
  type: "InnerProduct"
  bottom: "dc_ip1"
  top: "dc_ip2"
  param {
    lr_mult: 10
  }
  param {
    lr_mult: 20
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
  include: { phase: TRAIN }
}
layer {
  name: "dc_relu2"
  type: "ReLU"
  bottom: "dc_ip2"
  top: "dc_ip2"
  include: { phase: TRAIN }
}
layer {
  name: "dc_drop2"
  type: "Dropout"
  bottom: "dc_ip2"
  top: "dc_ip2"
  dropout_param {
    dropout_ratio: 0.5
  }
  include: { phase: TRAIN }
}
# ----------------------------------------------------------------------------
layer {
  name: "dc_ip3"
  type: "InnerProduct"
  bottom: "dc_ip2"
  top: "dc_ip3"
  param {
    lr_mult: 10
  }
  param {
    lr_mult: 20
  }
  inner_product_param {
    num_output: 3
    weight_filler {
      type: "gaussian"
      std: 0.3
    }
    bias_filler {
      type: "constant"
    }
  }
  include: { phase: TRAIN }
}
layer {
  name: "dc_loss"
  type: "SoftmaxWithLoss"
  bottom: "dc_ip3"
  bottom: "dc_labels"
  top: "dc_loss"
  loss_weight: 0.1
  include: { phase: TRAIN }
}
layer {
  name: "dc_accuracy"
  type: "Accuracy"
  bottom: "dc_ip3"
  bottom: "dc_labels"
  top: "dc_accuracy"
  include: { phase: TRAIN }
}

# ------------ classifiers
# ------------------------------------------------------ Exclude target samples
layer {
  name: "slice_features"
  type: "Slice"
  bottom: "bottleneck"
  top: "source_features"
  top: "target_features"
  slice_param {
    axis: 0
    slice_point: 24
  }
  include: { phase: TRAIN }
}

layer {
  name: "kill_target_features"
  type: "Silence"
  bottom: "target_features"
  include: { phase: TRAIN }
}

layer {
  name: "kill_target_labels"
  type: "Silence"
  bottom: "labels-target"
  include: { phase: TRAIN }
}

layer {
  name: "bottleneck_alias"
  type: "Split"
  bottom: "bottleneck"
  top: "source_features"
  include: { phase: TEST }
}

layer{
    name: "classifier"
    type: "InnerProduct"
    bottom: "source_features"
    top: "scorer"
    param {
        name: "wclassifier"
        lr_mult: 10.0
        decay_mult: 1.0
    }
        param {
        lr_mult: 20.0
        decay_mult: 1.0
    }
    inner_product_param {
        num_output: 7
        weight_filler {
        type: "gaussian"
                std: 0.01
            }
        bias_filler {
        type: "constant"
                value: 0.0
            }
    }
}

layer{
    name: "loss"
    type: "SoftmaxWithLoss"
    bottom: "scorer"
    bottom: "labels"
    top: "loss"
    loss_weight: 1
    include {
        phase: TRAIN
    }
}

layer{
    name: "accuracy"
    type: "Accuracy"
    bottom: "scorer"
    bottom: "labels"
    top: "accuracy"
    include {
        phase: TEST
    }
}

